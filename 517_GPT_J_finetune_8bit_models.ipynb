{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zo2di_L042N",
        "outputId": "9fa53fa2-1073-4701-aa1c-f7b114d28039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement bitsandbytes-cuda111==0.26.0 (from versions: 0.26.0.post2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for bitsandbytes-cuda111==0.26.0\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers -q\n",
        "!pip install bitsandbytes-cuda111==0.26.0 -q\n",
        "!pip install datasets -q\n",
        "!pip install accelerate -q\n",
        "!pip install numpy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O63l-OmBcwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4f9cb9-4286-4960-c583-b74b8102db58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.25.2)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.42.0\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXIjUDGc5RLq"
      },
      "source": [
        "### Fine-tuning 6-Billion GPT-J (& other models) in colab with LoRA and 8-bit compression\n",
        "\n",
        "This notebook is a simple example for fine-tuning [GPT-J-6B](https://huggingface.co/EleutherAI/gpt-j-6B) with limited memory. A detailed explanation of how it works can be found in [this model card](https://huggingface.co/hivemind/gpt-j-6B-8bit). It is heavily based on [this Colab](https://colab.research.google.com/drive/1ft6wQU0BhqG5PRlwgaZJv2VukKKjU4Es#scrollTo=vfdLQHOuEU7h). Huge thanks to Hivemind!\n",
        "\n",
        "You can also finetune [GPT-Neo-2.7B](https://huggingface.co/gustavecortal/gpt-neo-2.7B-8bit), [French GPT-J (Cedille's Boris)](https://huggingface.co/gustavecortal/fr-boris-8bit) and [T0-3B](https://huggingface.co/gustavecortal/T0_3B-8bit) with limited memory.\n",
        "\n",
        "Twitter: [@gustavecortal](https://twitter.com/gustavecortal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX35XMqY1JfY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47hM3-7-1WOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0a7aac-bbde-4154-cc71-f0012d2fed88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKti6sXNG4H5"
      },
      "source": [
        "## Converting the model to 8 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVLaOT811bVo"
      },
      "outputs": [],
      "source": [
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
        "        if self.adapter:\n",
        "            clone_output = output + self.adapter(input)\n",
        "        return clone_output\n",
        "\n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        "\n",
        "\n",
        "class DequantizeAndLinear(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias)\n",
        "\n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        "\n",
        "\n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "\n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        if self.adapter:\n",
        "            clone_output = output + self.adapter(input)\n",
        "        return clone_output\n",
        "\n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        "\n",
        "\n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        "\n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        "\n",
        "\n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Y40yNoG_Kn"
      },
      "source": [
        "You have to Monkey-Patch GPT-J before loading:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtafVIQn1gcl"
      },
      "outputs": [],
      "source": [
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpyKyOpsHF27"
      },
      "source": [
        "If you're using another 8-bit quantized model (e.g. T0-3B), remember to Monkey-Patch the model using convert_to_int8()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1q4P6av8e3k"
      },
      "outputs": [],
      "source": [
        "class T5ForConditionalGeneration(transformers.models.t5.modeling_t5.T5ForConditionalGeneration):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "transformers.models.t5.modeling_t5.T5ForConditionalGeneration = T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwJixCub1uwI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "4805798a6f774a8bb96421b10a9e1e5f",
            "f38d006d1b694e0d8c8e47458ec881ee",
            "d6b3c4b2f7cf4b03aefd0af29bb2a50d",
            "f552ee027c504b649c2f17e9463bc667",
            "c79fc1578da44601835d4755d98e0529",
            "146c7d19f47d4d73ae8572136a22a684",
            "2b5e20b7980a4af0aa0cf9c8dcb9677d",
            "1d9cc9325f29477490a869a41a268053",
            "388f8bf5b31c40e2bf8c3b3209c19803",
            "f75e4592e28e41ba96dfb87e3d80419b",
            "5765881a0a8a4093a194a6e8f8da7976",
            "229c40b15a2941af83f7b73e0b0aab0d",
            "919cee99c3f34d3e9354b86b5b8c9199",
            "3aa417c88ca74ee19fd39f8f754b7229",
            "feb8b60e519441e3af9d18c40642dab8",
            "b35f2ff3127c4222abeb0b8e7093e9eb",
            "04bfdd29270b48729ee500bbf08e21d2",
            "d9440c07aaea4f859752bfed4326e2ae",
            "e9984b74c6974b25b9a5674502c48f46",
            "b8a3c12b5ad54691b6472ac03c93862e",
            "cafbc3897ba24acc965dbb615d200ed1",
            "651f8567abda4e1aa401473e43c19a07",
            "d54655f562b84b799d62e7ceecd0af85",
            "45c38795d7bf4b1db927ee1f701f48aa",
            "b1224779ad1f4541935d0b0ef6dd748f",
            "ca8857d3aa7e45c9a037273c6ac66106",
            "4ce13f0a986c4766926cb42318fe0847",
            "056f909b85d0404ab25e0519f43ac1a0",
            "ff587e4a779c42ec90795d774cf46e7c",
            "15494dd7401f48d8aee59f3de8195915",
            "b55f291f36ee46a7a0647b8c77acc323",
            "3de3beb751094db1b1d5fa05cd3ca1f9",
            "0db503e08f1d40b5b26ff6f818ef4866",
            "091130c1742543eaa82cf8caea8389a3",
            "f6b87d74a3bb4cf9a724aef2f067f229",
            "cef80ab331cf4bba9e52935bd04aac2e",
            "a783615902a341ca88abed8609b81d77",
            "3b0ed456901e4a5090f78d641703ae86",
            "4b9344f6e5ee42feabfdfec3daa9c488",
            "6de7543c717f494eba0265ddaf405263",
            "1648369082df40048f2ff98be1220345",
            "728f03d9159b47058c3a6330230cba9e",
            "f4ff084f82bb444d866f95e2662ddee1",
            "78779ff75bc443e9ad599ffce86303f3",
            "0c9c76b1f9ef471a8c1cc16086247268",
            "5a87078d56a949d49513105bd259976b",
            "748490a2a36d4f10ab6bc2ab8549a25e",
            "93e7c8414e5546a09730d9a93e69d8a1",
            "b5faebebea2244daae7156828efcb81a",
            "c9c07ca84a1c451f82560d4cb3096257",
            "9842efeb578e42659ff74589ffbe753a",
            "2f9f784ba3f547e2a071973460c743ec",
            "823e47b957264a4f9f9bed307884ea4c",
            "7584fc07157e43809648727d207fed99",
            "9ec64e77b3204d5e9979bd70176d7611",
            "279d90f20f214c6dbfc89893353b354f",
            "ccab09bf2ae24933a3be202c212b4b42",
            "8b652d2718b24e499ad60b5d9d2ba8c9",
            "cc7bf9662eee44a4923e80bd1b951b1f",
            "25d6a2b8bdf940488e60c31e169d3a9d",
            "d006a5773ea449798a6587dff92ea597",
            "e5722a927145468c8395a9e50adece93",
            "63c516abae324c2db6b855b044b6a65d",
            "0e5e2e64e09b48b99fff817898829db2",
            "4eab045d0cee4d51a92ea71af1350cf4",
            "06caebfbf3b24452807c3d3f1b0686e7",
            "18786fd4074c47c8a674fbe2a29ce463",
            "e3d10ad0eab84617ac771b2d8f77289f",
            "b72cbf14259444e59ec1dcdf196e6793",
            "fbebc98f842b4ba28681261551e2e9ad",
            "d0ecccee13d94e12ac299d680cef9ec4",
            "75b8edac7de34392bb6ba6f83ce83d88",
            "08a8af132e81408ca7132d8361377a5e",
            "66fc3aa0f332483b93eff328254388c7",
            "b2a5ecc4dc4945929b54d7307782ecbf",
            "269f065646424890ab10552febcb8b2a",
            "bdfd458998a34ef0a0d32454243eb44f"
          ]
        },
        "outputId": "26fa153d-1e25-4985-be0b-c32b67cdaf3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4805798a6f774a8bb96421b10a9e1e5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "229c40b15a2941af83f7b73e0b0aab0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d54655f562b84b799d62e7ceecd0af85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "091130c1742543eaa82cf8caea8389a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c9c76b1f9ef471a8c1cc16086247268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "279d90f20f214c6dbfc89893353b354f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18786fd4074c47c8a674fbe2a29ce463"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0SXSVLk1zh_"
      },
      "outputs": [],
      "source": [
        "config.pad_token_id = config.eos_token_id\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYYH1l2hHhFZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0143abdc5fa74e1aa6bf857400fa924d",
            "0c90d1694835405db24bf74b5ae390ad",
            "e03268cff7c543cb98961df0e81ac592",
            "3eea976c0898435d960fb9996f08c5d0",
            "21aa77f8ee1343e18cc3d14c826088ad",
            "90fed7cb25e8440a980d2b06ef42b1a5",
            "cb8c902295f34d169e13ee899a350d93",
            "a2612fb718c0434aaf39c8f53d46a7b5",
            "db46ce6514f04c79916d68a978056849",
            "c88bda8b358d4291a3450a9c0c3ff919",
            "7c507167e88042d59d33831c490cf8e8",
            "a109632e5b744d0c86983a9cd0ba7cd0",
            "749b11ac45af4eb7b7eb66abd3a1fb09",
            "711b7f8b6ecb4a8893fff167d9ca8e3c",
            "b85a7430609c4e06b42144033f24f712",
            "bdf015223fe74b798078aaa8366b49e9",
            "a82b38ce73c14cfca29a6994e0b64b70",
            "f3c586b14bed44cabb9d894bb348d149",
            "a7572ec4844e42a485a4c13e30143634",
            "0fb54a4ab280464da7a81c721e102175",
            "97249b974f644058a0228d57cfc9cc9e",
            "eda84334c2354d1da4ee6ede987ce006"
          ]
        },
        "outputId": "be689bc9-d0a7-474b-dfca-04749dafef43"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0143abdc5fa74e1aa6bf857400fa924d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a109632e5b744d0c86983a9cd0ba7cd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
            "fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
            "fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
            "lm_head Linear(in_features=4096, out_features=50400, bias=True)\n"
          ]
        }
      ],
      "source": [
        "gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n",
        "#gpt.save_pretrained('/content/drive/MyDrive/nlp/')\n",
        "#gpt = GPTJForCausalLM.from_pretrained(\"gustavecortal/fr-boris-8bit\", low_cpu_mem_usage=True) French GPT-J Cedille's Boris\n",
        "\n",
        "#model_dir = '/content/drive/MyDrive/nlp/'\n",
        "#gpt = GPTJForCausalLM.from_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOmJJMf0Ho3H"
      },
      "source": [
        "## LoRA fine-tuning example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qnwAuQ8HsM6"
      },
      "source": [
        "You can load my very small dataset composed of philosophical sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DokZdiFd9K-W"
      },
      "outputs": [],
      "source": [
        "# !gdown --id 1Q1WMjny26VHLKb71iTCHIS5zvdm9c-wz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SUuVsoZ18rb"
      },
      "outputs": [],
      "source": [
        "main_folder = '/content/drive/MyDrive/nlp/'\n",
        "data = pd.read_csv(main_folder+'CombinedAnnotated.csv')\n",
        "train, test = train_test_split(data, test_size=0.01, random_state=42)\n",
        "train.to_csv('/content/CombinedAnnotatedTrain.csv', index=False)\n",
        "test.to_csv('/content/CombinedAnnotatedTest.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo6uZOqU2DxU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ec3acfde125041cbb7b449af4f99cb3c",
            "d01704f79fe449979986c1318e75df60",
            "f77b6aaaa2304139bb62f9312723bfe0",
            "0545672558a1491095e081ee366ffbac",
            "3a8ea716182345aa8b0e34cf3720f925",
            "9de0d31ef11243d0a37083a857f1c049",
            "f96cdae4ea50467986997a9815aab226",
            "f7e0fcaf27e848369c9ec6a22aa6194a",
            "433e67c15c4e4a61b957a8395494505b",
            "9a90de8b831e4a40a7a67a169a29c81e",
            "2ba73ce1daab4a5badcfae341930fce0",
            "ca0b4eb779134c2da309403a833a29e7",
            "d659cb945baa4c55baa8d76f5c98e4d2",
            "dbc08e665f8b48cfb08fb0ff5c93d6dc",
            "f2282ee90838408f82c5e4ef7e53ce1f",
            "bd2122ccb00f41f3aa5fa399ef6c3ab7",
            "df89ff28807a4859ab96b0aea971582e",
            "4973f25ea21b41dbab9c718bab6130f2",
            "459360c049044f8f98ced55eff6c4aa2",
            "23e8820f523d4187ac282b8ce1b4c34d",
            "389a9211039241c2a2c84d1e244d072a",
            "b72076622881418aac43e2ecc78438d2"
          ]
        },
        "outputId": "adf71ec4-2c96-49e5-c583-bcb7b01d2b66"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec3acfde125041cbb7b449af4f99cb3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca0b4eb779134c2da309403a833a29e7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('csv', data_files={'train': '/content/CombinedAnnotatedTrain.csv',\n",
        "                                              'test': '/content/CombinedAnnotatedTest.csv'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0QrNw_r2OMr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a9ea86b53ef94ed890805e52bb2025b6",
            "9ee370e902a64d629884e3b8fc8bbb18",
            "095330f7568947608ed4120e4a992bd1",
            "02810fc413ec466fb66078cbbee78b96",
            "b7708856a9074f23b0f9be57f4a29b68",
            "a6c42760731e48828afbdf02e30ee08e",
            "7bedfe44b3ce4bbcb3c2a3d03083ee98",
            "b383dddfabdb495caff25b2d3fd04332",
            "ab5507acea794a699bd7f551dcedde6a",
            "034cedee18964d25bf38cf946ffef79e",
            "71419a9287e94df7a07ff1fb66ca5ce0",
            "736f26441ace46978a9dcf587297e92f",
            "73a1535d9180412794f71641c7515800",
            "b1289c6498a14632843ef93f9dde7d8f",
            "c749e5bc750742fd844b11580cca898c",
            "05f8b5cc932f4834bbdb34c4d4521185",
            "77ada285016140bea0e9935da6475bc6",
            "3aae450fb24f4ef9b5fedac86814182d",
            "eefbed69157a4fd7ac2cb701a1d8cf65",
            "1d72af4aed8a481385c58baaeac98b8b",
            "dd2e3f14d4574bbcbdaacbd410cbb606",
            "c991291fa16d42cb870bd7b05e488478"
          ]
        },
        "outputId": "14ce5ce0-b075-47ef-a517-39697cf12b08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3611 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9ea86b53ef94ed890805e52bb2025b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "736f26441ace46978a9dcf587297e92f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=True, truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\"])\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vltw5L0i2b3d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "full_train_dataset = tokenized_datasets[\"train\"]\n",
        "train_dataloader = DataLoader(full_train_dataset, shuffle=False, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MUl4jkSKi6W"
      },
      "source": [
        "Add adapters to Embedding/MLP/Attention/LMHead layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Jfpe2h2mHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811b04da-0f1c-4cea-8bd6-f889ef261a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding adapter to transformer.wte\n",
            "Initializing transformer.wte\n",
            "Adding adapter to transformer.h.0.attn.k_proj\n",
            "Initializing transformer.h.0.attn.k_proj\n",
            "Adding adapter to transformer.h.0.attn.v_proj\n",
            "Initializing transformer.h.0.attn.v_proj\n",
            "Adding adapter to transformer.h.0.attn.q_proj\n",
            "Initializing transformer.h.0.attn.q_proj\n",
            "Adding adapter to transformer.h.0.attn.out_proj\n",
            "Initializing transformer.h.0.attn.out_proj\n",
            "Adding adapter to transformer.h.0.mlp.fc_in\n",
            "Initializing transformer.h.0.mlp.fc_in\n",
            "Adding adapter to transformer.h.0.mlp.fc_out\n",
            "Initializing transformer.h.0.mlp.fc_out\n",
            "Adding adapter to transformer.h.1.attn.k_proj\n",
            "Initializing transformer.h.1.attn.k_proj\n",
            "Adding adapter to transformer.h.1.attn.v_proj\n",
            "Initializing transformer.h.1.attn.v_proj\n",
            "Adding adapter to transformer.h.1.attn.q_proj\n",
            "Initializing transformer.h.1.attn.q_proj\n",
            "Adding adapter to transformer.h.1.attn.out_proj\n",
            "Initializing transformer.h.1.attn.out_proj\n",
            "Adding adapter to transformer.h.1.mlp.fc_in\n",
            "Initializing transformer.h.1.mlp.fc_in\n",
            "Adding adapter to transformer.h.1.mlp.fc_out\n",
            "Initializing transformer.h.1.mlp.fc_out\n",
            "Adding adapter to transformer.h.2.attn.k_proj\n",
            "Initializing transformer.h.2.attn.k_proj\n",
            "Adding adapter to transformer.h.2.attn.v_proj\n",
            "Initializing transformer.h.2.attn.v_proj\n",
            "Adding adapter to transformer.h.2.attn.q_proj\n",
            "Initializing transformer.h.2.attn.q_proj\n",
            "Adding adapter to transformer.h.2.attn.out_proj\n",
            "Initializing transformer.h.2.attn.out_proj\n",
            "Adding adapter to transformer.h.2.mlp.fc_in\n",
            "Initializing transformer.h.2.mlp.fc_in\n",
            "Adding adapter to transformer.h.2.mlp.fc_out\n",
            "Initializing transformer.h.2.mlp.fc_out\n",
            "Adding adapter to transformer.h.3.attn.k_proj\n",
            "Initializing transformer.h.3.attn.k_proj\n",
            "Adding adapter to transformer.h.3.attn.v_proj\n",
            "Initializing transformer.h.3.attn.v_proj\n",
            "Adding adapter to transformer.h.3.attn.q_proj\n",
            "Initializing transformer.h.3.attn.q_proj\n",
            "Adding adapter to transformer.h.3.attn.out_proj\n",
            "Initializing transformer.h.3.attn.out_proj\n",
            "Adding adapter to transformer.h.3.mlp.fc_in\n",
            "Initializing transformer.h.3.mlp.fc_in\n",
            "Adding adapter to transformer.h.3.mlp.fc_out\n",
            "Initializing transformer.h.3.mlp.fc_out\n",
            "Adding adapter to transformer.h.4.attn.k_proj\n",
            "Initializing transformer.h.4.attn.k_proj\n",
            "Adding adapter to transformer.h.4.attn.v_proj\n",
            "Initializing transformer.h.4.attn.v_proj\n",
            "Adding adapter to transformer.h.4.attn.q_proj\n",
            "Initializing transformer.h.4.attn.q_proj\n",
            "Adding adapter to transformer.h.4.attn.out_proj\n",
            "Initializing transformer.h.4.attn.out_proj\n",
            "Adding adapter to transformer.h.4.mlp.fc_in\n",
            "Initializing transformer.h.4.mlp.fc_in\n",
            "Adding adapter to transformer.h.4.mlp.fc_out\n",
            "Initializing transformer.h.4.mlp.fc_out\n",
            "Adding adapter to transformer.h.5.attn.k_proj\n",
            "Initializing transformer.h.5.attn.k_proj\n",
            "Adding adapter to transformer.h.5.attn.v_proj\n",
            "Initializing transformer.h.5.attn.v_proj\n",
            "Adding adapter to transformer.h.5.attn.q_proj\n",
            "Initializing transformer.h.5.attn.q_proj\n",
            "Adding adapter to transformer.h.5.attn.out_proj\n",
            "Initializing transformer.h.5.attn.out_proj\n",
            "Adding adapter to transformer.h.5.mlp.fc_in\n",
            "Initializing transformer.h.5.mlp.fc_in\n",
            "Adding adapter to transformer.h.5.mlp.fc_out\n",
            "Initializing transformer.h.5.mlp.fc_out\n",
            "Adding adapter to transformer.h.6.attn.k_proj\n",
            "Initializing transformer.h.6.attn.k_proj\n",
            "Adding adapter to transformer.h.6.attn.v_proj\n",
            "Initializing transformer.h.6.attn.v_proj\n",
            "Adding adapter to transformer.h.6.attn.q_proj\n",
            "Initializing transformer.h.6.attn.q_proj\n",
            "Adding adapter to transformer.h.6.attn.out_proj\n",
            "Initializing transformer.h.6.attn.out_proj\n",
            "Adding adapter to transformer.h.6.mlp.fc_in\n",
            "Initializing transformer.h.6.mlp.fc_in\n",
            "Adding adapter to transformer.h.6.mlp.fc_out\n",
            "Initializing transformer.h.6.mlp.fc_out\n",
            "Adding adapter to transformer.h.7.attn.k_proj\n",
            "Initializing transformer.h.7.attn.k_proj\n",
            "Adding adapter to transformer.h.7.attn.v_proj\n",
            "Initializing transformer.h.7.attn.v_proj\n",
            "Adding adapter to transformer.h.7.attn.q_proj\n",
            "Initializing transformer.h.7.attn.q_proj\n",
            "Adding adapter to transformer.h.7.attn.out_proj\n",
            "Initializing transformer.h.7.attn.out_proj\n",
            "Adding adapter to transformer.h.7.mlp.fc_in\n",
            "Initializing transformer.h.7.mlp.fc_in\n",
            "Adding adapter to transformer.h.7.mlp.fc_out\n",
            "Initializing transformer.h.7.mlp.fc_out\n",
            "Adding adapter to transformer.h.8.attn.k_proj\n",
            "Initializing transformer.h.8.attn.k_proj\n",
            "Adding adapter to transformer.h.8.attn.v_proj\n",
            "Initializing transformer.h.8.attn.v_proj\n",
            "Adding adapter to transformer.h.8.attn.q_proj\n",
            "Initializing transformer.h.8.attn.q_proj\n",
            "Adding adapter to transformer.h.8.attn.out_proj\n",
            "Initializing transformer.h.8.attn.out_proj\n",
            "Adding adapter to transformer.h.8.mlp.fc_in\n",
            "Initializing transformer.h.8.mlp.fc_in\n",
            "Adding adapter to transformer.h.8.mlp.fc_out\n",
            "Initializing transformer.h.8.mlp.fc_out\n",
            "Adding adapter to transformer.h.9.attn.k_proj\n",
            "Initializing transformer.h.9.attn.k_proj\n",
            "Adding adapter to transformer.h.9.attn.v_proj\n",
            "Initializing transformer.h.9.attn.v_proj\n",
            "Adding adapter to transformer.h.9.attn.q_proj\n",
            "Initializing transformer.h.9.attn.q_proj\n",
            "Adding adapter to transformer.h.9.attn.out_proj\n",
            "Initializing transformer.h.9.attn.out_proj\n",
            "Adding adapter to transformer.h.9.mlp.fc_in\n",
            "Initializing transformer.h.9.mlp.fc_in\n",
            "Adding adapter to transformer.h.9.mlp.fc_out\n",
            "Initializing transformer.h.9.mlp.fc_out\n",
            "Adding adapter to transformer.h.10.attn.k_proj\n",
            "Initializing transformer.h.10.attn.k_proj\n",
            "Adding adapter to transformer.h.10.attn.v_proj\n",
            "Initializing transformer.h.10.attn.v_proj\n",
            "Adding adapter to transformer.h.10.attn.q_proj\n",
            "Initializing transformer.h.10.attn.q_proj\n",
            "Adding adapter to transformer.h.10.attn.out_proj\n",
            "Initializing transformer.h.10.attn.out_proj\n",
            "Adding adapter to transformer.h.10.mlp.fc_in\n",
            "Initializing transformer.h.10.mlp.fc_in\n",
            "Adding adapter to transformer.h.10.mlp.fc_out\n",
            "Initializing transformer.h.10.mlp.fc_out\n",
            "Adding adapter to transformer.h.11.attn.k_proj\n",
            "Initializing transformer.h.11.attn.k_proj\n",
            "Adding adapter to transformer.h.11.attn.v_proj\n",
            "Initializing transformer.h.11.attn.v_proj\n",
            "Adding adapter to transformer.h.11.attn.q_proj\n",
            "Initializing transformer.h.11.attn.q_proj\n",
            "Adding adapter to transformer.h.11.attn.out_proj\n",
            "Initializing transformer.h.11.attn.out_proj\n",
            "Adding adapter to transformer.h.11.mlp.fc_in\n",
            "Initializing transformer.h.11.mlp.fc_in\n",
            "Adding adapter to transformer.h.11.mlp.fc_out\n",
            "Initializing transformer.h.11.mlp.fc_out\n",
            "Adding adapter to transformer.h.12.attn.k_proj\n",
            "Initializing transformer.h.12.attn.k_proj\n",
            "Adding adapter to transformer.h.12.attn.v_proj\n",
            "Initializing transformer.h.12.attn.v_proj\n",
            "Adding adapter to transformer.h.12.attn.q_proj\n",
            "Initializing transformer.h.12.attn.q_proj\n",
            "Adding adapter to transformer.h.12.attn.out_proj\n",
            "Initializing transformer.h.12.attn.out_proj\n",
            "Adding adapter to transformer.h.12.mlp.fc_in\n",
            "Initializing transformer.h.12.mlp.fc_in\n",
            "Adding adapter to transformer.h.12.mlp.fc_out\n",
            "Initializing transformer.h.12.mlp.fc_out\n",
            "Adding adapter to transformer.h.13.attn.k_proj\n",
            "Initializing transformer.h.13.attn.k_proj\n",
            "Adding adapter to transformer.h.13.attn.v_proj\n",
            "Initializing transformer.h.13.attn.v_proj\n",
            "Adding adapter to transformer.h.13.attn.q_proj\n",
            "Initializing transformer.h.13.attn.q_proj\n",
            "Adding adapter to transformer.h.13.attn.out_proj\n",
            "Initializing transformer.h.13.attn.out_proj\n",
            "Adding adapter to transformer.h.13.mlp.fc_in\n",
            "Initializing transformer.h.13.mlp.fc_in\n",
            "Adding adapter to transformer.h.13.mlp.fc_out\n",
            "Initializing transformer.h.13.mlp.fc_out\n",
            "Adding adapter to transformer.h.14.attn.k_proj\n",
            "Initializing transformer.h.14.attn.k_proj\n",
            "Adding adapter to transformer.h.14.attn.v_proj\n",
            "Initializing transformer.h.14.attn.v_proj\n",
            "Adding adapter to transformer.h.14.attn.q_proj\n",
            "Initializing transformer.h.14.attn.q_proj\n",
            "Adding adapter to transformer.h.14.attn.out_proj\n",
            "Initializing transformer.h.14.attn.out_proj\n",
            "Adding adapter to transformer.h.14.mlp.fc_in\n",
            "Initializing transformer.h.14.mlp.fc_in\n",
            "Adding adapter to transformer.h.14.mlp.fc_out\n",
            "Initializing transformer.h.14.mlp.fc_out\n",
            "Adding adapter to transformer.h.15.attn.k_proj\n",
            "Initializing transformer.h.15.attn.k_proj\n",
            "Adding adapter to transformer.h.15.attn.v_proj\n",
            "Initializing transformer.h.15.attn.v_proj\n",
            "Adding adapter to transformer.h.15.attn.q_proj\n",
            "Initializing transformer.h.15.attn.q_proj\n",
            "Adding adapter to transformer.h.15.attn.out_proj\n",
            "Initializing transformer.h.15.attn.out_proj\n",
            "Adding adapter to transformer.h.15.mlp.fc_in\n",
            "Initializing transformer.h.15.mlp.fc_in\n",
            "Adding adapter to transformer.h.15.mlp.fc_out\n",
            "Initializing transformer.h.15.mlp.fc_out\n",
            "Adding adapter to transformer.h.16.attn.k_proj\n",
            "Initializing transformer.h.16.attn.k_proj\n",
            "Adding adapter to transformer.h.16.attn.v_proj\n",
            "Initializing transformer.h.16.attn.v_proj\n",
            "Adding adapter to transformer.h.16.attn.q_proj\n",
            "Initializing transformer.h.16.attn.q_proj\n",
            "Adding adapter to transformer.h.16.attn.out_proj\n",
            "Initializing transformer.h.16.attn.out_proj\n",
            "Adding adapter to transformer.h.16.mlp.fc_in\n",
            "Initializing transformer.h.16.mlp.fc_in\n",
            "Adding adapter to transformer.h.16.mlp.fc_out\n",
            "Initializing transformer.h.16.mlp.fc_out\n",
            "Adding adapter to transformer.h.17.attn.k_proj\n",
            "Initializing transformer.h.17.attn.k_proj\n",
            "Adding adapter to transformer.h.17.attn.v_proj\n",
            "Initializing transformer.h.17.attn.v_proj\n",
            "Adding adapter to transformer.h.17.attn.q_proj\n",
            "Initializing transformer.h.17.attn.q_proj\n",
            "Adding adapter to transformer.h.17.attn.out_proj\n",
            "Initializing transformer.h.17.attn.out_proj\n",
            "Adding adapter to transformer.h.17.mlp.fc_in\n",
            "Initializing transformer.h.17.mlp.fc_in\n",
            "Adding adapter to transformer.h.17.mlp.fc_out\n",
            "Initializing transformer.h.17.mlp.fc_out\n",
            "Adding adapter to transformer.h.18.attn.k_proj\n",
            "Initializing transformer.h.18.attn.k_proj\n",
            "Adding adapter to transformer.h.18.attn.v_proj\n",
            "Initializing transformer.h.18.attn.v_proj\n",
            "Adding adapter to transformer.h.18.attn.q_proj\n",
            "Initializing transformer.h.18.attn.q_proj\n",
            "Adding adapter to transformer.h.18.attn.out_proj\n",
            "Initializing transformer.h.18.attn.out_proj\n",
            "Adding adapter to transformer.h.18.mlp.fc_in\n",
            "Initializing transformer.h.18.mlp.fc_in\n",
            "Adding adapter to transformer.h.18.mlp.fc_out\n",
            "Initializing transformer.h.18.mlp.fc_out\n",
            "Adding adapter to transformer.h.19.attn.k_proj\n",
            "Initializing transformer.h.19.attn.k_proj\n",
            "Adding adapter to transformer.h.19.attn.v_proj\n",
            "Initializing transformer.h.19.attn.v_proj\n",
            "Adding adapter to transformer.h.19.attn.q_proj\n",
            "Initializing transformer.h.19.attn.q_proj\n",
            "Adding adapter to transformer.h.19.attn.out_proj\n",
            "Initializing transformer.h.19.attn.out_proj\n",
            "Adding adapter to transformer.h.19.mlp.fc_in\n",
            "Initializing transformer.h.19.mlp.fc_in\n",
            "Adding adapter to transformer.h.19.mlp.fc_out\n",
            "Initializing transformer.h.19.mlp.fc_out\n",
            "Adding adapter to transformer.h.20.attn.k_proj\n",
            "Initializing transformer.h.20.attn.k_proj\n",
            "Adding adapter to transformer.h.20.attn.v_proj\n",
            "Initializing transformer.h.20.attn.v_proj\n",
            "Adding adapter to transformer.h.20.attn.q_proj\n",
            "Initializing transformer.h.20.attn.q_proj\n",
            "Adding adapter to transformer.h.20.attn.out_proj\n",
            "Initializing transformer.h.20.attn.out_proj\n",
            "Adding adapter to transformer.h.20.mlp.fc_in\n",
            "Initializing transformer.h.20.mlp.fc_in\n",
            "Adding adapter to transformer.h.20.mlp.fc_out\n",
            "Initializing transformer.h.20.mlp.fc_out\n",
            "Adding adapter to transformer.h.21.attn.k_proj\n",
            "Initializing transformer.h.21.attn.k_proj\n",
            "Adding adapter to transformer.h.21.attn.v_proj\n",
            "Initializing transformer.h.21.attn.v_proj\n",
            "Adding adapter to transformer.h.21.attn.q_proj\n",
            "Initializing transformer.h.21.attn.q_proj\n",
            "Adding adapter to transformer.h.21.attn.out_proj\n",
            "Initializing transformer.h.21.attn.out_proj\n",
            "Adding adapter to transformer.h.21.mlp.fc_in\n",
            "Initializing transformer.h.21.mlp.fc_in\n",
            "Adding adapter to transformer.h.21.mlp.fc_out\n",
            "Initializing transformer.h.21.mlp.fc_out\n",
            "Adding adapter to transformer.h.22.attn.k_proj\n",
            "Initializing transformer.h.22.attn.k_proj\n",
            "Adding adapter to transformer.h.22.attn.v_proj\n",
            "Initializing transformer.h.22.attn.v_proj\n",
            "Adding adapter to transformer.h.22.attn.q_proj\n",
            "Initializing transformer.h.22.attn.q_proj\n",
            "Adding adapter to transformer.h.22.attn.out_proj\n",
            "Initializing transformer.h.22.attn.out_proj\n",
            "Adding adapter to transformer.h.22.mlp.fc_in\n",
            "Initializing transformer.h.22.mlp.fc_in\n",
            "Adding adapter to transformer.h.22.mlp.fc_out\n",
            "Initializing transformer.h.22.mlp.fc_out\n",
            "Adding adapter to transformer.h.23.attn.k_proj\n",
            "Initializing transformer.h.23.attn.k_proj\n",
            "Adding adapter to transformer.h.23.attn.v_proj\n",
            "Initializing transformer.h.23.attn.v_proj\n",
            "Adding adapter to transformer.h.23.attn.q_proj\n",
            "Initializing transformer.h.23.attn.q_proj\n",
            "Adding adapter to transformer.h.23.attn.out_proj\n",
            "Initializing transformer.h.23.attn.out_proj\n",
            "Adding adapter to transformer.h.23.mlp.fc_in\n",
            "Initializing transformer.h.23.mlp.fc_in\n",
            "Adding adapter to transformer.h.23.mlp.fc_out\n",
            "Initializing transformer.h.23.mlp.fc_out\n",
            "Adding adapter to transformer.h.24.attn.k_proj\n",
            "Initializing transformer.h.24.attn.k_proj\n",
            "Adding adapter to transformer.h.24.attn.v_proj\n",
            "Initializing transformer.h.24.attn.v_proj\n",
            "Adding adapter to transformer.h.24.attn.q_proj\n",
            "Initializing transformer.h.24.attn.q_proj\n",
            "Adding adapter to transformer.h.24.attn.out_proj\n",
            "Initializing transformer.h.24.attn.out_proj\n",
            "Adding adapter to transformer.h.24.mlp.fc_in\n",
            "Initializing transformer.h.24.mlp.fc_in\n",
            "Adding adapter to transformer.h.24.mlp.fc_out\n",
            "Initializing transformer.h.24.mlp.fc_out\n",
            "Adding adapter to transformer.h.25.attn.k_proj\n",
            "Initializing transformer.h.25.attn.k_proj\n",
            "Adding adapter to transformer.h.25.attn.v_proj\n",
            "Initializing transformer.h.25.attn.v_proj\n",
            "Adding adapter to transformer.h.25.attn.q_proj\n",
            "Initializing transformer.h.25.attn.q_proj\n",
            "Adding adapter to transformer.h.25.attn.out_proj\n",
            "Initializing transformer.h.25.attn.out_proj\n",
            "Adding adapter to transformer.h.25.mlp.fc_in\n",
            "Initializing transformer.h.25.mlp.fc_in\n",
            "Adding adapter to transformer.h.25.mlp.fc_out\n",
            "Initializing transformer.h.25.mlp.fc_out\n",
            "Adding adapter to transformer.h.26.attn.k_proj\n",
            "Initializing transformer.h.26.attn.k_proj\n",
            "Adding adapter to transformer.h.26.attn.v_proj\n",
            "Initializing transformer.h.26.attn.v_proj\n",
            "Adding adapter to transformer.h.26.attn.q_proj\n",
            "Initializing transformer.h.26.attn.q_proj\n",
            "Adding adapter to transformer.h.26.attn.out_proj\n",
            "Initializing transformer.h.26.attn.out_proj\n",
            "Adding adapter to transformer.h.26.mlp.fc_in\n",
            "Initializing transformer.h.26.mlp.fc_in\n",
            "Adding adapter to transformer.h.26.mlp.fc_out\n",
            "Initializing transformer.h.26.mlp.fc_out\n",
            "Adding adapter to transformer.h.27.attn.k_proj\n",
            "Initializing transformer.h.27.attn.k_proj\n",
            "Adding adapter to transformer.h.27.attn.v_proj\n",
            "Initializing transformer.h.27.attn.v_proj\n",
            "Adding adapter to transformer.h.27.attn.q_proj\n",
            "Initializing transformer.h.27.attn.q_proj\n",
            "Adding adapter to transformer.h.27.attn.out_proj\n",
            "Initializing transformer.h.27.attn.out_proj\n",
            "Adding adapter to transformer.h.27.mlp.fc_in\n",
            "Initializing transformer.h.27.mlp.fc_in\n",
            "Adding adapter to transformer.h.27.mlp.fc_out\n",
            "Initializing transformer.h.27.mlp.fc_out\n",
            "Adding adapter to lm_head\n",
            "Initializing lm_head\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJForCausalLM(\n",
              "  (transformer): GPTJModel(\n",
              "    (wte): FrozenBNBEmbedding(50400, 4096)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-27): 28 x GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
              "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
              "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): FrozenBNBLinear(4096, 50400)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def add_adapters(model, adapter_dim=4, p = 0.1):\n",
        "    assert adapter_dim > 0\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "      if isinstance(module, FrozenBNBLinear):\n",
        "          if \"attn\" in name or \"mlp\" in name or \"head\" in name:\n",
        "              print(\"Adding adapter to\", name)\n",
        "              module.adapter = nn.Sequential(\n",
        "                nn.Linear(module.in_features, adapter_dim, bias=False),\n",
        "                nn.Dropout(p=p),\n",
        "                nn.Linear(adapter_dim, module.out_features, bias=False),\n",
        "            )\n",
        "              print(\"Initializing\", name)\n",
        "              nn.init.zeros_(module.adapter[2].weight)\n",
        "\n",
        "          else:\n",
        "              print(\"Not adding adapter to\", name)\n",
        "      elif isinstance(module, FrozenBNBEmbedding):\n",
        "          print(\"Adding adapter to\", name)\n",
        "          module.adapter = nn.Sequential(\n",
        "                nn.Embedding(module.num_embeddings, adapter_dim),\n",
        "                nn.Dropout(p=p),\n",
        "                nn.Linear(adapter_dim, module.embedding_dim, bias=False),\n",
        "            )\n",
        "          print(\"Initializing\", name)\n",
        "          nn.init.zeros_(module.adapter[2].weight)\n",
        "\n",
        "add_adapters(gpt)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOnrE2C330UL"
      },
      "outputs": [],
      "source": [
        "from bitsandbytes.optim import Adam8bit\n",
        "\n",
        "gpt.gradient_checkpointing_enable()\n",
        "optimizer = Adam8bit(gpt.parameters(), lr=1e-5, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvD2RYYK32qH"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM_29EAi37rr"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer, int(num_training_steps*0.1), num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9ZH7tEb4EOB"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/model.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJltmES4FdM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d4617d930144c16854e933d2bf3197d",
            "90feca0c227a4a78b6652560c90e6376",
            "b9d9b91ca10a41558191d40b4ff35b94",
            "163dc83cd9304df784626b4697cb50d3",
            "5f835b8599df4c339b18f04554502c79",
            "3c637d8567644f98aea8ed5586b0ac13",
            "988bc5981fe4485db9048047e9dcceeb",
            "3d897d34bdec4e108d15431d287488ca",
            "ab3f9dc90d7a4e3f95b16c9abbf6c892",
            "4d14a18abe2f4d3ca60227525929b8c9",
            "e8d84eff449a4b9793d486edb6b6f23b"
          ]
        },
        "outputId": "a3c1eacb-4e23-4e3a-9aed-4b24a8d6709c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2260 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d4617d930144c16854e933d2bf3197d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.1151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.1352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9.0416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.9445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9.4242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9.1322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.9611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.9298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.8468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.5774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.7687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(9.0885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.9319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.8835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6063, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.8019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.6087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.0246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.3798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(8.2615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.3022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.4853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.8013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.2836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.3155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.9508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.2879, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.2333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.8373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.6999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.1910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.8217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.8491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(7.0814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.8277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.9670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.3304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.5915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.2675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.9895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.2828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.2906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.2579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.2454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.8902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(6.1449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.6164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.7768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.3476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.5946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.0958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.3206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.2369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.1896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(5.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.6871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.6286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.4802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.3863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(4.1775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.8551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.8055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.2723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.9216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.2398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(3.1156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.9011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.8873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4007, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2851, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "500\n",
            "tensor(2.0657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0935, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0187, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1607, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9407, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0219, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1000\n",
            "tensor(2.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9743, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0900, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "1500\n",
            "tensor(1.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9037, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9830, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8827, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8038, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8327, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9920, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.3078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8865, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0924, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "2000\n",
            "tensor(2.0995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8245, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.2199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9843, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9071, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0910, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9869, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.7978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9816, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.9388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.8991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(2.1951, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "gpt.train()\n",
        "gpt.gradient_checkpointing_enable()\n",
        "k = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "\n",
        "        k = k + 1\n",
        "        if k % 500 == 0:\n",
        "          print(k)\n",
        "          state = {'k' : k, 'epoch': num_epochs, 'lr_scheduler': lr_scheduler.state_dict(), 'state_dict': gpt.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "          torch.save(state, filepath)\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "          out = gpt.forward(**batch,)\n",
        "\n",
        "          loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n",
        "                                reduction='mean', label_smoothing=0.1)\n",
        "\n",
        "        print(loss)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3U67wWMIgK7"
      },
      "source": [
        "## Text generation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Qj4EAPPIW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f587e4bf-b502-4cf7-a323-51429f6ef9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who does patrick stewart play in star trek? Answer: [QA(Who does patrick stewart play in star trek?) -> Patrick Stewart] Patrick Stewart<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "gpt.eval()\n",
        "with torch.no_grad():\n",
        "  prompt = tokenizer(\"Question: Who does patrick stewart play in star trek? Answer:\", truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "  prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "  out = gpt.generate(**prompt, max_length=256, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\n",
        "  print(tokenizer.decode(out[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d_R9ocCsS-j"
      },
      "outputs": [],
      "source": [
        "from operator import floordiv, mul, add, sub\n",
        "\n",
        "def is_decimal(input_string: str) -> bool:\n",
        "  try:\n",
        "    float(input_string)\n",
        "    return True\n",
        "  except ValueError:\n",
        "    return False\n",
        "\n",
        "def Calculator(input_query: str):\n",
        "  operators = {'+': add, '-': sub, '*': mul, '/': floordiv}\n",
        "  try:\n",
        "    if input_query.isdigit():\n",
        "      return int(input_query)\n",
        "    elif is_decimal(input_query):\n",
        "      return float(input_query)\n",
        "    for c in operators.keys():\n",
        "      left, operator, right = input_query.partition(c)\n",
        "      if operator in operators:\n",
        "        if operator == '/':\n",
        "          return str(Calculator(left) // Calculator(right)) + \" r\"+ str(Calculator(left) % Calculator(right))\n",
        "        return round(operators[operator](Calculator(left), Calculator(right)), 2)\n",
        "  except TypeError as e:\n",
        "    print(f\"Error processing the input '{input_query}': {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"YOUR-API-KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvoEMCvj6AS",
        "outputId": "ba86ebb4-a182-4c74-8d6b-a38c328d21c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aq_YnKOxZpi"
      },
      "outputs": [],
      "source": [
        "def inference(text_input):\n",
        "  gpt.eval()\n",
        "  with torch.no_grad():\n",
        "    prompt = tokenizer(text_input, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "    prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "    output_tokens = gpt.generate(**prompt, max_length=256, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\n",
        "    out = tokenizer.decode(output_tokens[0])\n",
        "    print(\"Original prompt: \"+out)\n",
        "    if \"[Calculator(\" in out and \"[QA(\" in out:\n",
        "      print(\"Note, this output below uses both calculator and QA. This will likely not give a right answer\")\n",
        "\n",
        "    api_str = \"[Calculator(\"\n",
        "    api_str_end = \")]\"\n",
        "    idx_start = 0\n",
        "    idx_end = 0\n",
        "    checkpoint = 0\n",
        "    i = 0\n",
        "    while api_str in out[checkpoint:len(out)] and i < 5:\n",
        "      #print(\"we're using calculator\")\n",
        "      idx_start = checkpoint + out[checkpoint:len(out)].find(api_str) + len(api_str)\n",
        "      idx_end = checkpoint + out[checkpoint:len(out)].find(api_str_end)\n",
        "      #assert idx_start <= idx_end, \"start index shouldn't be larger than end index, start: \"+str(idx_start)+\" end: \"+str(idx_end)+\" i: \"+str(i)\n",
        "      if idx_start > idx_end:\n",
        "        print(\"WE SKIPPED\")\n",
        "        break\n",
        "      expr = out[idx_start:idx_end]\n",
        "      expr = expr.replace(',', '')\n",
        "      answer = Calculator(expr)\n",
        "      if answer == None:\n",
        "        print(\"WE SKIPPED\")\n",
        "        break\n",
        "      if is_decimal(answer):\n",
        "        answer = round(float(answer), 2)\n",
        "      print(\"Computed answer was: \"+str(answer))\n",
        "      new_input = out[0:idx_end+len(api_str_end)]+\"=\"+str(answer)\n",
        "      prompt = tokenizer(new_input, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "      prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "      output_tokens = gpt.generate(**prompt, max_length=256, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\n",
        "      out = tokenizer.decode(output_tokens[0])\n",
        "      if idx_end != 0:\n",
        "        checkpoint = idx_end + len(api_str_end) # would be pos of '=' in '+3)]='\n",
        "      else:\n",
        "        checkpoint = idx_end\n",
        "      #print(out)\n",
        "      i += 1\n",
        "\n",
        "    api_str_2 = \"[QA(\"\n",
        "    api_str_end_2 = \") ->\"\n",
        "    idx_start_2 = 0\n",
        "    idx_end_2 = 0\n",
        "    checkpoint_2 = 0\n",
        "    j = 0\n",
        "\n",
        "    while api_str_2 in out[checkpoint_2:len(out)] and j < 5:\n",
        "      #print(\"we're using chatgpt for Q&A help\")\n",
        "      idx_start_2 = checkpoint_2 + out[checkpoint_2:len(out)].find(api_str_2) + len(api_str_2)\n",
        "      idx_end_2 = checkpoint_2 + out[checkpoint_2:len(out)].find(api_str_end_2)\n",
        "      #assert idx_start_2 <= idx_end_2, \"start index shouldn't be larger than end index, start: \"+str(idx_start_2)+\" end: \"+str(idx_end_2)+\" i: \"+str(j)\n",
        "      if idx_start > idx_end:\n",
        "        print(\"WE SKIPPED\")\n",
        "        break\n",
        "      prompt = out[idx_start_2:idx_end_2]\n",
        "      prompt = \"Please give a concise answer with only few words. \" + prompt\n",
        "      #print(prompt)\n",
        "      chat_completion = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt,}], model=\"gpt-4\",)\n",
        "      answer = chat_completion.choices[0].message.content\n",
        "      new_input = out[0:idx_end_2+len(api_str_end_2)]+\" \"+answer+\"]\"\n",
        "      second_try_prompt = tokenizer(new_input, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "      second_try_prompt = {key: value.to(device) for key, value in second_try_prompt.items()}\n",
        "      output_tokens = gpt.generate(**second_try_prompt, max_length=512, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\n",
        "      out = tokenizer.decode(output_tokens[0])\n",
        "      if idx_end_2 != 0:\n",
        "        checkpoint_2 = idx_end_2 + len(api_str_end_2)\n",
        "      else:\n",
        "        checkpoint_2 = idx_end_2\n",
        "      j += 1\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-3v2eLl2Jur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f4b892-f459-4164-bab3-bd26455d87bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original prompt: Question: Who did Trump face in the 2020 election?  Answer: [QA(Who did Trump face in the 2020 election?) -> Joe Biden, Bernie Sanders, Elizabeth Warren, Pete Buttigieg, Kamala Harris, Amy Klobuchar, Beto O'Rourke, Cory Booker, Kristen Gillibrand, Jay Inslee, Marianne Williamson, John Hickenlooper, Tim Ryan, Eric Swalwell, John Delaney, Seth Moulton, Wayne Messam, Steve Bullock, Joe Biden, Bernie Sanders, Elizabeth Warren, Pete Buttigieg, Kamala Harris, Amy Klobuchar, Beto O'Rourke, Cory Booker, Kristen Gillibrand, Jay Inslee, Marianne Williamson, John Hickenlooper, Tim Ryan, Eric Swalwell, John Delaney, Seth Moulton, Wayne Messam, Steve Bullock, Joe Biden, Bernie Sanders, Elizabeth Warren, Pete Buttigieg, Kamala Harris, Amy Klobuchar, Beto O'Rourke, Cory Booker, Kristen Gillibrand, Jay Inslee, Marianne Williamson, John Hickenlooper, Tim Ryan, Eric Swalwell, John Delaney, Seth Moulton, Wayne Mess\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who did Trump face in the 2020 election?  Answer: [QA(Who did Trump face in the 2020 election?) -> Trump faced Joe Biden in the 2020 election.] Joe Biden<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "infered = inference(\"Question: Who did Trump face in the 2020 election? \")\n",
        "print(infered)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import re\n",
        "\n",
        "file_name = 'ASDivBenchmarkNoAnswers.txt'\n",
        "output_file_name = 'ASDivBenchmarkVanillaAnswers.txt'\n",
        "\n",
        "with open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\n",
        "  for line in file:\n",
        "    print(\"Original: \" + line)\n",
        "    gpt.eval()\n",
        "    with torch.no_grad():\n",
        "      prompt = tokenizer(line.strip(), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
        "      prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "      output_tokens = gpt.generate(**prompt, max_length=256, do_sample=True, repetition_penalty = 1.0, num_beams=3)\n",
        "      generated_line = tokenizer.decode(output_tokens[0])\n",
        "      print(\"Generated: \" + generated_line)\n",
        "      outfile.write(generated_line)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "3nHiQkhl2lq1",
        "outputId": "d09fbc98-e02a-4703-afcc-b3408f749888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport re\\n\\nfile_name = \\'ASDivBenchmarkNoAnswers.txt\\'\\noutput_file_name = \\'ASDivBenchmarkVanillaAnswers.txt\\'\\n\\nwith open(file_name, \\'r\\') as file, open(output_file_name, \\'w\\') as outfile:\\n  for line in file:\\n    print(\"Original: \" + line)\\n    gpt.eval()\\n    with torch.no_grad():\\n      prompt = tokenizer(line.strip(), truncation=True, padding=True, max_length=256, return_tensors=\\'pt\\')\\n      prompt = {key: value.to(device) for key, value in prompt.items()}\\n      output_tokens = gpt.generate(**prompt, max_length=256, do_sample=True, repetition_penalty = 1.0, num_beams=3)\\n      generated_line = tokenizer.decode(output_tokens[0])\\n      print(\"Generated: \" + generated_line)\\n      outfile.write(generated_line)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "file_name = 'NQBenchmarkNoAnswers.txt'\n",
        "output_file_name = 'NQBenchmarkVanillaAnswers.txt'\n",
        "\n",
        "with open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\n",
        "  for line in file:\n",
        "    print(\"Original: \" + line)\n",
        "    gpt.eval()\n",
        "    with torch.no_grad():\n",
        "      prompt = tokenizer(line.strip(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "      prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "      output_tokens = gpt.generate(**prompt, max_length=256, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\n",
        "      generated_line = tokenizer.decode(output_tokens[0])\n",
        "      print(\"Generated: \" + generated_line)\n",
        "      outfile.write(generated_line)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "jCbA1QqS3IKb",
        "outputId": "959628ab-6e97-43c7-bb54-f21f57d6d930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfile_name = \\'NQBenchmarkNoAnswers.txt\\'\\noutput_file_name = \\'NQBenchmarkVanillaAnswers.txt\\'\\n\\nwith open(file_name, \\'r\\') as file, open(output_file_name, \\'w\\') as outfile:\\n  for line in file:\\n    print(\"Original: \" + line)\\n    gpt.eval()\\n    with torch.no_grad():\\n      prompt = tokenizer(line.strip(), truncation=True, padding=True, max_length=128, return_tensors=\\'pt\\')\\n      prompt = {key: value.to(device) for key, value in prompt.items()}\\n      output_tokens = gpt.generate(**prompt, max_length=256, top_k=100, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=3)\\n      generated_line = tokenizer.decode(output_tokens[0])\\n      print(\"Generated: \" + generated_line)\\n      outfile.write(generated_line)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import re\n",
        "\n",
        "file_name = 'ASDivBenchmarkNoAnswers.txt'\n",
        "output_file_name = 'ASDivBenchmarkToolformerAnswers.txt'\n",
        "\n",
        "with open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\n",
        "  for line in file:\n",
        "    #print(line)\n",
        "    generated_line = inference(line)\n",
        "    print(generated_line)\n",
        "    outfile.write(generated_line)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M2vul8RBP3PI",
        "outputId": "1e925fb0-d09a-4b66-a304-6d0d13604306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport re\\n\\nfile_name = 'ASDivBenchmarkNoAnswers.txt'\\noutput_file_name = 'ASDivBenchmarkToolformerAnswers.txt'\\n\\nwith open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\\n  for line in file:\\n    #print(line)\\n    generated_line = inference(line)\\n    print(generated_line)\\n    outfile.write(generated_line)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "file_name = 'NQBenchmarkNoAnswers.txt'\n",
        "output_file_name = 'NQBenchmarkToolformerAnswers.txt'\n",
        "\n",
        "with open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\n",
        "  for line in file:\n",
        "    print(\"Original: \" + line)\n",
        "    generated_line = inference(line)\n",
        "    print(\"Generated: \" + generated_line)\n",
        "    outfile.write(generated_line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDT8xfk0c4IC",
        "outputId": "f39d639f-b7cd-4ac2-9f76-f40b29d12751"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: Question: When was puerto rico added to the usa? Answer:\n",
            "\n",
            "Original prompt: Question: When was puerto rico added to the usa? Answer:\n",
            "[QA(When was puerto rico added to the usa?) -> 1898] 1898<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was puerto rico added to the usa? Answer:\n",
            "[QA(When was puerto rico added to the usa?) -> 1898] 1898<|endoftext|>\n",
            "Original: Question: In which year vivo launch its first phone in india? Answer:\n",
            "\n",
            "Original prompt: Question: In which year vivo launch its first phone in india? Answer:\n",
            "[QA(In which year vivo launch its first phone in india?) -> 2006] 2006<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: In which year vivo launch its first phone in india? Answer:\n",
            "[QA(In which year vivo launch its first phone in india?) -> 2014] 2014<|endoftext|>\n",
            "Original: Question: What's the legal marriage age in new york? Answer:\n",
            "\n",
            "Original prompt: Question: What's the legal marriage age in new york? Answer:\n",
            "[QA(What's the legal marriage age in new york?) -> The legal marriage age in New York is 18.] 18<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What's the legal marriage age in new york? Answer:\n",
            "[QA(What's the legal marriage age in new york?) -> 17 years old] 17<|endoftext|>\n",
            "Original: Question: When did the ipod touch 6 gen came out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the ipod touch 6 gen came out? Answer:\n",
            "[QA(When did the ipod touch 6 gen come out?) -> September 19, 2010] September 19, 2010<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the ipod touch 6 gen came out? Answer:\n",
            "[QA(When did the ipod touch 6 gen come out?) -> July 15, 2015] July 15, 2015<|endoftext|>\n",
            "Original: Question: When did justin bieber perform at madison square garden? Answer:\n",
            "\n",
            "Original prompt: Question: When did justin bieber perform at madison square garden? Answer:\n",
            "[QA(When did justin bieber perform at madison square garden?) -> In 2015] 2015<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did justin bieber perform at madison square garden? Answer:\n",
            "[QA(When did justin bieber perform at madison square garden?) -> August 31, 2010.] August 31, 2010<|endoftext|>\n",
            "Original: Question: Who sings done for me with charlie puth? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings done for me with charlie puth? Answer:\n",
            "[QA(Who sings done for me with charlie puth?) -> Jason Mraz] Jason Mraz<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings done for me with charlie puth? Answer:\n",
            "[QA(Who sings done for me with charlie puth?) -> Kehlani] Kehlani<|endoftext|>\n",
            "Original: Question: Who did chris long play football for last year? Answer:\n",
            "\n",
            "Original prompt: Question: Who did chris long play football for last year? Answer:\n",
            "[QA(Who did chris long play football for last year?) -> Chris Long played football for the New England Patriots.] New England Patriots<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who did chris long play football for last year? Answer:\n",
            "[QA(Who did chris long play football for last year?) -> Chris Long last played football for the Philadelphia Eagles in 2018.] Philadelphia Eagles<|endoftext|>\n",
            "Original: Question: Starch based food to be made into plastic? Answer:\n",
            "\n",
            "Original prompt: Question: Starch based food to be made into plastic? Answer:\n",
            "[QA(Starch based food to be made into plastic?) -> Starch-based food such as noodles or rice can be made into plastic.] starch<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Starch based food to be made into plastic? Answer:\n",
            "[QA(Starch based food to be made into plastic?) -> Potatoes, corn, rice, wheat.] starch<|endoftext|>\n",
            "Original: Question: When is it revealed that luke and leia are siblings? Answer:\n",
            "\n",
            "Original prompt: Question: When is it revealed that luke and leia are siblings? Answer:\n",
            "[QA(When is it revealed that luke and leia are siblings?) -> In The Last Jedi.] The Last Jedi<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is it revealed that luke and leia are siblings? Answer:\n",
            "[QA(When is it revealed that luke and leia are siblings?) -> In \"Star Wars: Episode VI – Return of the Jedi\" (1983) it is revealed that Luke and Leia are siblings.] Return of the Jedi (1983)<|endoftext|>\n",
            "Original: Question: How does the oral cavity help the digestive system? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How does the oral cavity help the digestive system? Answer:\n",
            "The oral cavity helps the digestive system by allowing the digestive system to break down food.<|endoftext|>\n",
            "Generated: Question: How does the oral cavity help the digestive system? Answer:\n",
            "The oral cavity helps the digestive system by allowing the digestive system to break down food.<|endoftext|>\n",
            "Original: Question: When will new tappan zee bridge be completed? Answer:\n",
            "\n",
            "Original prompt: Question: When will new tappan zee bridge be completed? Answer:\n",
            "[QA(When will new tappan zee bridge be completed?) -> The new Tappan Zee Bridge is expected to be completed in 2021.] 2021<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When will new tappan zee bridge be completed? Answer:\n",
            "[QA(When will new tappan zee bridge be completed?) -> The new Tappan Zee Bridge, renamed as the Governor Mario M. Cuomo Bridge, was officially completed in September 2018.] September 2018<|endoftext|>\n",
            "Original: Question: Who does jessica marry in the merchant of venice? Answer:\n",
            "\n",
            "Original prompt: Question: Who does jessica marry in the merchant of venice? Answer:\n",
            "[QA(Who does jessica marry in the merchant of venice?) -> The Merchant of Venice] Antonio and Bassanio<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who does jessica marry in the merchant of venice? Answer:\n",
            "[QA(Who does jessica marry in the merchant of venice?) -> Jessica marries Lorenzo in The Merchant of Venice.] Lorenzo<|endoftext|>\n",
            "Original: Question: Who does patrick stewart play in star trek? Answer:\n",
            "\n",
            "Original prompt: Question: Who does patrick stewart play in star trek? Answer:\n",
            "[QA(Who does patrick stewart play in star trek?) -> Patrick Stewart] Patrick Stewart<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who does patrick stewart play in star trek? Answer:\n",
            "[QA(Who does patrick stewart play in star trek?) -> Patrick Stewart plays Captain Jean-Luc Picard in Star Trek.] Patrick Stewart<|endoftext|>\n",
            "Original: Question: Who began the mass printing of bibles five centuries ago? Answer:\n",
            "\n",
            "Original prompt: Question: Who began the mass printing of bibles five centuries ago? Answer:\n",
            "[QA(Who began the mass printing of bibles five centuries ago?) -> Gutenberg] Gutenberg<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who began the mass printing of bibles five centuries ago? Answer:\n",
            "[QA(Who began the mass printing of bibles five centuries ago?) -> Johannes Gutenberg] Johannes Gutenberg<|endoftext|>\n",
            "Original: Question: What are the two main political parties in france? Answer:\n",
            "\n",
            "Original prompt: Question: What are the two main political parties in france? Answer:\n",
            "[QA(What are the two main political parties in france?) -> The two main political parties in France are called the Socialist Party of France and the Union for a Popular Movement.] Socialist Party of France, Union for a Popular Movement<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What are the two main political parties in france? Answer:\n",
            "[QA(What are the two main political parties in france?) -> La République En Marche! and The Republicans] La République En Marche! and The Republicans<|endoftext|>\n",
            "Original: Question: When did apple computer change to apple inc? Answer:\n",
            "\n",
            "Original prompt: Question: When did apple computer change to apple inc? Answer:\n",
            "[QA(When did apple computer change to apple inc?) -> June 1976] 1976<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did apple computer change to apple inc? Answer:\n",
            "[QA(When did apple computer change to apple inc?) -> January 9, 2007] January 9, 2007<|endoftext|>\n",
            "Original: Question: When did the olympics start every 2 years? Answer: \n",
            "\n",
            "Original prompt: Question: When did the olympics start every 2 years? Answer: \n",
            "[QA(When did the olympics start every 2 years?) -> 1932] 1932<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the olympics start every 2 years? Answer: \n",
            "[QA(When did the olympics start every 2 years?) -> 1994] 1994<|endoftext|>\n",
            "Original: Question: Who wrote the song i drive your truck? Answer: \n",
            "\n",
            "Original prompt: Question: Who wrote the song i drive your truck? Answer: \n",
            "[QA(Who wrote the song i drive your truck?) -> Tom Petty and the Heartbreakers] Tom Petty and the Heartbreakers<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the song i drive your truck? Answer: \n",
            "[QA(Who wrote the song i drive your truck?) -> Jessi Alexander, Connie Harrington and Jimmy Yeary.] Connie Harrington, Jessi Alexander and Jimmy Yeary<|endoftext|>\n",
            "Original: Question: Who played freddy krueger in the 2010 nightmare on elm street? Answer:\n",
            "\n",
            "Original prompt: Question: Who played freddy krueger in the 2010 nightmare on elm street? Answer:\n",
            "[QA(Who played freddy krueger in the 2010 nightmare on elm street?) -> Fred Krueger] Freddy Krueger<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played freddy krueger in the 2010 nightmare on elm street? Answer:\n",
            "[QA(Who played freddy krueger in the 2010 nightmare on elm street?) -> Jackie Earle Haley] Jackie Earle Haley<|endoftext|>\n",
            "Original: Question: Who explored the west coast of north america? Answer:\n",
            "\n",
            "Original prompt: Question: Who explored the west coast of north america? Answer:\n",
            "[QA(Who explored the west coast of north america?) -> John Cabot] John Cabot<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who explored the west coast of north america? Answer:\n",
            "[QA(Who explored the west coast of north america?) -> Juan Rodriguez Cabrillo and James Cook.] Juan Rodriguez Cabrillo and James Cook<|endoftext|>\n",
            "Original: Question: When is the next episode of flash going to air? Answer:\n",
            "\n",
            "Original prompt: Question: When is the next episode of flash going to air? Answer:\n",
            "[QA(When is the next episode of flash going to air?) -> The next episode of \"Flash\" will be aired on October 2, 2017.] October 2, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is the next episode of flash going to air? Answer:\n",
            "[QA(When is the next episode of flash going to air?) -> As an AI, I cannot provide real-time information or updates. Please check the latest schedule on the network's official website or other trusted TV show platforms.] the next episode of flash<|endoftext|>\n",
            "Original: Question: Who played jimmy in high school musical 3? Answer:\n",
            "\n",
            "Original prompt: Question: Who played jimmy in high school musical 3? Answer:\n",
            "[QA(Who played jimmy in high school musical 3?) -> Zac Efron] Zac Efron<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played jimmy in high school musical 3? Answer:\n",
            "[QA(Who played jimmy in high school musical 3?) -> Matt Prokop] Matt Prokop<|endoftext|>\n",
            "Original: Question: Who introduced the concept of providing alu in the computer system? Answer:\n",
            "\n",
            "Original prompt: Question: Who introduced the concept of providing alu in the computer system? Answer:\n",
            "[QA(Who introduced the concept of providing alu in the computer system?) -> John W. Backus] John W. Backus<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who introduced the concept of providing alu in the computer system? Answer:\n",
            "[QA(Who introduced the concept of providing alu in the computer system?) -> John von Neumann] John von Neumann<|endoftext|>\n",
            "Original: Question: When did the original my little pony come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the original my little pony come out? Answer:\n",
            "[QA(When did the original my little pony come out?) -> \"My Little Pony: Friendship is Magic\" came out in 2014.] 2014<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the original my little pony come out? Answer:\n",
            "[QA(When did the original my little pony come out?) -> 1983] 1983<|endoftext|>\n",
            "Original: Question: What is the school in dead poets society? Answer:\n",
            "\n",
            "Original prompt: Question: What is the school in dead poets society? Answer:\n",
            "[QA(What is the school in dead poets society?) -> The school in Dead Poets Society is the fictional school that John Keating and his classmates attend in the movie Dead Poets Society.] John Keating<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the school in dead poets society? Answer:\n",
            "[QA(What is the school in dead poets society?) -> Welton Academy] Welton Academy<|endoftext|>\n",
            "Original: Question: Which is the state flower of himachal pradesh? Answer:\n",
            "\n",
            "Original prompt: Question: Which is the state flower of himachal pradesh? Answer:\n",
            "[QA(Which is the state flower of himachal pradesh?) -> Tulsi] Tulsi<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which is the state flower of himachal pradesh? Answer:\n",
            "[QA(Which is the state flower of himachal pradesh?) -> Pink Rhododendron] Pink Rhododendron<|endoftext|>\n",
            "Original: Question: Who sang since you've been gone by rainbow? Answer:\n",
            "\n",
            "Original prompt: Question: Who sang since you've been gone by rainbow? Answer:\n",
            "[QA(Who sang since you've been gone by rainbow?) -> Mariah Carey] Mariah Carey<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sang since you've been gone by rainbow? Answer:\n",
            "[QA(Who sang since you've been gone by rainbow?) -> Graham Bonnet] Graham Bonnet<|endoftext|>\n",
            "Original: Question: Who played the mother on the partridge family? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the mother on the partridge family? Answer:\n",
            "[QA(Who played the mother on the partridge family?) -> Ann B. Davis] Ann B. Davis<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the mother on the partridge family? Answer:\n",
            "[QA(Who played the mother on the partridge family?) -> Shirley Jones] Shirley Jones<|endoftext|>\n",
            "Original: Question: Who is the highest goal scorer in the epl? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the highest goal scorer in the epl? Answer:\n",
            "[QA(Who is the highest goal scorer in the epl?) -> Alan Shearer] Alan Shearer<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the highest goal scorer in the epl? Answer:\n",
            "[QA(Who is the highest goal scorer in the epl?) -> As of February 2022, Alan Shearer is the highest goal scorer in the EPL.] Alan Shearer<|endoftext|>\n",
            "Original: Question: Who is next in line for the royal throne of england? Answer:\n",
            "\n",
            "Original prompt: Question: Who is next in line for the royal throne of england? Answer:\n",
            "[QA(Who is next in line for the royal throne of england?) -> King Edward VIII] Edward VIII<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is next in line for the royal throne of england? Answer:\n",
            "[QA(Who is next in line for the royal throne of england?) -> Prince Charles] Charles, Prince of Wales<|endoftext|>\n",
            "Original: Question: How many cities of refuge were the israelites to form? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many cities of refuge were the israelites to form? Answer:\n",
            "[Calculator(5-1)]=4 thus answer is 4 (cities of refuge).<|endoftext|>\n",
            "Computed answer was: 4.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many cities of refuge were the israelites to form? Answer:\n",
            "[Calculator(5-1)]=4.0 thus answer is 4 (cities of refuge).<|endoftext|>\n",
            "Original: Question: Who played the oompa loompas in charlie and the chocolate factory? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the oompa loompas in charlie and the chocolate factory? Answer:\n",
            "[QA(Who played the oompa loompas in charlie and the chocolate factory?) -> The Oompa-Loompas were played by a group of South African puppeteers known as the Khumba Group.] the Khumba Group<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the oompa loompas in charlie and the chocolate factory? Answer:\n",
            "[QA(Who played the oompa loompas in charlie and the chocolate factory?) -> Deep Roy] Deep Roy<|endoftext|>\n",
            "Original: Question: What is the real name of sleeping beauty? Answer:\n",
            "\n",
            "Original prompt: Question: What is the real name of sleeping beauty? Answer:\n",
            "[QA(What is the real name of sleeping beauty?) -> \"Sleeping Beauty\"] Sleeping Beauty<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the real name of sleeping beauty? Answer:\n",
            "[QA(What is the real name of sleeping beauty?) -> Aurora] Aurora<|endoftext|>\n",
            "Original: Question: Who sings the song save a horse ride a cowboy? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings the song save a horse ride a cowboy? Answer:\n",
            "[QA(Who sings the song save a horse ride a cowboy?) -> Lee Greenwood] Lee Greenwood<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings the song save a horse ride a cowboy? Answer:\n",
            "[QA(Who sings the song save a horse ride a cowboy?) -> Big & Rich] Big & Rich<|endoftext|>\n",
            "Original: Question: The centers of most cities became business areas after the invention of what? Answer:\n",
            "\n",
            "Original prompt: Question: The centers of most cities became business areas after the invention of what? Answer:\n",
            "[QA(The centers of most cities became business areas after the invention of what?) -> The centers of most cities became business areas after the invention of the printing press.] the printing press<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The centers of most cities became business areas after the invention of what? Answer:\n",
            "[QA(The centers of most cities became business areas after the invention of what?) -> Automobile] Automobile<|endoftext|>\n",
            "Original: Question: What episode of the flash is crisis on earth x? Answer:\n",
            "\n",
            "Original prompt: Question: What episode of the flash is crisis on earth x? Answer:\n",
            "[QA(What episode of the flash is crisis on earth x?) -> \"Crisis on Earth-X\"] \"Crisis on Earth-X\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What episode of the flash is crisis on earth x? Answer:\n",
            "[QA(What episode of the flash is crisis on earth x?) -> The Flash Season 4, Episode 8.] The Flash Season 4, Episode 8<|endoftext|>\n",
            "Original: Question: Who plays al pacino in jack and jill? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays al pacino in jack and jill? Answer:\n",
            "[QA(Who plays al pacino in jack and jill?) -> Al Pacino] Al Pacino<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays al pacino in jack and jill? Answer:\n",
            "[QA(Who plays al pacino in jack and jill?) -> Al Pacino plays himself in Jack and Jill.] Al Pacino<|endoftext|>\n",
            "Original: Question: Who ruled the ottoman empire at its height in about 1550? Answer:\n",
            "\n",
            "Original prompt: Question: Who ruled the ottoman empire at its height in about 1550? Answer:\n",
            "[QA(Who ruled the ottoman empire at its height in about 1550?) -> Suleyman the Magnificent] Suleyman the Magnificent<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who ruled the ottoman empire at its height in about 1550? Answer:\n",
            "[QA(Who ruled the ottoman empire at its height in about 1550?) -> Suleiman the Magnificent] Suleiman the Magnificent<|endoftext|>\n",
            "Original: Question: How much does it cost to renew a cuban passport? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How much does it cost to renew a cuban passport? Answer:\n",
            "[Calculator(2*40)]=80 thus answer is 80 (dollars).<|endoftext|>\n",
            "Computed answer was: 80.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How much does it cost to renew a cuban passport? Answer:\n",
            "[Calculator(2*40)]=80.0 thus answer is 80.0 (dollars).<|endoftext|>\n",
            "Original: Question: Who won the last triple crown in baseball? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the last triple crown in baseball? Answer:\n",
            "[QA(Who won the last triple crown in baseball?) -> Barry Bonds] Barry Bonds<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the last triple crown in baseball? Answer:\n",
            "[QA(Who won the last triple crown in baseball?) -> Miguel Cabrera won the last triple crown in baseball in 2012.] Miguel Cabrera<|endoftext|>\n",
            "Original: Question: How many pages is the forest of hands and teeth? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many pages is the forest of hands and teeth? Answer:\n",
            "[Calculator(1+2)]=3 thus answer is 3 (pages).<|endoftext|>\n",
            "Computed answer was: 3.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many pages is the forest of hands and teeth? Answer:\n",
            "[Calculator(1+2)]=3.0 thus answer is 3 (pages).<|endoftext|>\n",
            "Original: Question: When is the last time scotland were in the world cup? Answer:\n",
            "\n",
            "Original prompt: Question: When is the last time scotland were in the world cup? Answer:\n",
            "[QA(When is the last time scotland were in the world cup?) -> 2018] 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is the last time scotland were in the world cup? Answer:\n",
            "[QA(When is the last time scotland were in the world cup?) -> 1998] 1998<|endoftext|>\n",
            "Original: Question: Who has won more oscars then anyone else? Answer:\n",
            "\n",
            "Original prompt: Question: Who has won more oscars then anyone else? Answer:\n",
            "[QA(Who has won more oscars then anyone else?) -> The Academy of Motion Pictures Arts and Sciences] The Academy of Motion Pictures Arts and Sciences<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has won more oscars then anyone else? Answer:\n",
            "[QA(Who has won more oscars then anyone else?) -> Walt Disney] Walt Disney<|endoftext|>\n",
            "Original: Question: When did the lyrics to o canada change? Answer:\n",
            "\n",
            "Original prompt: Question: When did the lyrics to o canada change? Answer:\n",
            "[QA(When did the lyrics to o canada change?) -> The lyrics to \"O Canada\" changed in 1995.] 1995<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the lyrics to o canada change? Answer:\n",
            "[QA(When did the lyrics to o canada change?) -> In February 2018.] February 2018<|endoftext|>\n",
            "Original: Question: Who ran the first sub 4 minute mile? Answer:\n",
            "\n",
            "Original prompt: Question: Who ran the first sub 4 minute mile? Answer:\n",
            "[QA(Who ran the first sub 4 minute mile?) -> Roger Bannister] Roger Bannister<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who ran the first sub 4 minute mile? Answer:\n",
            "[QA(Who ran the first sub 4 minute mile?) -> Roger Bannister] Roger Bannister<|endoftext|>\n",
            "Original: Question: Who plays rebecca in bridget jones edge of reason? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays rebecca in bridget jones edge of reason? Answer:\n",
            "[QA(Who plays rebecca in bridget jones edge of reason?) -> AnnaSophia Robb] AnnaSophia Robb<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays rebecca in bridget jones edge of reason? Answer:\n",
            "[QA(Who plays rebecca in bridget jones edge of reason?) -> Jacinda Barrett] Jacinda Barrett<|endoftext|>\n",
            "Original: Question: When does new season of first 48 start? Answer:\n",
            "\n",
            "Original prompt: Question: When does new season of first 48 start? Answer:\n",
            "[QA(When does new season of first 48 start?) -> The new season of First 48 starts on January 13, 2018.] January 13, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does new season of first 48 start? Answer:\n",
            "[QA(When does new season of first 48 start?) -> The release dates for new seasons of The First 48 can vary and are typically announced by A&E network. Check their official website or news for the latest updates.] September 18, 2017<|endoftext|>\n",
            "Original: Question: What is the dog called in midsomer murders? Answer:\n",
            "\n",
            "Original prompt: Question: What is the dog called in midsomer murders? Answer:\n",
            "[QA(What is the dog called in midsomer murders?) -> The name of the dog in \"Midsomer Murders\" is Lassie.] Lassie<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the dog called in midsomer murders? Answer:\n",
            "[QA(What is the dog called in midsomer murders?) -> Sykes] Sykes<|endoftext|>\n",
            "Original: Question: Who won the first academy award for best picture? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the first academy award for best picture? Answer:\n",
            "[QA(Who won the first academy award for best picture?) -> The first Academy Award for Best Picture was won by \"Wizard of Oz\" in 1939.] \"Wizard of Oz\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the first academy award for best picture? Answer:\n",
            "[QA(Who won the first academy award for best picture?) -> \"Wings\"] the first Academy Award for best picture was awarded to \"Wings\" in 1929.<|endoftext|>\n",
            "Original: Question: When did wrath of the lich king release? Answer:\n",
            "\n",
            "Original prompt: Question: When did wrath of the lich king release? Answer:\n",
            "[QA(When did wrath of the lich king release?) -> April 21, 2018] April 21, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did wrath of the lich king release? Answer:\n",
            "[QA(When did wrath of the lich king release?) -> November 13, 2008] November 13, 2008<|endoftext|>\n",
            "Original: Question: When do we need to revisit bcp plan and strategy? Answer:\n",
            "\n",
            "Original prompt: Question: When do we need to revisit bcp plan and strategy? Answer:\n",
            "[QA(When do we need to revisit bcp plan and strategy?) -> BCP plans and strategies are reviewed every 5 years.] 5 years<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When do we need to revisit bcp plan and strategy? Answer:\n",
            "[QA(When do we need to revisit bcp plan and strategy?) -> BCP (Business Continuity Plan) and strategy should be revisited when there is a significant change in a business operation, after a disaster has occurred, or on a regular annual or biannual basis.] the answer is on a regular annual or biannual basis.<|endoftext|>\n",
            "Original: Question: Where is most of earths fresh water located? Answer:\n",
            "\n",
            "Original prompt: Question: Where is most of earths fresh water located? Answer:\n",
            "[QA(Where is most of earths fresh water located?) -> Most of earth's fresh water is located in the oceans.] oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans, oceans,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is most of earths fresh water located? Answer:\n",
            "[QA(Where is most of earths fresh water located?) -> Most of Earth's fresh water is located in ice caps and glaciers.] the polar ice caps and glaciers<|endoftext|>\n",
            "Original: Question: How many episodes are there in the tv series yellowstone? Answer:\n",
            "\n",
            "Original prompt: Question: How many episodes are there in the tv series yellowstone? Answer:\n",
            "[QA(How many episodes are there in the tv series yellowstone?) -> The number of episodes in the TV series YellowStone varies from season to season. In the first season, there are 12 episodes. In the second season, there are 16 episodes. In the third season, there are 20 episodes. In the fourth season, there are 22 episodes. In the fifth season, there are 26 episodes. In the sixth season, there are 28 episodes. In the seventh season, there are 30 episodes. In the eighth season, there are 32 episodes. In the ninth season, there are 34 episodes. In the tenth season, there are 36 episodes. In the eleventh season, there are 38 episodes. In the twelfth season, there are 40 episodes. In the thirteenth season, there are 42 episodes. In the fourteenth season, there are 44 episodes. In the fifteenth season, there are 46 episodes. In the sixteenth season, there are 48 episodes. In the seventeenth season, there are 50 episodes. In the eighteenth season, there are 52 episodes. In the nineteenth season, there are 54 episodes. In the twentieth season, there are 56\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many episodes are there in the tv series yellowstone? Answer:\n",
            "[QA(How many episodes are there in the tv series yellowstone?) -> 39] 39<|endoftext|>\n",
            "Original: Question: The first collaboration of richard rodgers and oscar hammerstein ii was? Answer:\n",
            "\n",
            "Original prompt: Question: The first collaboration of richard rodgers and oscar hammerstein ii was? Answer:\n",
            "[QA(The first collaboration of richard rodgers and oscar hammerstein ii was?) -> The first collaboration of richard rodgers and oscar hammerstein ii was \"showboat\"] \"showboat\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The first collaboration of richard rodgers and oscar hammerstein ii was? Answer:\n",
            "[QA(The first collaboration of richard rodgers and oscar hammerstein ii was?) -> Oklahoma!] Oklahoma!<|endoftext|>\n",
            "Original: Question: When was the last province added to canada? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last province added to canada? Answer:\n",
            "[QA(When was the last province added to canada?) -> On July 1, 1949] July 1, 1949<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last province added to canada? Answer:\n",
            "[QA(When was the last province added to canada?) -> Newfoundland and Labrador on March 31, 1949.] October 1, 1949<|endoftext|>\n",
            "Original: Question: Which nation was not part of the united nations allied military force in korea? Answer:\n",
            "\n",
            "Original prompt: Question: Which nation was not part of the united nations allied military force in korea? Answer:\n",
            "[QA(Which nation was not part of the united nations allied military force in korea?) -> South Korea] South Korea<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which nation was not part of the united nations allied military force in korea? Answer:\n",
            "[QA(Which nation was not part of the united nations allied military force in korea?) -> The Soviet Union.] Soviet Union<|endoftext|>\n",
            "Original: Question: The optic nerve is known also as what cranial nerve? Answer:\n",
            "\n",
            "Original prompt: Question: The optic nerve is known also as what cranial nerve? Answer:\n",
            "[QA(The optic nerve is known also as what cranial nerve?) -> optic nerve] optic nerve<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The optic nerve is known also as what cranial nerve? Answer:\n",
            "[QA(The optic nerve is known also as what cranial nerve?) -> The optic nerve is known as the second cranial nerve, or cranial nerve II.] Optic nerve<|endoftext|>\n",
            "Original: Question: Which second messenger molecule acts on the endoplasmic reticulum to release calcium ions? Answer:\n",
            "\n",
            "Original prompt: Question: Which second messenger molecule acts on the endoplasmic reticulum to release calcium ions? Answer:\n",
            "[QA(Which second messenger molecule acts on the endoplasmic reticulum to release calcium ions?) -> inositol 1,4,5-trisphosphate] inositol 1,4,5-trisphosphate<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which second messenger molecule acts on the endoplasmic reticulum to release calcium ions? Answer:\n",
            "[QA(Which second messenger molecule acts on the endoplasmic reticulum to release calcium ions?) -> Inositol trisphosphate (IP3)] inositol 1,4,5-trisphosphate<|endoftext|>\n",
            "Original: Question: When did the story to kill a mockingbird take place? Answer:\n",
            "\n",
            "Original prompt: Question: When did the story to kill a mockingbird take place? Answer:\n",
            "[QA(When did the story to kill a mockingbird take place?) -> 1944] 1944<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the story to kill a mockingbird take place? Answer:\n",
            "[QA(When did the story to kill a mockingbird take place?) -> The story \"To Kill a Mockingbird\" takes place in the mid-1930s.] the 1930s<|endoftext|>\n",
            "Original: Question: Who is chips voice in beauty and the beast? Answer:\n",
            "\n",
            "Original prompt: Question: Who is chips voice in beauty and the beast? Answer:\n",
            "[QA(Who is chips voice in beauty and the beast?) -> Chips is the voice of the Beast in Beauty and the Beast.] Chips<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is chips voice in beauty and the beast? Answer:\n",
            "[QA(Who is chips voice in beauty and the beast?) -> Bradley Pierce] Bradley Pierce<|endoftext|>\n",
            "Original: Question: The type of decent that explains why all species are linked in a single tree of life? Answer:\n",
            "\n",
            "Original prompt: Question: The type of decent that explains why all species are linked in a single tree of life? Answer:\n",
            "[QA(The type of decent that explains why all species are linked in a single tree of life?) -> phylogeny] phylogeny<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The type of decent that explains why all species are linked in a single tree of life? Answer:\n",
            "[QA(The type of decent that explains why all species are linked in a single tree of life?) -> Common descent] common descent<|endoftext|>\n",
            "Original: Question: Who has the longest winning streak in ufc? Answer:\n",
            "\n",
            "Original prompt: Question: Who has the longest winning streak in ufc? Answer:\n",
            "[QA(Who has the longest winning streak in ufc?) -> Frank Mir] Frank Mir<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has the longest winning streak in ufc? Answer:\n",
            "[QA(Who has the longest winning streak in ufc?) -> Anderson Silva has the longest winning streak in UFC.] Anderson Silva<|endoftext|>\n",
            "Original: Question: When does the reboot of charmed come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does the reboot of charmed come out? Answer:\n",
            "[QA(When does the reboot of charmed come out?) -> The reboot of charmed comes out in 2018.] December 21, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does the reboot of charmed come out? Answer:\n",
            "[QA(When does the reboot of charmed come out?) -> The reboot of Charmed premiered on October 14, 2018.] October 14, 2018<|endoftext|>\n",
            "Original: Question: What was the inaugural year of the ncaa tournament? Answer:\n",
            "\n",
            "Original prompt: Question: What was the inaugural year of the ncaa tournament? Answer:\n",
            "[QA(What was the inaugural year of the ncaa tournament?) -> 1994] 1994<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the inaugural year of the ncaa tournament? Answer:\n",
            "[QA(What was the inaugural year of the ncaa tournament?) -> 1939] 1939<|endoftext|>\n",
            "Original: Question: What do you call someone from czech republic? Answer:\n",
            "\n",
            "Original prompt: Question: What do you call someone from czech republic? Answer:\n",
            "[QA(What do you call someone from czech republic?) -> Czech] Czech<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What do you call someone from czech republic? Answer:\n",
            "[QA(What do you call someone from czech republic?) -> Czech] Czech<|endoftext|>\n",
            "Original: Question: The lowest possible energy level for an electron is known as? Answer:\n",
            "\n",
            "Original prompt: Question: The lowest possible energy level for an electron is known as? Answer:\n",
            "[QA(The lowest possible energy level for an electron is known as?) -> the ground state] the ground state<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The lowest possible energy level for an electron is known as? Answer:\n",
            "[QA(The lowest possible energy level for an electron is known as?) -> Ground state] the ground state<|endoftext|>\n",
            "Original: Question: When did the first ipod video come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the first ipod video come out? Answer:\n",
            "[QA(When did the first ipod video come out?) -> October 23, 2001] October 23, 2001<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the first ipod video come out? Answer:\n",
            "[QA(When did the first ipod video come out?) -> October 2005] October 2005<|endoftext|>\n",
            "Original: Question: When is game of thrones next book coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is game of thrones next book coming out? Answer:\n",
            "[QA(When is game of thrones next book coming out?) -> The next book in the Game of Thrones series is called The Winds of Winter. It will be released in December 2017.] December 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is game of thrones next book coming out? Answer:\n",
            "[QA(When is game of thrones next book coming out?) -> As of now, there is no confirmed release date for the next Game of Thrones book.] October 8, 2017<|endoftext|>\n",
            "Original: Question: When did the first cell phone with a camera come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the first cell phone with a camera come out? Answer:\n",
            "[QA(When did the first cell phone with a camera come out?) -> In the 1970s] the 1970s<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the first cell phone with a camera come out? Answer:\n",
            "[QA(When did the first cell phone with a camera come out?) -> In 2000.] October 2000<|endoftext|>\n",
            "Original: Question: The individual best known for his work on behavior theory is? Answer:\n",
            "\n",
            "Original prompt: Question: The individual best known for his work on behavior theory is? Answer:\n",
            "[QA(The individual best known for his work on behavior theory is?) -> Edward Thorndike] Edward Thorndike<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The individual best known for his work on behavior theory is? Answer:\n",
            "[QA(The individual best known for his work on behavior theory is?) -> B.F. Skinner] B.F. Skinner<|endoftext|>\n",
            "Original: Question: Who won the popular vote in 2012 us presidential election? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the popular vote in 2012 us presidential election? Answer:\n",
            "[QA(Who won the popular vote in 2012 us presidential election?) -> The popular vote was won by Barack Obama.] Barack Obama<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the popular vote in 2012 us presidential election? Answer:\n",
            "[QA(Who won the popular vote in 2012 us presidential election?) -> Barack Obama] Barack Obama<|endoftext|>\n",
            "Original: Question: What is the cast of big bang theory paid? Answer:\n",
            "\n",
            "Original prompt: Question: What is the cast of big bang theory paid? Answer:\n",
            "[QA(What is the cast of big bang theory paid?) -> The cast of big bang theory is paid a total of $1.5 million.] $1.5 million<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the cast of big bang theory paid? Answer:\n",
            "[QA(What is the cast of big bang theory paid?) -> The main cast members were paid $1 million per episode in the final seasons.] $1 million<|endoftext|>\n",
            "Original: Question: When did the price is right first air? Answer:\n",
            "\n",
            "Original prompt: Question: When did the price is right first air? Answer:\n",
            "[QA(When did the price is right first air?) -> October 9, 1962] October 9, 1962<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the price is right first air? Answer:\n",
            "[QA(When did the price is right first air?) -> September 4, 1972] September 4, 1972<|endoftext|>\n",
            "Original: Question: Where did ac/dc get their band name? Answer:\n",
            "\n",
            "Original prompt: Question: Where did ac/dc get their band name? Answer:\n",
            "[QA(Where did ac/dc get their band name?) -> \"AC/DC\" got their band name from a combination of the first letters of the names of the band's founders, Angus Young and Malcolm Young, and the last letters of the names of the band's members, Bon Scott, Phil Rudd, and Brian Johnson.] \"AC/DC\" got their band name from a combination of the first letters of the names of the band's founders, Angus Young and Malcolm Young, and the last letters of the names of the band's members, Bon Scott, Phil Rudd, and Brian Johnson.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did ac/dc get their band name? Answer:\n",
            "[QA(Where did ac/dc get their band name?) -> From a label on a sewing machine, which indicated the electrical current as \"AC/DC\".] the sewing machine<|endoftext|>\n",
            "Original: Question: Star cast of kuch tum kaho kuch hum kahein? Answer:\n",
            "\n",
            "Original prompt: Question: Star cast of kuch tum kaho kuch hum kahein? Answer:\n",
            "[QA(Star cast of kuch tum kaho kuch hum kahein?) -> Sanjay Dutt, Juhi Chawla, Saif Ali Khan, Kareena Kapoor, Kunal Kapoor, Bipasha Basu, Sonali Bendre, Raveena Tandon, Amrita Singh, Shilpa Shirodkar, Mahima Chaudhry, Poonam Dhillon, Neelima Azeem]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Star cast of kuch tum kaho kuch hum kahein? Answer:\n",
            "[QA(Star cast of kuch tum kaho kuch hum kahein?) -> Fardeen Khan, Richa Pallod, Farida Jalal, Govind Namdeo.] Fardeen Khan, Richa Pallod, Farida Jalal, Govind Namdeo<|endoftext|>\n",
            "Original: Question: Where did frasier go in the last episode? Answer:\n",
            "\n",
            "Original prompt: Question: Where did frasier go in the last episode? Answer:\n",
            "[QA(Where did frasier go in the last episode?) -> In the last episode of \"Frasier,\" Frasier and his father went on a vacation.] the Bahamas<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did frasier go in the last episode? Answer:\n",
            "[QA(Where did frasier go in the last episode?) -> Frasier went to Chicago in the last episode.] Chicago<|endoftext|>\n",
            "Original: Question: What is the theme of midnight in paris? Answer:\n",
            "\n",
            "Original prompt: Question: What is the theme of midnight in paris? Answer:\n",
            "[QA(What is the theme of midnight in paris?) -> Midnight in Paris is a 2015 romantic comedy film.] Midnight in Paris<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the theme of midnight in paris? Answer:\n",
            "[QA(What is the theme of midnight in paris?) -> Nostalgia and the romanticization of the past.] Nostalgia and the romanticization of the past<|endoftext|>\n",
            "Original: Question: Minimum age to contest for president in nigeria? Answer:\n",
            "\n",
            "Original prompt: Question: Minimum age to contest for president in nigeria? Answer:\n",
            "[QA(Minimum age to contest for president in nigeria?) -> 18 years old] 18 years old<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Minimum age to contest for president in nigeria? Answer:\n",
            "[QA(Minimum age to contest for president in nigeria?) -> 40 years] 40<|endoftext|>\n",
            "Original: Question: When was the first episode of charmed aired? Answer:\n",
            "\n",
            "Original prompt: Question: When was the first episode of charmed aired? Answer:\n",
            "[QA(When was the first episode of charmed aired?) -> October 9, 1998] 1998<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the first episode of charmed aired? Answer:\n",
            "[QA(When was the first episode of charmed aired?) -> October 7, 1998] October 7, 1998<|endoftext|>\n",
            "Original: Question: Where was tears dry on their own filmed? Answer:\n",
            "\n",
            "Original prompt: Question: Where was tears dry on their own filmed? Answer:\n",
            "[QA(Where was tears dry on their own filmed?) -> Tears Dry on Their Own was filmed in the Canary Islands.] Canary Islands<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where was tears dry on their own filmed? Answer:\n",
            "[QA(Where was tears dry on their own filmed?) -> The music video for \"Tears Dry on Their Own\" by Amy Winehouse was filmed in Los Angeles, California, USA.] Los Angeles<|endoftext|>\n",
            "Original: Question: Who plays pearl in the scarlet letter movie? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays pearl in the scarlet letter movie? Answer:\n",
            "[QA(Who plays pearl in the scarlet letter movie?) -> Winona Ryder] Winona Ryder<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays pearl in the scarlet letter movie? Answer:\n",
            "[QA(Who plays pearl in the scarlet letter movie?) -> Pearl is played by Jodhi May in the 1995 version of \"The Scarlet Letter\" movie.] Jodhi May<|endoftext|>\n",
            "Original: Question: Who was crowned emperor of the west in 800 ce? Answer:\n",
            "\n",
            "Original prompt: Question: Who was crowned emperor of the west in 800 ce? Answer:\n",
            "[QA(Who was crowned emperor of the west in 800 ce?) -> Charlemagne] Charlemagne<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was crowned emperor of the west in 800 ce? Answer:\n",
            "[QA(Who was crowned emperor of the west in 800 ce?) -> Charlemagne] Charlemagne<|endoftext|>\n",
            "Original: Question: Who are the voices on the phone walking dead? Answer:\n",
            "\n",
            "Original prompt: Question: Who are the voices on the phone walking dead? Answer:\n",
            "[QA(Who are the voices on the phone walking dead?) -> The voices on the phone walking dead are the voices of various characters on the show, including Daryl, Michonne, and Tyreese.] Daryl, Michonne, and Tyreese<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who are the voices on the phone walking dead? Answer:\n",
            "[QA(Who are the voices on the phone walking dead?) -> The voices on the phone in The Walking Dead are hallucinations of Rick's deceased wife, Lori, and deceased friends Amy, Jim, and Jacqui.] Lori, Amy, Jim, and Jacqui<|endoftext|>\n",
            "Original: Question: Which river takes its name from loess soil? Answer:\n",
            "\n",
            "Original prompt: Question: Which river takes its name from loess soil? Answer:\n",
            "[QA(Which river takes its name from loess soil?) -> The Ganges] Ganges<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which river takes its name from loess soil? Answer:\n",
            "[QA(Which river takes its name from loess soil?) -> Yellow River] the Yellow River<|endoftext|>\n",
            "Original: Question: Who are the players on the nrl trophy? Answer:\n",
            "\n",
            "Original prompt: Question: Who are the players on the nrl trophy? Answer:\n",
            "[QA(Who are the players on the nrl trophy?) -> The players on the nrl trophy are the same as the players on the nrl trophy.] the nrl trophy<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who are the players on the nrl trophy? Answer:\n",
            "[QA(Who are the players on the nrl trophy?) -> The players on the NRL trophy are not specific individuals. The trophy features two generic figures representing rugby league players.] the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl trophy, the players on the nrl<|endoftext|>\n",
            "Original: Question: Who are the chefs on america's test kitchen? Answer:\n",
            "\n",
            "Original prompt: Question: Who are the chefs on america's test kitchen? Answer:\n",
            "[QA(Who are the chefs on america's test kitchen?) -> The chefs on America's Test Kitchen are a group of professional cooks who develop and test recipes for the television show.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who are the chefs on america's test kitchen? Answer:\n",
            "[QA(Who are the chefs on america's test kitchen?) -> As of 2022, the main chefs on America's Test Kitchen are Julia Collin Davison and Bridget Lancaster.] Julia Collin Davison, Bridget Lancaster<|endoftext|>\n",
            "Original: Question: When was the last time germany lost world cup? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last time germany lost world cup? Answer:\n",
            "[QA(When was the last time germany lost world cup?) -> 2006] 2006<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last time germany lost world cup? Answer:\n",
            "[QA(When was the last time germany lost world cup?) -> 2018] 2018<|endoftext|>\n",
            "Original: Question: Who played the lone ranger in the 1950s? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the lone ranger in the 1950s? Answer:\n",
            "[QA(Who played the lone ranger in the 1950s?) -> Lee Majors] Lee Majors<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the lone ranger in the 1950s? Answer:\n",
            "[QA(Who played the lone ranger in the 1950s?) -> Clayton Moore] Clayton Moore<|endoftext|>\n",
            "Original: Question: Who discovered sandwich (now hawaiian) isles? Answer:\n",
            "\n",
            "Original prompt: Question: Who discovered sandwich (now hawaiian) isles? Answer:\n",
            "[QA(Who discovered sandwich (now hawaiian) isles?) -> Christopher Columbus] Christopher Columbus<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who discovered sandwich (now hawaiian) isles? Answer:\n",
            "[QA(Who discovered sandwich (now hawaiian) isles?) -> James Cook] James Cook<|endoftext|>\n",
            "Original: Question: Who runs the fastest 40-yard dash in the nfl? Answer:\n",
            "\n",
            "Original prompt: Question: Who runs the fastest 40-yard dash in the nfl? Answer:\n",
            "[QA(Who runs the fastest 40-yard dash in the nfl?) -> Ezekiel Elliott] Ezekiel Elliott<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who runs the fastest 40-yard dash in the nfl? Answer:\n",
            "[QA(Who runs the fastest 40-yard dash in the nfl?) -> John Ross III] John Ross III<|endoftext|>\n",
            "Original: Question: When was the internet invented for home use? Answer:\n",
            "\n",
            "Original prompt: Question: When was the internet invented for home use? Answer:\n",
            "[QA(When was the internet invented for home use?) -> 1972] 1972<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the internet invented for home use? Answer:\n",
            "[QA(When was the internet invented for home use?) -> The internet became available for home use in the late 1980s and early 1990s.] the late 1980s and early 1990s<|endoftext|>\n",
            "Original: Question: Who has most superbowl wins afc or nfc? Answer:\n",
            "\n",
            "Original prompt: Question: Who has most superbowl wins afc or nfc? Answer:\n",
            "[QA(Who has most superbowl wins afc or nfc?) -> AFC] Indianapolis Colts<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has most superbowl wins afc or nfc? Answer:\n",
            "[QA(Who has most superbowl wins afc or nfc?) -> NFC] The San Francisco 49ers, the Green Bay Packers, the Pittsburgh Steelers, the New England Patriots, the Philadelphia Eagles, the Chicago Bears, the Denver Broncos, the Kansas City Chiefs, the Los Angeles Rams, the Minnesota Vikings, the New Orleans Saints, the New York Giants, the Oakland Raiders, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle Seahawks, the Tampa Bay Buccaneers, the Tennessee Titans, the Washington Redskins, the Carolina Panthers, the Dallas Cowboys, the Houston Texans, the Indianapolis Colts, the Jacksonville Jaguars, the Los Angeles Chargers, the Miami Dolphins, the New York Jets, the Oakland Raiders, the Philadelphia Eagles, the Pittsburgh Steelers, the San Francisco 49ers, the Seattle\n",
            "Original: Question: Last of the mohicans filming locations north carolina? Answer:\n",
            "\n",
            "Original prompt: Question: Last of the mohicans filming locations north carolina? Answer:\n",
            "[QA(Last of the mohicans filming locations north carolina?) -> North Carolina] Asheville<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Last of the mohicans filming locations north carolina? Answer:\n",
            "[QA(Last of the mohicans filming locations north carolina?) -> Chimney Rock State Park, Lake James, Dupont State Forest.] Chimney Rock State Park<|endoftext|>\n",
            "Original: Question: Who plays erica hahn on grey's anatomy? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays erica hahn on grey's anatomy? Answer:\n",
            "[QA(Who plays erica hahn on grey's anatomy?) -> Ellen Pompeo] Ellen Pompeo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays erica hahn on grey's anatomy? Answer:\n",
            "[QA(Who plays erica hahn on grey's anatomy?) -> Brooke Smith] Brooke Smith<|endoftext|>\n",
            "Original: Question: When was disney the fox and the hound first released? Answer:\n",
            "\n",
            "Original prompt: Question: When was disney the fox and the hound first released? Answer:\n",
            "[QA(When was disney the fox and the hound first released?) -> July 5, 1939] July 5, 1939<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was disney the fox and the hound first released? Answer:\n",
            "[QA(When was disney the fox and the hound first released?) -> July 10, 1981] 1981<|endoftext|>\n",
            "Original: Question: When is episode 10 of boruto coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is episode 10 of boruto coming out? Answer:\n",
            "[QA(When is episode 10 of boruto coming out?) -> Episode 10 of Boruto: The Demon of the Mist is coming out on April 4, 2018.] April 4, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is episode 10 of boruto coming out? Answer:\n",
            "[QA(When is episode 10 of boruto coming out?) -> The release date for episode 10 of Boruto was June 7, 2017.] June 7, 2017<|endoftext|>\n",
            "Original: Question: What episode of bleach does the fullbring arc start? Answer:\n",
            "\n",
            "Original prompt: Question: What episode of bleach does the fullbring arc start? Answer:\n",
            "[QA(What episode of bleach does the fullbring arc start?) -> \"The Fullbring Arc\"] \"The Fullbring Arc\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What episode of bleach does the fullbring arc start? Answer:\n",
            "[QA(What episode of bleach does the fullbring arc start?) -> Episode 343] 343<|endoftext|>\n",
            "Original: Question: How and when was knowledge of paper making established in christian europe? Answer:\n",
            "\n",
            "Original prompt: Question: How and when was knowledge of paper making established in christian europe? Answer:\n",
            "[QA(How and when was knowledge of paper making established in christian europe?) -><|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How and when was knowledge of paper making established in christian europe? Answer:\n",
            "[QA(How and when was knowledge of paper making established in christian europe?) -> Knowledge of paper making was established in Christian Europe in the 11th-12th centuries through contact with the Islamic world.] the 11th-12th centuries through contact with the Islamic world.<|endoftext|>\n",
            "Original: Question: How many episode shokugeki no soma season 3? Answer:\n",
            "\n",
            "Original prompt: Question: How many episode shokugeki no soma season 3? Answer:\n",
            "[QA(How many episode shokugeki no soma season 3?) -><|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many episode shokugeki no soma season 3? Answer:\n",
            "[QA(How many episode shokugeki no soma season 3?) -> 24 episodes] 24<|endoftext|>\n",
            "Original: Question: What are the bikes called where you lay down? Answer:\n",
            "\n",
            "Original prompt: Question: What are the bikes called where you lay down? Answer:\n",
            "[QA(What are the bikes called where you lay down?) -> Segways] Segways<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What are the bikes called where you lay down? Answer:\n",
            "[QA(What are the bikes called where you lay down?) -> Recumbent bikes.] Recumbent bikes<|endoftext|>\n",
            "Original: Question: Who is in charge of american monetary policy? Answer:\n",
            "\n",
            "Original prompt: Question: Who is in charge of american monetary policy? Answer:\n",
            "[QA(Who is in charge of american monetary policy?) -> The Federal Reserve System] the Federal Reserve System<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is in charge of american monetary policy? Answer:\n",
            "[QA(Who is in charge of american monetary policy?) -> The Federal Reserve (Fed)] the Federal Reserve<|endoftext|>\n",
            "Original: Question: Who was heading indian army 1971 bangladesh war? Answer:\n",
            "\n",
            "Original prompt: Question: Who was heading indian army 1971 bangladesh war? Answer:\n",
            "[QA(Who was heading indian army 1971 bangladesh war?) -> Lt. Gen. Jagjit Singh Aurora] Lt. Gen. Jagjit Singh Aurora<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was heading indian army 1971 bangladesh war? Answer:\n",
            "[QA(Who was heading indian army 1971 bangladesh war?) -> General Sam Manekshaw] General Sam Manekshaw<|endoftext|>\n",
            "Original: Question: What was the mohammedan anglo oriental school 4 marks? Answer:\n",
            "\n",
            "Original prompt: Question: What was the mohammedan anglo oriental school 4 marks? Answer:\n",
            "[QA(What was the mohammedan anglo oriental school 4 marks?) -> The mohammedan anglo oriental school 4 marks was a school in the United Kingdom that was established in 1858.] 19th century<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the mohammedan anglo oriental school 4 marks? Answer:\n",
            "[QA(What was the mohammedan anglo oriental school 4 marks?) -> The Mohammedan Anglo Oriental School was an educational institution established in 1875 in Aligarh, India, by Sir Syed Ahmed Khan, aiming to promote modern education for India's Muslim community. It later became Aligarh Muslim University.\n",
            "] 4 marks<|endoftext|>\n",
            "Original: Question: How many times has the us constitution been changed? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many times has the us constitution been changed? Answer:\n",
            "[Calculator(2)]=2; [Calculator(3)]=3; [Calculator(4)]=4; [Calculator(5)]=5; [Calculator(6)]=6; [Calculator(7)]=7; [Calculator(8)]=8; [Calculator(9)]=9; [Calculator(10)]=10; [Calculator(11)]=11; [Calculator(12)]=12; [Calculator(13)]=13; [Calculator(14)]=14; [Calculator(15)]=15; [Calculator(16)]=16; [Calculator(17)]=17; [Calculator(18)]=18; [Calculator(19)]=19; [Calculator(20)]=20; [Calculator(21)]=21; [Calculator(22)]=22; [Calculator(23)]=23; [Calculator(24)]=24; [Calculator(25)]=25; [\n",
            "Computed answer was: 2.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many times has the us constitution been changed? Answer:\n",
            "[Calculator(2)]=2.0 times<|endoftext|>\n",
            "Original: Question: When did we start paying federal income tax? Answer:\n",
            "\n",
            "Original prompt: Question: When did we start paying federal income tax? Answer:\n",
            "[QA(When did we start paying federal income tax?) -> 1894] 1894<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did we start paying federal income tax? Answer:\n",
            "[QA(When did we start paying federal income tax?) -> 1913] 1913<|endoftext|>\n",
            "Original: Question: How many times peyton been to super bowl? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many times peyton been to super bowl? Answer:\n",
            "[Calculator(2*Super Bowl)]=4 thus answer is 4 (times).<|endoftext|>\n",
            "Error processing the input '2*Super Bowl': unsupported operand type(s) for *: 'int' and 'NoneType'\n",
            "WE SKIPPED\n",
            "Generated: Question: How many times peyton been to super bowl? Answer:\n",
            "[Calculator(2*Super Bowl)]=4 thus answer is 4 (times).<|endoftext|>\n",
            "Original: Question: Where is the new years eve concert held? Answer:\n",
            "\n",
            "Original prompt: Question: Where is the new years eve concert held? Answer:\n",
            "[QA(Where is the new years eve concert held?) -> The New Year's Eve concert is held in New York, New York.] New York, New York<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is the new years eve concert held? Answer:\n",
            "[QA(Where is the new years eve concert held?) -> The location of New Year's Eve concert can vary based on different cities and countries globally. Famous ones include Times Square in New York, Sydney Opera House in Australia, or Vienna Philharmonic in Austria. You need to specify a place for a precise answer.] New York, New York<|endoftext|>\n",
            "Original: Question: Which u.s. supreme court case required states to use the exclusionary rule? Answer:\n",
            "\n",
            "Original prompt: Question: Which u.s. supreme court case required states to use the exclusionary rule? Answer:\n",
            "[QA(Which u.s. supreme court case required states to use the exclusionary rule?) -> The case of Mapp v. Ohio.] Mapp v. Ohio<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which u.s. supreme court case required states to use the exclusionary rule? Answer:\n",
            "[QA(Which u.s. supreme court case required states to use the exclusionary rule?) -> Mapp v. Ohio] Mapp v. Ohio<|endoftext|>\n",
            "Original: Question: When did ginny weasley join the quidditch team? Answer:\n",
            "\n",
            "Original prompt: Question: When did ginny weasley join the quidditch team? Answer:\n",
            "[QA(When did ginny weasley join the quidditch team?) -> In the movie \"Harry Potter and the Deathly Hallows: Part 2,\" Ginny Weasley joins the Quidditch team in the last book of the series, \"Harry Potter and the Deathly Hallows: Part 2.\"] the last book of the series, \"Harry Potter and the Deathly Hallows: Part 2.\"\"Harry Potter and the Deathly Hallows: Part 2.\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did ginny weasley join the quidditch team? Answer:\n",
            "[QA(When did ginny weasley join the quidditch team?) -> Ginny Weasley joined the Quidditch team in her fourth year at Hogwarts.] her fourth year at Hogwarts<|endoftext|>\n",
            "Original: Question: What car does reynolds woodcock drive in phantom thread? Answer:\n",
            "\n",
            "Original prompt: Question: What car does reynolds woodcock drive in phantom thread? Answer:\n",
            "[QA(What car does reynolds woodcock drive in phantom thread?) -> The car that Reynolds Woodcock drives in Phantom Thread is a Rolls-Royce Wraith.] Rolls-Royce Wraith<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What car does reynolds woodcock drive in phantom thread? Answer:\n",
            "[QA(What car does reynolds woodcock drive in phantom thread?) -> Bristol 405] Bristol 405<|endoftext|>\n",
            "Original: Question: Who plays kiki in queen of the south? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays kiki in queen of the south? Answer:\n",
            "[QA(Who plays kiki in queen of the south?) -> Mariah Carey] Mariah Carey<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays kiki in queen of the south? Answer:\n",
            "[QA(Who plays kiki in queen of the south?) -> Molly Burnett] Molly Burnett<|endoftext|>\n",
            "Original: Question: When will game of thrones season 7 will be aired? Answer:\n",
            "\n",
            "Original prompt: Question: When will game of thrones season 7 will be aired? Answer:\n",
            "[QA(When will game of thrones season 7 will be aired?) -> Season 7 of Game of Thrones will be aired in 2020.] 2020<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When will game of thrones season 7 will be aired? Answer:\n",
            "[QA(When will game of thrones season 7 will be aired?) -> Game of Thrones Season 7 premiered on July 16, 2017.] July 16, 2017<|endoftext|>\n",
            "Original: Question: What does it mean when you hear high pitched noises? Answer:\n",
            "\n",
            "Original prompt: Question: What does it mean when you hear high pitched noises? Answer:\n",
            "[QA(What does it mean when you hear high pitched noises?) -> High-pitched noises are sounds that have a high frequency and can be heard at a higher pitch than a low-pitched noise.] sound<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What does it mean when you hear high pitched noises? Answer:\n",
            "[QA(What does it mean when you hear high pitched noises?) -> It typically indicates hearing a sound with a high frequency.] a whistle<|endoftext|>\n",
            "Original: Question: Where does the last name bermudez come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the last name bermudez come from? Answer:\n",
            "[QA(Where does the last name bermudez come from?) -> The last name Bermudez comes from the Canary Islands.] Canary Islands<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the last name bermudez come from? Answer:\n",
            "[QA(Where does the last name bermudez come from?) -> The last name Bermudez originates from Spain.] Spain<|endoftext|>\n",
            "Original: Question: Who slew the philistines with a donkey jawbone? Answer:\n",
            "\n",
            "Original prompt: Question: Who slew the philistines with a donkey jawbone? Answer:\n",
            "[QA(Who slew the philistines with a donkey jawbone?) -> King David] David<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who slew the philistines with a donkey jawbone? Answer:\n",
            "[QA(Who slew the philistines with a donkey jawbone?) -> Samson.] Samson<|endoftext|>\n",
            "Original: Question: Where did the term dark ages come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where did the term dark ages come from? Answer:\n",
            "[QA(Where did the term dark ages come from?) -> The term \"dark ages\" comes from the medieval period in Europe.] the Middle Ages<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did the term dark ages come from? Answer:\n",
            "[QA(Where did the term dark ages come from?) -> The term \"Dark Ages\" originated from the Italian scholar Petrarch in the 1330s to describe the period of time following the fall of the Roman Empire.] the Middle Ages<|endoftext|>\n",
            "Original: Question: How many super bowl wins does the pittsburgh steelers have? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many super bowl wins does the pittsburgh steelers have? Answer:\n",
            "[Calculator(2+3)]=5 thus answer is 5 (super bowl wins).<|endoftext|>\n",
            "Computed answer was: 5.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many super bowl wins does the pittsburgh steelers have? Answer:\n",
            "[Calculator(2+3)]=5.0 thus answer is 5 (super bowl wins).<|endoftext|>\n",
            "Original: Question: What is the full name of nigerian president? Answer:\n",
            "\n",
            "Original prompt: Question: What is the full name of nigerian president? Answer:\n",
            "[QA(What is the full name of nigerian president?) -> Olusegun Obasanjo] Olusegun Obasanjo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the full name of nigerian president? Answer:\n",
            "[QA(What is the full name of nigerian president?) -> Muhammadu Buhari] Muhammadu Buhari<|endoftext|>\n",
            "Original: Question: 1 kunta is equal to how many square feet? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: 1 kunta is equal to how many square feet? Answer:\n",
            "[Calculator(1*1000)]=1000 thus answer is 1000 (square feet).<|endoftext|>\n",
            "Computed answer was: 1000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: 1 kunta is equal to how many square feet? Answer:\n",
            "[Calculator(1*1000)]=1000.0 (square feet) thus answer is 1000.0 (square feet).<|endoftext|>\n",
            "Original: Question: What books are in the lord of the rings series? Answer:\n",
            "\n",
            "Original prompt: Question: What books are in the lord of the rings series? Answer:\n",
            "[QA(What books are in the lord of the rings series?) -> The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return of the King, The Hobbit, The Fellowship of the Ring, The Two Towers, The Return\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What books are in the lord of the rings series? Answer:\n",
            "[QA(What books are in the lord of the rings series?) -> 1. The Fellowship of the Ring\n",
            "2. The Two Towers\n",
            "3. The Return of the King] The Fellowship of the Ring, The Two Towers, and The Return of the King<|endoftext|>\n",
            "Original: Question: Sound is a form of what kind of energy? Answer:\n",
            "\n",
            "Original prompt: Question: Sound is a form of what kind of energy? Answer:\n",
            "[QA(Sound is a form of what kind of energy?) -> Sound is a form of kinetic energy.] kinetic energy<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Sound is a form of what kind of energy? Answer:\n",
            "[QA(Sound is a form of what kind of energy?) -> Mechanical energy] mechanical energy<|endoftext|>\n",
            "Original: Question: What is the capital of new zealands north island? Answer:\n",
            "\n",
            "Original prompt: Question: What is the capital of new zealands north island? Answer:\n",
            "[QA(What is the capital of new zealands north island?) -> Auckland] Auckland<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the capital of new zealands north island? Answer:\n",
            "[QA(What is the capital of new zealands north island?) -> Wellington] Wellington<|endoftext|>\n",
            "Original: Question: Who used the sherman antitrust act to dissolve the monopoly of the northern securities company? Answer:\n",
            "\n",
            "Original prompt: Question: Who used the sherman antitrust act to dissolve the monopoly of the northern securities company? Answer:\n",
            "[QA(Who used the sherman antitrust act to dissolve the monopoly of the northern securities company?) -> The Sherman Antitrust Act was used to dissolve the monopoly of the Northern Securities Company.] Theodore Roosevelt<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who used the sherman antitrust act to dissolve the monopoly of the northern securities company? Answer:\n",
            "[QA(Who used the sherman antitrust act to dissolve the monopoly of the northern securities company?) -> President Theodore Roosevelt] Theodore Roosevelt<|endoftext|>\n",
            "Original: Question: Who is the current madam president in the senate? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the current madam president in the senate? Answer:\n",
            "[QA(Who is the current madam president in the senate?) -> Kirsten Gillibrand] Kirsten Gillibrand<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the current madam president in the senate? Answer:\n",
            "[QA(Who is the current madam president in the senate?) -> The U.S. Senate doesn't have a title \"Madam President\". The closest title would be \"Madam Vice President\", currently held by Kamala Harris as of 2022.] Kamala Harris<|endoftext|>\n",
            "Original: Question: Who played the cigarette smoking man on the x-files? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the cigarette smoking man on the x-files? Answer:\n",
            "[QA(Who played the cigarette smoking man on the x-files?) -> William B. Davis] William B. Davis<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the cigarette smoking man on the x-files? Answer:\n",
            "[QA(Who played the cigarette smoking man on the x-files?) -> William B. Davis] William B. Davis<|endoftext|>\n",
            "Original: Question: When does the rest of season 7 of suits start? Answer:\n",
            "\n",
            "Original prompt: Question: When does the rest of season 7 of suits start? Answer:\n",
            "[QA(When does the rest of season 7 of suits start?) -> The rest of season 7 of Suits starts in January 2019.] January 2019<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does the rest of season 7 of suits start? Answer:\n",
            "[QA(When does the rest of season 7 of suits start?) -> \"Suits\" Season 7 resumed on March 28, 2018.] March 28, 2018<|endoftext|>\n",
            "Original: Question: Who composed the famous song 'sare jahan se acha'? Answer:\n",
            "\n",
            "Original prompt: Question: Who composed the famous song'sare jahan se acha'? Answer:\n",
            "[QA(Who composed the famous song'sare jahan se acha') -> Ravi Shankar] Ravi Shankar<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who composed the famous song'sare jahan se acha'? Answer:\n",
            "[QA(Who composed the famous song'sare jahan se acha') -> Muhammad Iqbal] Muhammad Iqbal<|endoftext|>\n",
            "Original: Question: What is the top speed of a yamaha blaster? Answer:\n",
            "\n",
            "Original prompt: Question: What is the top speed of a yamaha blaster? Answer:\n",
            "[QA(What is the top speed of a yamaha blaster?) -> The top speed of a Yamaha blaster depends on the model. Some models have a top speed of 120 km/h (75 mph), while others have a top speed of 140 km/h (87 mph).] 150 km/h (93 mph)<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the top speed of a yamaha blaster? Answer:\n",
            "[QA(What is the top speed of a yamaha blaster?) -> 55 mph] 55 mph<|endoftext|>\n",
            "Original: Question: Where does raisin in the sun take place? Answer:\n",
            "\n",
            "Original prompt: Question: Where does raisin in the sun take place? Answer:\n",
            "[QA(Where does raisin in the sun take place?) -> The movie Raisin in the Sun takes place in Chicago, Illinois.] Chicago<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does raisin in the sun take place? Answer:\n",
            "[QA(Where does raisin in the sun take place?) -> \"Raisin in the Sun\" takes place in Chicago's Southside.] Chicago's Southside<|endoftext|>\n",
            "Original: Question: What is the first light in the night sky? Answer:\n",
            "\n",
            "Original prompt: Question: What is the first light in the night sky? Answer:\n",
            "[QA(What is the first light in the night sky?) -> The first light in the night sky is the first star that appears in the night sky.] Sirius<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the first light in the night sky? Answer:\n",
            "[QA(What is the first light in the night sky?) -> The moon.] the moon<|endoftext|>\n",
            "Original: Question: Who's the lead singer of the doobie brothers? Answer:\n",
            "\n",
            "Original prompt: Question: Who's the lead singer of the doobie brothers? Answer:\n",
            "[QA(Who's the lead singer of the doobie brothers?) -> Robert Hunter] Robert Hunter<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who's the lead singer of the doobie brothers? Answer:\n",
            "[QA(Who's the lead singer of the doobie brothers?) -> Tom Johnston and Patrick Simmons.] Tom Johnston<|endoftext|>\n",
            "Original: Question: Who won the gold medal for men's halfpipe? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the gold medal for men's halfpipe? Answer:\n",
            "[QA(Who won the gold medal for men's halfpipe?) -> Shaun White] Shaun White<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the gold medal for men's halfpipe? Answer:\n",
            "[QA(Who won the gold medal for men's halfpipe?) -> The information about the specific year, event, and sport is necessary to provide the accurate answer. The'men's halfpipe' event can refer to different sports like snowboarding or skateboarding in different years of competitions like the Olympics or X Games. Please provide more specific details.] 2018<|endoftext|>\n",
            "Original: Question: Who has the least punishments on impractical jokers? Answer:\n",
            "\n",
            "Original prompt: Question: Who has the least punishments on impractical jokers? Answer:\n",
            "[QA(Who has the least punishments on impractical jokers?) -> The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have the least punishments on impractical jokers. The impractical jokers have\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has the least punishments on impractical jokers? Answer:\n",
            "[QA(Who has the least punishments on impractical jokers?) -> Joe Gatto] Joe Gatto<|endoftext|>\n",
            "Original: Question: When did fortnite come out on xbox one? Answer:\n",
            "\n",
            "Original prompt: Question: When did fortnite come out on xbox one? Answer:\n",
            "[QA(When did fortnite come out on xbox one?) -> July 2017] July 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did fortnite come out on xbox one? Answer:\n",
            "[QA(When did fortnite come out on xbox one?) -> July 25, 2017] July 25, 2017<|endoftext|>\n",
            "Original: Question: When is mom and dad movie coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is mom and dad movie coming out? Answer:\n",
            "[QA(When is mom and dad movie coming out?) -> The mom and dad movie is coming out on July 5, 2018.] July 5, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is mom and dad movie coming out? Answer:\n",
            "[QA(When is mom and dad movie coming out?) -> The movie \"Mom and Dad\" was released on January 19, 2018.] January 19, 2018<|endoftext|>\n",
            "Original: Question: When did the us send troops to europe in ww1? Answer:\n",
            "\n",
            "Original prompt: Question: When did the us send troops to europe in ww1? Answer:\n",
            "[QA(When did the us send troops to europe in ww1?) -> 1918] 1918<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the us send troops to europe in ww1? Answer:\n",
            "[QA(When did the us send troops to europe in ww1?) -> June 1917] June 1917<|endoftext|>\n",
            "Original: Question: Largest and deepest freshwater lake in the world? Answer:\n",
            "\n",
            "Original prompt: Question: Largest and deepest freshwater lake in the world? Answer:\n",
            "[QA(Largest and deepest freshwater lake in the world?) -> Lake Titicaca] Lake Titicaca<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Largest and deepest freshwater lake in the world? Answer:\n",
            "[QA(Largest and deepest freshwater lake in the world?) -> Lake Baikal] Lake Baikal<|endoftext|>\n",
            "Original: Question: What is the another name of sahara desert? Answer:\n",
            "\n",
            "Original prompt: Question: What is the another name of sahara desert? Answer:\n",
            "[QA(What is the another name of sahara desert?) -> The Sahara Desert] Sahara<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the another name of sahara desert? Answer:\n",
            "[QA(What is the another name of sahara desert?) -> The Great Desert] The Sahara Desert<|endoftext|>\n",
            "Original: Question: When does shokugeki no soma season 3 return? Answer:\n",
            "\n",
            "Original prompt: Question: When does shokugeki no soma season 3 return? Answer:\n",
            "[QA(When does shokugeki no soma season 3 return?) -> October 11, 2018] October 11, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does shokugeki no soma season 3 return? Answer:\n",
            "[QA(When does shokugeki no soma season 3 return?) -> Shokugeki no Soma Season 3 returned on April 9, 2018.] April 9, 2018<|endoftext|>\n",
            "Original: Question: Who invented the television and when was it invented? Answer:\n",
            "\n",
            "Original prompt: Question: Who invented the television and when was it invented? Answer:\n",
            "[QA(Who invented the television and when was it invented?) -> The television was invented by Philo T. Farnsworth in 1927.] Philo T. Farnsworth<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who invented the television and when was it invented? Answer:\n",
            "[QA(Who invented the television and when was it invented?) -> The television was invented by Philo Farnsworth in 1927.] Philo Farnsworth<|endoftext|>\n",
            "Original: Question: When did the go pro hero 6 come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the go pro hero 6 come out? Answer:\n",
            "[QA(When did the go pro hero 6 come out?) -> December 2017] December 17, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the go pro hero 6 come out? Answer:\n",
            "[QA(When did the go pro hero 6 come out?) -> September 28, 2017] September 28, 2017<|endoftext|>\n",
            "Original: Question: Who won the last food network star 2017? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the last food network star 2017? Answer:\n",
            "[QA(Who won the last food network star 2017?) -> Gwyneth Paltrow] Gwyneth Paltrow<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the last food network star 2017? Answer:\n",
            "[QA(Who won the last food network star 2017?) -> Jason Smith] Jason Smith<|endoftext|>\n",
            "Original: Question: Who dies in harry potter and the half blood prince? Answer:\n",
            "\n",
            "Original prompt: Question: Who dies in harry potter and the half blood prince? Answer:\n",
            "[QA(Who dies in harry potter and the half blood prince?) -> Fenrir Greyback] Fenrir Greyback<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who dies in harry potter and the half blood prince? Answer:\n",
            "[QA(Who dies in harry potter and the half blood prince?) -> Albus Dumbledore.] Albus Dumbledore<|endoftext|>\n",
            "Original: Question: When does marriage boot camp family edition come on? Answer:\n",
            "\n",
            "Original prompt: Question: When does marriage boot camp family edition come on? Answer:\n",
            "[QA(When does marriage boot camp family edition come on?) -> Marriage Boot Camp: Family Edition comes on after the episode<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does marriage boot camp family edition come on? Answer:\n",
            "[QA(When does marriage boot camp family edition come on?) -> The schedule can vary, so it would be best to check with the local cable provider's TV guide or the official website for the most accurate times.] January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December<|endoftext|>\n",
            "Original: Question: Where did the movie players club take place? Answer:\n",
            "\n",
            "Original prompt: Question: Where did the movie players club take place? Answer:\n",
            "[QA(Where did the movie players club take place?) -> The movie players club took place in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie players club\" in the movie \"The movie\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did the movie players club take place? Answer:\n",
            "[QA(Where did the movie players club take place?) -> The movie Players Club took place in Atlanta, Georgia.] Atlanta<|endoftext|>\n",
            "Original: Question: Minnesota twins logo what does the c stand for? Answer:\n",
            "\n",
            "Original prompt: Question: Minnesota twins logo what does the c stand for? Answer:\n",
            "[QA(Minnesota twins logo what does the c stand for?) -> The C stands for the city of Minneapolis.] Minneapolis<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Minnesota twins logo what does the c stand for? Answer:\n",
            "[QA(Minnesota twins logo what does the c stand for?) -> The \"C\" in the Minnesota Twins logo stands for \"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.] \"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.] \"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St. Paul.\"Cities,\" referring to the Twin Cities of Minneapolis and St.<|endoftext|>\n",
            "Original: Question: Which part of the plant is sugar beet? Answer:\n",
            "\n",
            "Original prompt: Question: Which part of the plant is sugar beet? Answer:\n",
            "[QA(Which part of the plant is sugar beet?) -> The leaves of a sugar beet plant.] leaves<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which part of the plant is sugar beet? Answer:\n",
            "[QA(Which part of the plant is sugar beet?) -> Root] the root<|endoftext|>\n",
            "Original: Question: Who played larry in man about the house? Answer:\n",
            "\n",
            "Original prompt: Question: Who played larry in man about the house? Answer:\n",
            "[QA(Who played larry in man about the house?) -> Larry Hagman] Larry Hagman<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played larry in man about the house? Answer:\n",
            "[QA(Who played larry in man about the house?) -> Richard O'Sullivan] Richard O'Sullivan<|endoftext|>\n",
            "Original: Question: When did france give us the statue of liberty? Answer:\n",
            "\n",
            "Original prompt: Question: When did france give us the statue of liberty? Answer:\n",
            "[QA(When did france give us the statue of liberty?) -> July 4, 1776] July 4, 1776<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did france give us the statue of liberty? Answer:\n",
            "[QA(When did france give us the statue of liberty?) -> 1886] 1886<|endoftext|>\n",
            "Original: Question: What body of water does niagara falls flow into? Answer:\n",
            "\n",
            "Original prompt: Question: What body of water does niagara falls flow into? Answer:\n",
            "[QA(What body of water does niagara falls flow into?) -> The Niagara River flows into Lake Erie.] Lake Erie<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What body of water does niagara falls flow into? Answer:\n",
            "[QA(What body of water does niagara falls flow into?) -> Niagara River] the Niagara River<|endoftext|>\n",
            "Original: Question: When did the rams move to saint louis? Answer:\n",
            "\n",
            "Original prompt: Question: When did the rams move to saint louis? Answer:\n",
            "[QA(When did the rams move to saint louis?) -> The Rams moved to St. Louis in 1995.] 1995<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the rams move to saint louis? Answer:\n",
            "[QA(When did the rams move to saint louis?) -> 1995] 1995<|endoftext|>\n",
            "Original: Question: Who caught dan marino's one last pass? Answer:\n",
            "\n",
            "Original prompt: Question: Who caught dan marino's one last pass? Answer:\n",
            "[QA(Who caught dan marino's one last pass?) -> Dan Marino.] Dan Marino<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who caught dan marino's one last pass? Answer:\n",
            "[QA(Who caught dan marino's one last pass?) -> Konrad Rueland] Konrad Rueland<|endoftext|>\n",
            "Original: Question: When did trinidad and tobago become an independent nation? Answer:\n",
            "\n",
            "Original prompt: Question: When did trinidad and tobago become an independent nation? Answer:\n",
            "[QA(When did trinidad and tobago become an independent nation?) -> July 31, 1962] July 31, 1962<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did trinidad and tobago become an independent nation? Answer:\n",
            "[QA(When did trinidad and tobago become an independent nation?) -> August 31, 1962] August 31, 1962<|endoftext|>\n",
            "Original: Question: Who wrote the sanford and son theme song? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the sanford and son theme song? Answer:\n",
            "[QA(Who wrote the sanford and son theme song?) -> The Sherman Brothers.] Sherman Brothers<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the sanford and son theme song? Answer:\n",
            "[QA(Who wrote the sanford and son theme song?) -> Quincy Jones] Quincy Jones<|endoftext|>\n",
            "Original: Question: Which pm of pakistan had the shortest tenure? Answer:\n",
            "\n",
            "Original prompt: Question: Which pm of pakistan had the shortest tenure? Answer:\n",
            "[QA(Which pm of pakistan had the shortest tenure?) -> Zulfikar Ali Bhutto] Zulfikar Ali Bhutto<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which pm of pakistan had the shortest tenure? Answer:\n",
            "[QA(Which pm of pakistan had the shortest tenure?) -> Nurul Amin] Nurul Amin<|endoftext|>\n",
            "Original: Question: When do we celebrate world environment day and why? Answer:\n",
            "\n",
            "Original prompt: Question: When do we celebrate world environment day and why? Answer:\n",
            "[QA(When do we celebrate world environment day and why?) -> World Environment Day is celebrated on the last Sunday of October each year.] October 7, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When do we celebrate world environment day and why? Answer:\n",
            "[QA(When do we celebrate world environment day and why?) -> World Environment Day is celebrated on June 5 every year to raise global awareness about environmental issues and encourage actions for the protection of our environment.] June 5, 2017, to raise global awareness about environmental issues and encourage actions for the protection of our environment.<|endoftext|>\n",
            "Original: Question: Who sings don't call us we'll call you? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings don't call us we'll call you? Answer:\n",
            "[QA(Who sings don't call us we'll call you?) -> Adele] Adele<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings don't call us we'll call you? Answer:\n",
            "[QA(Who sings don't call us we'll call you?) -> Sugarloaf] Sugarloaf<|endoftext|>\n",
            "Original: Question: Who wrote i could fall in love by selena? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote i could fall in love by selena? Answer:\n",
            "[QA(Who wrote i could fall in love by selena?) -> Selena Gomez] Selena Gomez<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote i could fall in love by selena? Answer:\n",
            "[QA(Who wrote i could fall in love by selena?) -> Keith Thomas and Franne Golde.] Keith Thomas<|endoftext|>\n",
            "Original: Question: When was the aria built in las vegas? Answer:\n",
            "\n",
            "Original prompt: Question: When was the aria built in las vegas? Answer:\n",
            "[QA(When was the aria built in las vegas?) -> The Aria was built in 2017.] 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the aria built in las vegas? Answer:\n",
            "[QA(When was the aria built in las vegas?) -> December 2009] December 2009<|endoftext|>\n",
            "Original: Question: Who is known as the super fast boy in the series the incredible? Answer:\n",
            "\n",
            "Original prompt: Question: Who is known as the super fast boy in the series the incredible? Answer:\n",
            "[QA(Who is known as the super fast boy in the series the incredible?) -> Barry Allen] Barry Allen<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is known as the super fast boy in the series the incredible? Answer:\n",
            "[QA(Who is known as the super fast boy in the series the incredible?) -> Dash Parr] Dash Parr<|endoftext|>\n",
            "Original: Question: Who won the oscar for best actor in 2006? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the oscar for best actor in 2006? Answer:\n",
            "[QA(Who won the oscar for best actor in 2006?) -> Philip Seymour Hoffman] Philip Seymour Hoffman<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the oscar for best actor in 2006? Answer:\n",
            "[QA(Who won the oscar for best actor in 2006?) -> Philip Seymour Hoffman] Philip Seymour Hoffman<|endoftext|>\n",
            "Original: Question: Who did ava jerome kill on general hospital? Answer:\n",
            "\n",
            "Original prompt: Question: Who did ava jerome kill on general hospital? Answer:\n",
            "[QA(Who did ava jerome kill on general hospital?) -> In \"General Hospital,\" Ava Jerome killed her father, Martin Jerrome.] her father, Martin Jerrome<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who did ava jerome kill on general hospital? Answer:\n",
            "[QA(Who did ava jerome kill on general hospital?) -> Connie Falconeri] Connie Falconeri<|endoftext|>\n",
            "Original: Question: Who presides over the meeting of legislative council? Answer:\n",
            "\n",
            "Original prompt: Question: Who presides over the meeting of legislative council? Answer:\n",
            "[QA(Who presides over the meeting of legislative council?) -> The Speaker of the Legislative Council.] Speaker of the Legislative Council<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who presides over the meeting of legislative council? Answer:\n",
            "[QA(Who presides over the meeting of legislative council?) -> The Chairman presides over the meeting of the legislative council.] the Chairman of the Legislative Council<|endoftext|>\n",
            "Original: Question: Who plays robin's mom in how i met your mother? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays robin's mom in how i met your mother? Answer:\n",
            "[QA(Who plays robin's mom in how i met your mother?) -> Connie Britton] Connie Britton<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays robin's mom in how i met your mother? Answer:\n",
            "[QA(Who plays robin's mom in how i met your mother?) -> Tracy Ullman] Tracy Ullman<|endoftext|>\n",
            "Original: Question: When was the neutrality act of 1937 passed? Answer:\n",
            "\n",
            "Original prompt: Question: When was the neutrality act of 1937 passed? Answer:\n",
            "[QA(When was the neutrality act of 1937 passed?) -> October 6, 1937] October 6, 1937<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the neutrality act of 1937 passed? Answer:\n",
            "[QA(When was the neutrality act of 1937 passed?) -> May 1, 1937] May 1, 1937<|endoftext|>\n",
            "Original: Question: Arabian sea is the part of which ocean? Answer:\n",
            "\n",
            "Original prompt: Question: Arabian sea is the part of which ocean? Answer:\n",
            "[QA(Arabian sea is the part of which ocean?) -> Indian Ocean] Indian Ocean<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Arabian sea is the part of which ocean? Answer:\n",
            "[QA(Arabian sea is the part of which ocean?) -> Indian Ocean] Indian Ocean<|endoftext|>\n",
            "Original: Question: Who wrote the influence of sea power upon history? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the influence of sea power upon history? Answer:\n",
            "[QA(Who wrote the influence of sea power upon history?) -> Alfred Thayer Mahan] Alfred Thayer Mahan<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the influence of sea power upon history? Answer:\n",
            "[QA(Who wrote the influence of sea power upon history?) -> Alfred Thayer Mahan] Alfred Thayer Mahan<|endoftext|>\n",
            "Original: Question: What part of the chicken is general tso chicken? Answer:\n",
            "\n",
            "Original prompt: Question: What part of the chicken is general tso chicken? Answer:\n",
            "[QA(What part of the chicken is general tso chicken?) -> The wings] wings<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What part of the chicken is general tso chicken? Answer:\n",
            "[QA(What part of the chicken is general tso chicken?) -> Chicken thigh or breast.] thigh<|endoftext|>\n",
            "Original: Question: What feature led to the most sales for the playstation 2? Answer:\n",
            "\n",
            "Original prompt: Question: What feature led to the most sales for the playstation 2? Answer:\n",
            "[QA(What feature led to the most sales for the playstation 2?) -> The ability to play games in 3-D] 3-D<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What feature led to the most sales for the playstation 2? Answer:\n",
            "[QA(What feature led to the most sales for the playstation 2?) -> DVD playback capability] DVD playback capability<|endoftext|>\n",
            "Original: Question: Who won the ncaa basketball championship in 1989? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the ncaa basketball championship in 1989? Answer:\n",
            "[QA(Who won the ncaa basketball championship in 1989?) -> Michael Jordan] Michael Jordan<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the ncaa basketball championship in 1989? Answer:\n",
            "[QA(Who won the ncaa basketball championship in 1989?) -> University of Michigan] the University of Michigan<|endoftext|>\n",
            "Original: Question: When did america first land on the moon? Answer:\n",
            "\n",
            "Original prompt: Question: When did america first land on the moon? Answer:\n",
            "[QA(When did america first land on the moon?) -> July 20, 1969] July 20, 1969<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did america first land on the moon? Answer:\n",
            "[QA(When did america first land on the moon?) -> July 20, 1969] July 20, 1969<|endoftext|>\n",
            "Original: Question: Where does the tap water in london come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the tap water in london come from? Answer:\n",
            "[QA(Where does the tap water in london come from?) -> The water in London comes from the River Thames.] the Thames<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the tap water in london come from? Answer:\n",
            "[QA(Where does the tap water in london come from?) -> The tap water in London mainly comes from the River Thames and River Lea.] the Thames<|endoftext|>\n",
            "Original: Question: How many seasons of svu law and order are there? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many seasons of svu law and order are there? Answer:\n",
            "[Calculator(2)]=2; [Calculator(3)]=3; [Calculator(4)]=4; [Calculator(5)]=5; [Calculator(6)]=6; [Calculator(7)]=7; [Calculator(8)]=8; [Calculator(9)]=9; [Calculator(10)]=10; [Calculator(11)]=11; [Calculator(12)]=12; [Calculator(13)]=13; [Calculator(14)]=14; [Calculator(15)]=15; [Calculator(16)]=16; [Calculator(17)]=17; [Calculator(18)]=18; [Calculator(19)]=19; [Calculator(20)]=20; [Calculator(21)]=21; [Calculator(22)]=22; [Calculator(23)]=23; [Calculator(24)]=24; [Calculator(25)]=25\n",
            "Computed answer was: 2.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 3.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 4.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 5.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 6.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many seasons of svu law and order are there? Answer:\n",
            "[Calculator(2)]=2.0; [Calculator(3)]=3.0; [Calculator(4)]=4.0; [Calculator(5)]=5.0; [Calculator(6)]=6.0; [Calculator(7)]=7.0; [Calculator(8)]=8.0; [Calculator(9)]=9.0; [Calculator(10)]=10.0; [Calculator(11)]=11.0; [Calculator(12)]=12.0; [Calculator(13)]=13.0; [Calculator(14)]=14.0; [Calculator(15)]=15.0; [Calculator(16)]=16.0; [Calculator(17)]=17.0; [Calculator(18)]=18.0; [Calculator(19)]=19.0; [Calculator(20)]=20.0; [Calculator(21)]=21.0\n",
            "Original: Question: How many episodes are in american crime season 2? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many episodes are in american crime season 2? Answer:\n",
            "[Calculator(2+3)]=5 thus answer is 5 (episodes).<|endoftext|>\n",
            "Computed answer was: 5.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many episodes are in american crime season 2? Answer:\n",
            "[Calculator(2+3)]=5.0 thus answer is 5 (episodes).<|endoftext|>\n",
            "Original: Question: Who establishes the rules about naturalization of citizens? Answer:\n",
            "\n",
            "Original prompt: Question: Who establishes the rules about naturalization of citizens? Answer:\n",
            "[QA(Who establishes the rules about naturalization of citizens?) -> The U.S. Citizenship and Immigration Services]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who establishes the rules about naturalization of citizens? Answer:\n",
            "[QA(Who establishes the rules about naturalization of citizens?) -> The United States Congress]<|endoftext|>\n",
            "Original: Question: Where do ruby throated hummingbirds go in winter? Answer:\n",
            "\n",
            "Original prompt: Question: Where do ruby throated hummingbirds go in winter? Answer:\n",
            "[QA(Where do ruby throated hummingbirds go in winter?) -> The ruby throated hummingbird migrates to warmer climates in the winter.] Mexico<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where do ruby throated hummingbirds go in winter? Answer:\n",
            "[QA(Where do ruby throated hummingbirds go in winter?) -> Ruby throated hummingbirds migrate to Central America and Mexico in winter.] Central America and Mexico<|endoftext|>\n",
            "Original: Question: Thing that connects tongue to bottom of mouth? Answer:\n",
            "\n",
            "Original prompt: Question: Thing that connects tongue to bottom of mouth? Answer:\n",
            "[QA(Thing that connects tongue to bottom of mouth?) -> Palate]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Thing that connects tongue to bottom of mouth? Answer:\n",
            "[QA(Thing that connects tongue to bottom of mouth?) -> Frenulum] Frenulum<|endoftext|>\n",
            "Original: Question: What is the official language in the dominican republic? Answer:\n",
            "\n",
            "Original prompt: Question: What is the official language in the dominican republic? Answer:\n",
            "[QA(What is the official language in the dominican republic?) -> Spanish] Spanish<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the official language in the dominican republic? Answer:\n",
            "[QA(What is the official language in the dominican republic?) -> The official language in the Dominican Republic is Spanish.] Spanish<|endoftext|>\n",
            "Original: Question: What is the highest peak of mountain kenya? Answer:\n",
            "\n",
            "Original prompt: Question: What is the highest peak of mountain kenya? Answer:\n",
            "[QA(What is the highest peak of mountain kenya?) -> Kibo] Kibo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the highest peak of mountain kenya? Answer:\n",
            "[QA(What is the highest peak of mountain kenya?) -> Batian] Mount Batian<|endoftext|>\n",
            "Original: Question: Who is in charge of public schools in america? Answer:\n",
            "\n",
            "Original prompt: Question: Who is in charge of public schools in america? Answer:\n",
            "[QA(Who is in charge of public schools in america?) -> The states]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is in charge of public schools in america? Answer:\n",
            "[QA(Who is in charge of public schools in america?) -> Local school districts and state government.] the states<|endoftext|>\n",
            "Original: Question: Where is the final four 2018 being held? Answer:\n",
            "\n",
            "Original prompt: Question: Where is the final four 2018 being held? Answer:\n",
            "[QA(Where is the final four 2018 being held?) -> The Final Four 2018 is being held in Atlanta, Georgia.] Atlanta<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is the final four 2018 being held? Answer:\n",
            "[QA(Where is the final four 2018 being held?) -> The Final Four 2018 was held at the Alamodome in San Antonio, Texas.] Alamodome, San Antonio, Texas<|endoftext|>\n",
            "Original: Question: Who play the role of draupadi in mahabharat? Answer:\n",
            "\n",
            "Original prompt: Question: Who play the role of draupadi in mahabharat? Answer:\n",
            "[QA(Who play the role of draupadi in mahabharat?) -> Draupadi was the wife of the Pandavas.] Draupadi<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who play the role of draupadi in mahabharat? Answer:\n",
            "[QA(Who play the role of draupadi in mahabharat?) -> Roopa Ganguly] Roopa Ganguly<|endoftext|>\n",
            "Original: Question: When does supernatural scooby doo episodes come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does supernatural scooby doo episodes come out? Answer:\n",
            "[QA(When does supernatural scooby doo episodes come out?) -> \"Scooby-Doo\" episodes come out every month.] October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May, June, July, August, September, October, November, December, January, February, March, April, May,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does supernatural scooby doo episodes come out? Answer:\n",
            "[QA(When does supernatural scooby doo episodes come out?) -> The Supernatural Scooby Doo crossover episode aired on March 29, 2018.] March 29, 2018<|endoftext|>\n",
            "Original: Question: 1 kilohertz is equal to how many hertz? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: 1 kilohertz is equal to how many hertz? Answer:\n",
            "[Calculator(1000)]=1000 thus answer is 1000 (hertz).<|endoftext|>\n",
            "Computed answer was: 1000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: 1 kilohertz is equal to how many hertz? Answer:\n",
            "[Calculator(1000)]=1000.0 Hz thus answer is 1000 (hertz).<|endoftext|>\n",
            "Original: Question: Where did 6 degrees of separation come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where did 6 degrees of separation come from? Answer:\n",
            "[QA(Where did 6 degrees of separation come from?) -> 6 degrees of separation comes from the novel \"Six Degrees of Separation\" by John Guare.] the novel \"Six Degrees of Separation\" by John Guare.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did 6 degrees of separation come from? Answer:\n",
            "[QA(Where did 6 degrees of separation come from?) -> The concept, \"6 degrees of separation\", originated from the experiments by psychologist Stanley Milgram in the 1960s.] the experimentation by psychologist Stanley Milgram in the 1960s.<|endoftext|>\n",
            "Original: Question: Who wrote you don't know what it's like to love somebody? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote you don't know what it's like to love somebody? Answer:\n",
            "[QA(Who wrote you don't know what it's like to love somebody?) -> Bob Dylan] Bob Dylan<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote you don't know what it's like to love somebody? Answer:\n",
            "[QA(Who wrote you don't know what it's like to love somebody?) -> Barry Gibb, Robin Gibb and Maurice Gibb of the Bee Gees.] Robin Gibb<|endoftext|>\n",
            "Original: Question: Who does bob's voice from bob's burgers? Answer:\n",
            "\n",
            "Original prompt: Question: Who does bob's voice from bob's burgers? Answer:\n",
            "[QA(Who does bob's voice from bob's burgers?) -> Bob's voice from Bob's Burgers comes from the voice of Bob's father.] Bob's voice from Bob's Burgers<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who does bob's voice from bob's burgers? Answer:\n",
            "[QA(Who does bob's voice from bob's burgers?) -> H. Jon Benjamin] H. Jon Benjamin<|endoftext|>\n",
            "Original: Question: Han dynasty favored this religion and based civil service exams on it? Answer:\n",
            "\n",
            "Original prompt: Question: Han dynasty favored this religion and based civil service exams on it? Answer:\n",
            "[QA(Han dynasty favored this religion and based civil service exams on it?) -> Confucianism] Confucianism<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Han dynasty favored this religion and based civil service exams on it? Answer:\n",
            "[QA(Han dynasty favored this religion and based civil service exams on it?) -> Confucianism] Confucianism<|endoftext|>\n",
            "Original: Question: Where are the houses from full house located? Answer:\n",
            "\n",
            "Original prompt: Question: Where are the houses from full house located? Answer:\n",
            "[QA(Where are the houses from full house located?) -> The houses from Full House are located in various cities around the United States, including Atlanta, Los Angeles, Chicago, and New York.] Atlanta, Los Angeles, Chicago, and New York<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where are the houses from full house located? Answer:\n",
            "[QA(Where are the houses from full house located?) -> The houses from Full House are located in San Francisco, California, USA.] San Francisco<|endoftext|>\n",
            "Original: Question: Where does the blood in the pulmonary vein come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the blood in the pulmonary vein come from? Answer:\n",
            "[QA(Where does the blood in the pulmonary vein come from?) -> The blood in the pulmonary vein comes from the left atrium.] the left atrium<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the blood in the pulmonary vein come from? Answer:\n",
            "[QA(Where does the blood in the pulmonary vein come from?) -> The blood in the pulmonary vein comes from the lungs.] the lungs<|endoftext|>\n",
            "Original: Question: When did fred hollows get australian of the year? Answer:\n",
            "\n",
            "Original prompt: Question: When did fred hollows get australian of the year? Answer:\n",
            "[QA(When did fred hollows get australian of the year?) -> 2006] 2006<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did fred hollows get australian of the year? Answer:\n",
            "[QA(When did fred hollows get australian of the year?) -> 1990] 1990<|endoftext|>\n",
            "Original: Question: Do you have to show your id to police in va? Answer:\n",
            "\n",
            "Original prompt: Question: Do you have to show your id to police in va? Answer:\n",
            "[QA(Do you have to show your id to police in va?) -> No, you do not have to show your ID to the police in Virginia.] your driver's license<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Do you have to show your id to police in va? Answer:\n",
            "[QA(Do you have to show your id to police in va?) -> Yes, under certain circumstances.] If you are stopped by the police, you need to show them your driver's license. If you are not stopped by the police, you do not need to show them your driver's license.<|endoftext|>\n",
            "Original: Question: Which president was the general in charge of the union army during the civil war? Answer:\n",
            "\n",
            "Original prompt: Question: Which president was the general in charge of the union army during the civil war? Answer:\n",
            "[QA(Which president was the general in charge of the union army during the civil war?) -> Ulysses S. Grant] Ulysses S. Grant<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which president was the general in charge of the union army during the civil war? Answer:\n",
            "[QA(Which president was the general in charge of the union army during the civil war?) -> Ulysses S. Grant] Ulysses S. Grant<|endoftext|>\n",
            "Original: Question: Most points in la liga in a season? Answer:\n",
            "\n",
            "Original prompt: Question: Most points in la liga in a season? Answer:\n",
            "[QA(Most points in la liga in a season?) -> 92] 92<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Most points in la liga in a season? Answer:\n",
            "[QA(Most points in la liga in a season?) -> 100 points by Barcelona in the 2012-2013 season and Real Madrid in the 2011-2012 season.] 100<|endoftext|>\n",
            "Original: Question: The first railway train in india ran in 1853 from mumbai to? Answer:\n",
            "\n",
            "Original prompt: Question: The first railway train in india ran in 1853 from mumbai to? Answer:\n",
            "[QA(The first railway train in india ran in 1853 from mumbai to?) -> Pune] Pune<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The first railway train in india ran in 1853 from mumbai to? Answer:\n",
            "[QA(The first railway train in india ran in 1853 from mumbai to?) -> Thane] Thane<|endoftext|>\n",
            "Original: Question: Who sings ill make a man out of you? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings ill make a man out of you? Answer:\n",
            "[QA(Who sings ill make a man out of you?) -> The Beatles] The Beatles<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings ill make a man out of you? Answer:\n",
            "[QA(Who sings ill make a man out of you?) -> Donny Osmond] Donny Osmond<|endoftext|>\n",
            "Original: Question: What kind of cat is the maneki neko? Answer:\n",
            "\n",
            "Original prompt: Question: What kind of cat is the maneki neko? Answer:\n",
            "[QA(What kind of cat is the maneki neko?) -> The maneki neko is a type of cat.] cat<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What kind of cat is the maneki neko? Answer:\n",
            "[QA(What kind of cat is the maneki neko?) -> Maneki neko is a Japanese talisman, not a real cat. It's often referred to as \"lucky cat\" or \"beckoning cat\".] The maneki neko<|endoftext|>\n",
            "Original: Question: How many beads are in a mala bracelet? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many beads are in a mala bracelet? Answer:\n",
            "[Calculator(3*10)]=30 thus answer is 30 (beads).<|endoftext|>\n",
            "Computed answer was: 30.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many beads are in a mala bracelet? Answer:\n",
            "[Calculator(3*10)]=30.0 thus answer is 30 (beads).<|endoftext|>\n",
            "Original: Question: San andreas fault is an example of what type of fault? Answer:\n",
            "\n",
            "Original prompt: Question: San andreas fault is an example of what type of fault? Answer:\n",
            "[QA(San andreas fault is an example of what type of fault?) -> Strike-slip fault] strike-slip fault<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: San andreas fault is an example of what type of fault? Answer:\n",
            "[QA(San andreas fault is an example of what type of fault?) -> Transform fault] transform fault<|endoftext|>\n",
            "Original: Question: What is the current world record for shot put? Answer:\n",
            "\n",
            "Original prompt: Question: What is the current world record for shot put? Answer:\n",
            "[QA(What is the current world record for shot put?) -> The current world record for shot put is 67.25 meters.] 67.25 (meters)<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the current world record for shot put? Answer:\n",
            "[QA(What is the current world record for shot put?) -> As of my last update, the men's world record is 23.12 meters by Randy Barnes (USA) in 1990 and women's record is 22.63 meters by Natalya Lisovskaya (USSR) in 1987.] 23.12 (meters)<|endoftext|>\n",
            "Original: Question: When was walk on the wild side written? Answer:\n",
            "\n",
            "Original prompt: Question: When was walk on the wild side written? Answer:\n",
            "[QA(When was walk on the wild side written?) -> 1969] 1969<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was walk on the wild side written? Answer:\n",
            "[QA(When was walk on the wild side written?) -> 1972] 1972<|endoftext|>\n",
            "Original: Question: What are these little white balls in the back of my throat? Answer:\n",
            "\n",
            "Original prompt: Question: What are these little white balls in the back of my throat? Answer:\n",
            "[QA(What are these little white balls in the back of my throat?) -><|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What are these little white balls in the back of my throat? Answer:\n",
            "[QA(What are these little white balls in the back of my throat?) -> They could be tonsil stones or possibly strep throat. It's recommended to see a doctor for a diagnosis.] tonsils<|endoftext|>\n",
            "Original: Question: Who built the world's first binary digital computer z1? Answer:\n",
            "\n",
            "Original prompt: Question: Who built the world's first binary digital computer z1? Answer:\n",
            "[QA(Who built the world's first binary digital computer z1?) -> Gottfried Wilhelm Leibniz] Gottfried Wilhelm Leibniz<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who built the world's first binary digital computer z1? Answer:\n",
            "[QA(Who built the world's first binary digital computer z1?) -> Konrad Zuse] Konrad Zuse<|endoftext|>\n",
            "Original: Question: Who do you play as in halo 5? Answer:\n",
            "\n",
            "Original prompt: Question: Who do you play as in halo 5? Answer:\n",
            "[QA(Who do you play as in halo 5?) -> John-117] John-117<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who do you play as in halo 5? Answer:\n",
            "[QA(Who do you play as in halo 5?) -> You play as Spartan Jameson Locke and Master Chief (John-117).] Spartan Jameson Locke<|endoftext|>\n",
            "Original: Question: How many are in the house of representatives currently? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many are in the house of representatives currently? Answer:\n",
            "[Calculator(308)]=308 thus answer is 308 (representatives).<|endoftext|>\n",
            "Computed answer was: 308.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many are in the house of representatives currently? Answer:\n",
            "[Calculator(308)]=308.0 thus answer is 308 (representatives).<|endoftext|>\n",
            "Original: Question: Who owns willy wonka and the chocolate factory? Answer:\n",
            "\n",
            "Original prompt: Question: Who owns willy wonka and the chocolate factory? Answer:\n",
            "[QA(Who owns willy wonka and the chocolate factory?) -> The rights to \"Willy Wonka and the Chocolate Factory\" are owned by Roald Dahl.] Roald Dahl<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who owns willy wonka and the chocolate factory? Answer:\n",
            "[QA(Who owns willy wonka and the chocolate factory?) -> Warner Bros. Entertainment Inc.] Warner Bros. Entertainment Inc.<|endoftext|>\n",
            "Original: Question: When did the iphone 5 first come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did the iphone 5 first come out? Answer:\n",
            "[QA(When did the iphone 5 first come out?) -> September 19, 2014] September 19, 2014<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the iphone 5 first come out? Answer:\n",
            "[QA(When did the iphone 5 first come out?) -> September 21, 2012] September 21, 2012<|endoftext|>\n",
            "Original: Question: First name of the leader of britains lib dems? Answer:\n",
            "\n",
            "Original prompt: Question: First name of the leader of britains lib dems? Answer:\n",
            "[QA(First name of the leader of britains lib dems?) -> Ed Miliband] Ed Miliband<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: First name of the leader of britains lib dems? Answer:\n",
            "[QA(First name of the leader of britains lib dems?) -> Ed\n",
            "] Ed Miliband<|endoftext|>\n",
            "Original: Question: Where was the battle of savannah fought the location of the battlefield? Answer:\n",
            "\n",
            "Original prompt: Question: Where was the battle of savannah fought the location of the battlefield? Answer:\n",
            "[QA(Where was the battle of savannah fought the location of the battlefield?) -> The battle of Savannah was fought in Savannah, Georgia.] Savannah<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where was the battle of savannah fought the location of the battlefield? Answer:\n",
            "[QA(Where was the battle of savannah fought the location of the battlefield?) -> Savannah, Georgia, USA] Savannah<|endoftext|>\n",
            "Original: Question: When does jane the virgin episode 18 come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does jane the virgin episode 18 come out? Answer:\n",
            "[QA(When does jane the virgin episode 18 come out?) -> October 5, 2017] October 5, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does jane the virgin episode 18 come out? Answer:\n",
            "[QA(When does jane the virgin episode 18 come out?) -> The release date greatly depends on the season as there are total five seasons of \"Jane the Virgin\". However, the specific information for each season is as follows: \n",
            "\n",
            "- Season 1 Episode 18: April 6, 2015\n",
            "- Season 2 Episode 18: March 28, 2016\n",
            "- Season 3 Episode 18: May 1, 2017\n",
            "- Season 4 Episode 18: April 20, 2018\n",
            "- Season 5 doesn't have an episode 18 as it only has 19 episodes in total.] April 6, 2015, March 28, 2016, May 1, 2017, April 20, 2018<|endoftext|>\n",
            "Original: Question: When did health care workers first use chlorine solution to decontaminate hands? Answer:\n",
            "\n",
            "Original prompt: Question: When did health care workers first use chlorine solution to decontaminate hands? Answer:\n",
            "[QA(When did health care workers first use chlorine solution to decontaminate hands?) -> March of 1945.] March of 1945<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did health care workers first use chlorine solution to decontaminate hands? Answer:\n",
            "[QA(When did health care workers first use chlorine solution to decontaminate hands?) -> There's no exact known date, but the use of chlorine as a disinfectant in healthcare settings became more common in the late 19th and early 20th century.] the late 19th century<|endoftext|>\n",
            "Original: Question: When did the vietnam war start for us? Answer:\n",
            "\n",
            "Original prompt: Question: When did the vietnam war start for us? Answer:\n",
            "[QA(When did the vietnam war start for us?) -> The Vietnam War started in 1954.] 1954<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the vietnam war start for us? Answer:\n",
            "[QA(When did the vietnam war start for us?) -> The Vietnam War started for the US in 1965.] 1965<|endoftext|>\n",
            "Original: Question: When did season 2 of seven deadly sins come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did season 2 of seven deadly sins come out? Answer:\n",
            "[QA(When did season 2 of seven deadly sins come out?) -> Season 2 of Seven Deadly Sins came out in 2015.] 2015<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did season 2 of seven deadly sins come out? Answer:\n",
            "[QA(When did season 2 of seven deadly sins come out?) -> January 13, 2018] January 13, 2018<|endoftext|>\n",
            "Original: Question: Who has the highest career goals between ronaldo and messi? Answer:\n",
            "\n",
            "Original prompt: Question: Who has the highest career goals between ronaldo and messi? Answer:\n",
            "[QA(Who has the highest career goals between ronaldo and messi?) -> Cristiano Ronaldo] Cristiano Ronaldo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has the highest career goals between ronaldo and messi? Answer:\n",
            "[QA(Who has the highest career goals between ronaldo and messi?) -> Lionel Messi] Lionel Messi<|endoftext|>\n",
            "Original: Question: Where did cliff richard come in the eurovision? Answer:\n",
            "\n",
            "Original prompt: Question: Where did cliff richard come in the eurovision? Answer:\n",
            "[QA(Where did cliff richard come in the eurovision?) -> Cliff Richard came in the Eurovision in the United Kingdom.] England<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did cliff richard come in the eurovision? Answer:\n",
            "[QA(Where did cliff richard come in the eurovision?) -> Cliff Richard represented the UK in Eurovision twice, coming in 2nd place each time in 1968 and 1973.] 1968, 1973<|endoftext|>\n",
            "Original: Question: What are the names of the cinque ports? Answer:\n",
            "\n",
            "Original prompt: Question: What are the names of the cinque ports? Answer:\n",
            "[QA(What are the names of the cinque ports?) -> Plymouth, Portsmouth, Poole, Falmouth and Dartmouth.] Plymouth, Portsmouth, Poole, Falmouth and Dartmouth<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What are the names of the cinque ports? Answer:\n",
            "[QA(What are the names of the cinque ports?) -> Hastings, New Romney, Hythe, Dover, and Sandwich.] Hastings, New Romney, Hythe, Dover, and Sandwich<|endoftext|>\n",
            "Original: Question: Who is the original singer of only you? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the original singer of only you? Answer:\n",
            "[QA(Who is the original singer of only you?) -> Elton John] Elton John<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the original singer of only you? Answer:\n",
            "[QA(Who is the original singer of only you?) -> The Platters] The Platters<|endoftext|>\n",
            "Original: Question: Most premier league goals in a season by a player? Answer:\n",
            "\n",
            "Original prompt: Question: Most premier league goals in a season by a player? Answer:\n",
            "[QA(Most premier league goals in a season by a player?) -> Cristiano Ronaldo] Cristiano Ronaldo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Most premier league goals in a season by a player? Answer:\n",
            "[QA(Most premier league goals in a season by a player?) -> 32 goals by Mohamed Salah in 2017-2018 season.] 32<|endoftext|>\n",
            "Original: Question: When did india win its first cricket world cup? Answer:\n",
            "\n",
            "Original prompt: Question: When did india win its first cricket world cup? Answer:\n",
            "[QA(When did india win its first cricket world cup?) -> 1971] 1971<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did india win its first cricket world cup? Answer:\n",
            "[QA(When did india win its first cricket world cup?) -> India won its first Cricket World Cup in 1983.] 1983<|endoftext|>\n",
            "Original: Question: Where did the idea of cats having nine lives come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where did the idea of cats having nine lives come from? Answer:\n",
            "[QA(Where did the idea of cats having nine lives come from?) -> The notion of a cat having nine lives comes from a medieval European belief that cats have nine lives.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did the idea of cats having nine lives come from? Answer:\n",
            "[QA(Where did the idea of cats having nine lives come from?) -> The idea of cats having nine lives comes from ancient myths and folklore, particularly from ancient Egypt which worshipped cats and believed they held protective qualities.] Egyptian mythology<|endoftext|>\n",
            "Original: Question: When did the home service became radio 4? Answer:\n",
            "\n",
            "Original prompt: Question: When did the home service became radio 4? Answer:\n",
            "[QA(When did the home service became radio 4?) -> In<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the home service became radio 4? Answer:\n",
            "[QA(When did the home service became radio 4?) -> In 1967.] 1967<|endoftext|>\n",
            "Original: Question: Who plays abby's mother on girlfriends guide to divorce? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays abby's mother on girlfriends guide to divorce? Answer:\n",
            "[QA(Who plays abby's mother on girlfriends guide to divorce?) -> Margo Martindale] Margo Martindale<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays abby's mother on girlfriends guide to divorce? Answer:\n",
            "[QA(Who plays abby's mother on girlfriends guide to divorce?) -> Bernadette Peters] Bernadette Peters<|endoftext|>\n",
            "Original: Question: Where did gb come in the 2012 olympics? Answer:\n",
            "\n",
            "Original prompt: Question: Where did gb come in the 2012 olympics? Answer:\n",
            "[QA(Where did gb come in the 2012 olympics?) -> The 2012 Summer Olympics were held in London, England.] London<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did gb come in the 2012 olympics? Answer:\n",
            "[QA(Where did gb come in the 2012 olympics?) -> GB (Great Britain) came third in the 2012 Olympics.] London<|endoftext|>\n",
            "Original: Question: What were the cause of the american civil war? Answer:\n",
            "\n",
            "Original prompt: Question: What were the cause of the american civil war? Answer:\n",
            "[QA(What were the cause of the american civil war?) -> The American Civil War was caused by disagreements over the issue of slavery.] the issue of slavery<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What were the cause of the american civil war? Answer:\n",
            "[QA(What were the cause of the american civil war?) -> Slavery and states' rights disagreements.] slavery and states' rights disagreements<|endoftext|>\n",
            "Original: Question: Who moves first in chess black or white? Answer:\n",
            "\n",
            "Original prompt: Question: Who moves first in chess black or white? Answer:\n",
            "[QA(Who moves first in chess black or white?) -> In chess, the player with the white pieces moves first.] the white pieces<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who moves first in chess black or white? Answer:\n",
            "[QA(Who moves first in chess black or white?) -> White.] the white player<|endoftext|>\n",
            "Original: Question: Who plays the mother in my friend dahmer? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays the mother in my friend dahmer? Answer:\n",
            "[QA(Who plays the mother in my friend dahmer?) -> The mother in my friend Dahmer is played by Margot Kidder.] Margot Kidder<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays the mother in my friend dahmer? Answer:\n",
            "[QA(Who plays the mother in my friend dahmer?) -> Anne Heche] Anne Heche<|endoftext|>\n",
            "Original: Question: When is the last episode of the fosters season 5? Answer:\n",
            "\n",
            "Original prompt: Question: When is the last episode of the fosters season 5? Answer:\n",
            "[QA(When is the last episode of the fosters season 5?) -> The last episode of the Fosters season 5 is \"Don't Let Me Die\" on December 9, 2018.] December 9, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is the last episode of the fosters season 5? Answer:\n",
            "[QA(When is the last episode of the fosters season 5?) -> June 6, 2018] June 6, 2018<|endoftext|>\n",
            "Original: Question: Name of the main ape in planet of the apes? Answer:\n",
            "\n",
            "Original prompt: Question: Name of the main ape in planet of the apes? Answer:\n",
            "[QA(Name of the main ape in planet of the apes?) -> King Kong] King Kong<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Name of the main ape in planet of the apes? Answer:\n",
            "[QA(Name of the main ape in planet of the apes?) -> Caesar] Caesar<|endoftext|>\n",
            "Original: Question: Who played dogberry in much ado about nothing? Answer:\n",
            "\n",
            "Original prompt: Question: Who played dogberry in much ado about nothing? Answer:\n",
            "[QA(Who played dogberry in much ado about nothing?) -> Jack Worthing] Jack Worthing<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played dogberry in much ado about nothing? Answer:\n",
            "[QA(Who played dogberry in much ado about nothing?) -> In the 1993 film version, Dogberry was played by Michael Keaton. In the 2012 film version, the character was played by Nathan Fillion.] Nathan Fillion<|endoftext|>\n",
            "Original: Question: When was the lend lease act extended to the soviet union? Answer:\n",
            "\n",
            "Original prompt: Question: When was the lend lease act extended to the soviet union? Answer:\n",
            "[QA(When was the lend lease act extended to the soviet union?) -> December 31, 1944] December 31, 1944<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the lend lease act extended to the soviet union? Answer:\n",
            "[QA(When was the lend lease act extended to the soviet union?) -> October 1941] October 1941<|endoftext|>\n",
            "Original: Question: Who devised the first set of rules in basketball? Answer:\n",
            "\n",
            "Original prompt: Question: Who devised the first set of rules in basketball? Answer:\n",
            "[QA(Who devised the first set of rules in basketball?) -> James Naismith] James Naismith<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who devised the first set of rules in basketball? Answer:\n",
            "[QA(Who devised the first set of rules in basketball?) -> Dr. James Naismith] Dr. James Naismith<|endoftext|>\n",
            "Original: Question: When does the edge of seventeen come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does the edge of seventeen come out? Answer:\n",
            "[QA(When does the edge of seventeen come out?) -> The edge of seventeen comes out on the 17th of each month.] the 17th of each month<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does the edge of seventeen come out? Answer:\n",
            "[QA(When does the edge of seventeen come out?) -> The Edge of Seventeen premiered in the United States on November 18, 2016.] November 18, 2016<|endoftext|>\n",
            "Original: Question: What year did the chevrolet camaro come out? Answer:\n",
            "\n",
            "Original prompt: Question: What year did the chevrolet camaro come out? Answer:\n",
            "[QA(What year did the chevrolet camaro come out?) -> 1969] 1969<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What year did the chevrolet camaro come out? Answer:\n",
            "[QA(What year did the chevrolet camaro come out?) -> 1966] 1966<|endoftext|>\n",
            "Original: Question: When is the show six coming back on? Answer:\n",
            "\n",
            "Original prompt: Question: When is the show six coming back on? Answer:\n",
            "[QA(When is the show six coming back on?) -><|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is the show six coming back on? Answer:\n",
            "[QA(When is the show six coming back on?) -> As of my current knowledge, there has been no announcement about the show \"Six\" returning for a third season.] April 8, 2018<|endoftext|>\n",
            "Original: Question: How many independent states emerged after the collapse of the soviet union? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many independent states emerged after the collapse of the soviet union? Answer:\n",
            "[Calculator(8+3)]=11 thus answer is 11 (independent states).<|endoftext|>\n",
            "Computed answer was: 11.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many independent states emerged after the collapse of the soviet union? Answer:\n",
            "[Calculator(8+3)]=11.0 thus answer is 11 (independent states).<|endoftext|>\n",
            "Original: Question: When is the final show of americas got talent 2017? Answer:\n",
            "\n",
            "Original prompt: Question: When is the final show of americas got talent 2017? Answer:\n",
            "[QA(When is the final show of americas got talent 2017?) -> December 7, 2017] December 7, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is the final show of americas got talent 2017? Answer:\n",
            "[QA(When is the final show of americas got talent 2017?) -> September 20, 2017\n",
            "] September 20, 2017<|endoftext|>\n",
            "Original: Question: Which area in the united states has the most serious urban smog problem? Answer:\n",
            "\n",
            "Original prompt: Question: Which area in the united states has the most serious urban smog problem? Answer:\n",
            "[QA(Which area in the united states has the most serious urban smog problem?) -> The United States has no area that has the most serious urban smog problem.] the southeast<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which area in the united states has the most serious urban smog problem? Answer:\n",
            "[QA(Which area in the united states has the most serious urban smog problem?) -> Los Angeles, California] Los Angeles<|endoftext|>\n",
            "Original: Question: What was the last year chevy made the trailblazer? Answer:\n",
            "\n",
            "Original prompt: Question: What was the last year chevy made the trailblazer? Answer:\n",
            "[QA(What was the last year chevy made the trailblazer?) -> 2017] 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the last year chevy made the trailblazer? Answer:\n",
            "[QA(What was the last year chevy made the trailblazer?) -> 2020] 2020<|endoftext|>\n",
            "Original: Question: When was the last time we had total eclipse? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last time we had total eclipse? Answer:\n",
            "[QA(When was the last time we had total eclipse?) -> April 8, 2017] April 8, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last time we had total eclipse? Answer:\n",
            "[QA(When was the last time we had total eclipse?) -> December 14, 2020] December 14, 2020<|endoftext|>\n",
            "Original: Question: Who takes care of animals in a zoo? Answer:\n",
            "\n",
            "Original prompt: Question: Who takes care of animals in a zoo? Answer:\n",
            "[QA(Who takes care of animals in a zoo?) -> The keepers of the animals in a zoo.] the keepers of the animals in a zoo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who takes care of animals in a zoo? Answer:\n",
            "[QA(Who takes care of animals in a zoo?) -> Zookeepers.] Zookeepers<|endoftext|>\n",
            "Original: Question: When did law and order first air on tv? Answer:\n",
            "\n",
            "Original prompt: Question: When did law and order first air on tv? Answer:\n",
            "[QA(When did law and order first air on tv?) -> 1977] 1977<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did law and order first air on tv? Answer:\n",
            "[QA(When did law and order first air on tv?) -> September 13, 1990] September 13, 1990<|endoftext|>\n",
            "Original: Question: Which country won the icc under 19 cricket world cup 2018? Answer:\n",
            "\n",
            "Original prompt: Question: Which country won the icc under 19 cricket world cup 2018? Answer:\n",
            "[QA(Which country won the icc under 19 cricket world cup 2018?) -> India] India<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which country won the icc under 19 cricket world cup 2018? Answer:\n",
            "[QA(Which country won the icc under 19 cricket world cup 2018?) -> India] India<|endoftext|>\n",
            "Original: Question: How many seasons of sex and the coty are there? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many seasons of sex and the coty are there? Answer:\n",
            "[Calculator(6)]+[Calculator(2)]=8 thus answer is 8 (seasons).<|endoftext|>\n",
            "Computed answer was: 6.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 8.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 10.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 12.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 14.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many seasons of sex and the coty are there? Answer:\n",
            "[Calculator(6)]=6.0 seasons of sex and the coty; [Calculator(8)]=8.0 seasons of sex and the coty; [Calculator(10)]=10.0 seasons of sex and the coty; [Calculator(12)]=12.0 seasons of sex and the coty; [Calculator(14)]=14.0 seasons of sex and the coty; [Calculator(16)]=16.0 seasons of sex and the coty; [Calculator(18)]=18.0 seasons of sex and the coty; [Calculator(20)]=20.0 seasons of sex and the coty; [Calculator(22)]=22.0 seasons of sex and the coty; [Calculator(24)]=24.0 seasons of sex and the coty; [Calculator(26)]=26.0 seasons of sex and the coty; [Calculator(28)]=28.0 seasons of sex and the cot\n",
            "Original: Question: Who played eric in head of the class? Answer:\n",
            "\n",
            "Original prompt: Question: Who played eric in head of the class? Answer:\n",
            "[QA(Who played eric in head of the class?) -> Eric McCormack] Eric McCormack<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played eric in head of the class? Answer:\n",
            "[QA(Who played eric in head of the class?) -> Brian Robbins] Brian Robbins<|endoftext|>\n",
            "Original: Question: What's the name of a one piece ski suit? Answer:\n",
            "\n",
            "Original prompt: Question: What's the name of a one piece ski suit? Answer:\n",
            "[QA(What's the name of a one piece ski suit?) -> a one-piece ski suit is a ski suit that covers the whole body.] ski suit<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What's the name of a one piece ski suit? Answer:\n",
            "[QA(What's the name of a one piece ski suit?) -> Onesie.] Onesie<|endoftext|>\n",
            "Original: Question: Who played the hatter in alice through the looking glass? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the hatter in alice through the looking glass? Answer:\n",
            "[QA(Who played the hatter in alice through the looking glass?) -> Lewis Carroll] Lewis Carroll<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the hatter in alice through the looking glass? Answer:\n",
            "[QA(Who played the hatter in alice through the looking glass?) -> Johnny Depp] Johnny Depp<|endoftext|>\n",
            "Original: Question: When did france give the us the statue of liberty? Answer:\n",
            "\n",
            "Original prompt: Question: When did france give the us the statue of liberty? Answer:\n",
            "[QA(When did france give the us the statue of liberty?) -> 1789] 1789<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did france give the us the statue of liberty? Answer:\n",
            "[QA(When did france give the us the statue of liberty?) -> October 28, 1886] October 28, 1886<|endoftext|>\n",
            "Original: Question: Who talks for lotso in toy story 3? Answer:\n",
            "\n",
            "Original prompt: Question: Who talks for lotso in toy story 3? Answer:\n",
            "[QA(Who talks for lotso in toy story 3?) -> Lotso] Lotso<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who talks for lotso in toy story 3? Answer:\n",
            "[QA(Who talks for lotso in toy story 3?) -> Ned Beatty] Ned Beatty<|endoftext|>\n",
            "Original: Question: Who was the leader of vietnam during the cold war? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the leader of vietnam during the cold war? Answer:\n",
            "[QA(Who was the leader of vietnam during the cold war?) -> Ngo Dinh Diem] Ngo Dinh Diem<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the leader of vietnam during the cold war? Answer:\n",
            "[QA(Who was the leader of vietnam during the cold war?) -> Ho Chi Minh] Ho Chi Minh<|endoftext|>\n",
            "Original: Question: Who sang i wouldn't have missed it for the world? Answer:\n",
            "\n",
            "Original prompt: Question: Who sang i wouldn't have missed it for the world? Answer:\n",
            "[QA(Who sang i wouldn't have missed it for the world?) -> Elton John] Elton John<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sang i wouldn't have missed it for the world? Answer:\n",
            "[QA(Who sang i wouldn't have missed it for the world?) -> Ronnie Milsap] Ronnie Milsap<|endoftext|>\n",
            "Original: Question: Who sees the ghost of hamlet's father first? Answer:\n",
            "\n",
            "Original prompt: Question: Who sees the ghost of hamlet's father first? Answer:\n",
            "[QA(Who sees the ghost of hamlet's father first?) -> Hamlet's father is the first to see the ghost of Hamlet's father.] Hamlet<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sees the ghost of hamlet's father first? Answer:\n",
            "[QA(Who sees the ghost of hamlet's father first?) -> The guard Marcellus.] Marcellus<|endoftext|>\n",
            "Original: Question: The dorsal part of a turtle's shell is called the? Answer:\n",
            "\n",
            "Original prompt: Question: The dorsal part of a turtle's shell is called the? Answer:\n",
            "[QA(The dorsal part of a turtle's shell is called the?) -> plastron] plastron<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The dorsal part of a turtle's shell is called the? Answer:\n",
            "[QA(The dorsal part of a turtle's shell is called the?) -> Carapace] carapace<|endoftext|>\n",
            "Original: Question: What country has a black yellow and orange flag? Answer:\n",
            "\n",
            "Original prompt: Question: What country has a black yellow and orange flag? Answer:\n",
            "[QA(What country has a black yellow and orange flag?) -> South Africa] South Africa<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What country has a black yellow and orange flag? Answer:\n",
            "[QA(What country has a black yellow and orange flag?) -> Uganda] Uganda<|endoftext|>\n",
            "Original: Question: What is a type of mechanical wave motion in an elastic medium? Answer:\n",
            "\n",
            "Original prompt: Question: What is a type of mechanical wave motion in an elastic medium? Answer:\n",
            "[QA(What is a type of mechanical wave motion in an elastic medium?) -> A mechanical wave in an elastic medium is called a longitudinal wave.] longitudinal wave<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is a type of mechanical wave motion in an elastic medium? Answer:\n",
            "[QA(What is a type of mechanical wave motion in an elastic medium?) -> Sound wave] A sound wave in an elastic medium.<|endoftext|>\n",
            "Original: Question: When was the first human development report published? Answer:\n",
            "\n",
            "Original prompt: Question: When was the first human development report published? Answer:\n",
            "[QA(When was the first human development report published?) -> The first Human Development Report was published in 1974.] 1974<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the first human development report published? Answer:\n",
            "[QA(When was the first human development report published?) -> 1990] 1990<|endoftext|>\n",
            "Original: Question: What is the area code for montreal canada? Answer:\n",
            "\n",
            "Original prompt: Question: What is the area code for montreal canada? Answer:\n",
            "[QA(What is the area code for montreal canada?) -> 819] 819<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the area code for montreal canada? Answer:\n",
            "[QA(What is the area code for montreal canada?) -> 514] 514<|endoftext|>\n",
            "Original: Question: What episode of wizards of waverly place does juliet get taken by the mummy? Answer:\n",
            "\n",
            "Original prompt: Question: What episode of wizards of waverly place does juliet get taken by the mummy? Answer:\n",
            "[QA(What episode of wizards of waverly place does juliet get taken by the mummy?) -> \"The Mummy's Curse\"] \"The Mummy's Curse\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What episode of wizards of waverly place does juliet get taken by the mummy? Answer:\n",
            "[QA(What episode of wizards of waverly place does juliet get taken by the mummy?) -> The episode is titled \"Wizards vs. Werewolves.\"] \"Wizards vs. Werewolves\"<|endoftext|>\n",
            "Original: Question: The munsters today and mcmillan & wife star john? Answer:\n",
            "\n",
            "Original prompt: Question: The munsters today and mcmillan & wife star john? Answer:\n",
            "The munsters today and mcmillan & wife star john? [QA(The munsters today and mcmillan & wife star john?) -> The Munsters Today and McMillan & Wife Star John] The Munsters Today and McMillan & Wife Star John<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The munsters today and mcmillan & wife star john? Answer:\n",
            "The munsters today and mcmillan & wife star john? [QA(The munsters today and mcmillan & wife star john?) -> Schuck] The Munsters Today and McMillan & Wife Star John<|endoftext|>\n",
            "Original: Question: Who played the wicked witch on wizard of oz? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the wicked witch on wizard of oz? Answer:\n",
            "[QA(Who played the wicked witch on wizard of oz?) -> Helena Bonham-Carter] Helena Bonham-Carter<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the wicked witch on wizard of oz? Answer:\n",
            "[QA(Who played the wicked witch on wizard of oz?) -> Margaret Hamilton] Margaret Hamilton<|endoftext|>\n",
            "Original: Question: Where is human chorionic gonadotropin (hcg) produced? Answer:\n",
            "\n",
            "Original prompt: Question: Where is human chorionic gonadotropin (hcg) produced? Answer:\n",
            "[QA(Where is human chorionic gonadotropin (hcg) produced?) -> Human chorionic gonadotropin (hcg) is produced in the placenta.] the placenta<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is human chorionic gonadotropin (hcg) produced? Answer:\n",
            "[QA(Where is human chorionic gonadotropin (hcg) produced?) -> Human chorionic gonadotropin (hcg) is produced in the placenta.] the placenta<|endoftext|>\n",
            "Original: Question: How many chapters in alice through the looking glass? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many chapters in alice through the looking glass? Answer:\n",
            "[Calculator(5-1)]=4 thus answer is 4 (chapters).<|endoftext|>\n",
            "Computed answer was: 4.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many chapters in alice through the looking glass? Answer:\n",
            "[Calculator(5-1)]=4.0 thus answer is 4.0 (chapters).<|endoftext|>\n",
            "Original: Question: When does boku no hero academia anime come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does boku no hero academia anime come out? Answer:\n",
            "[QA(When does boku no hero academia anime come out?) -> The first season of Boku No Hero Academia was released on July 3, 2017.] July 3, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does boku no hero academia anime come out? Answer:\n",
            "[QA(When does boku no hero academia anime come out?) -> The \"Boku no Hero Academia\" anime first premiered on April 3, 2016.] April 3, 2016<|endoftext|>\n",
            "Original: Question: Who was the last roman emperor and what happened to him? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the last roman emperor and what happened to him? Answer:\n",
            "[QA(Who was the last roman emperor and what happened to him?) -> Marcus Aurelius] Marcus Aurelius<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the last roman emperor and what happened to him? Answer:\n",
            "[QA(Who was the last roman emperor and what happened to him?) -> The last Roman Emperor was Romulus Augustus. He was deposed by the Germanic King Odoacer in 476 AD.] Odoacer<|endoftext|>\n",
            "Original: Question: When were seat belts first required in cars? Answer:\n",
            "\n",
            "Original prompt: Question: When were seat belts first required in cars? Answer:\n",
            "[QA(When were seat belts first required in cars?) -> Seat belts were first required in cars in the United States in the late 1930s.] the late 1930s<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When were seat belts first required in cars? Answer:\n",
            "[QA(When were seat belts first required in cars?) -> 1968] 1968<|endoftext|>\n",
            "Original: Question: When did the taliban start to take over pakistan? Answer:\n",
            "\n",
            "Original prompt: Question: When did the taliban start to take over pakistan? Answer:\n",
            "[QA(When did the taliban start to take over pakistan?) -> September 2001] September 11, 2001<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the taliban start to take over pakistan? Answer:\n",
            "[QA(When did the taliban start to take over pakistan?) -> The Taliban began increasing their influence in Pakistan around 2004.] 2004<|endoftext|>\n",
            "Original: Question: Old 7 wonders of the world name list? Answer:\n",
            "\n",
            "Original prompt: Question: Old 7 wonders of the world name list? Answer:\n",
            "[QA(Old 7 wonders of the world name list?) -> The Seven Wonders of the Ancient World were the Pyramids of Giza, the Hanging Gardens of Babylon, the Statue of Zeus at Olympia, the Temple of Artemis at Ephesus, the Mausoleum at Halicarnassus, the Colossus of Rhodes, and the Lighthouse of Alexandria.] Egypt<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Old 7 wonders of the world name list? Answer:\n",
            "[QA(Old 7 wonders of the world name list?) -> 1. Great Pyramid of Giza.\n",
            "2. Hanging Gardens of Babylon.\n",
            "3. Statue of Zeus at Olympia.\n",
            "4. Temple of Artemis at Ephesus.\n",
            "5. Mausoleum at Halicarnassus.\n",
            "6. Colossus of Rhodes.\n",
            "7. Lighthouse of Alexandria.] 1. Great Pyramid of Giza. 2. Hanging Gardens of Babylon. 3. Statue of Zeus at Olympia. 4. Temple of Artemis at Ephesus. 5. Mausoleum at Halicarnassus. 6. Colossus of Rhodes. 7. Lighthouse of Alexandria.<|endoftext|>\n",
            "Original: Question: When did they stop making the crown victoria? Answer:\n",
            "\n",
            "Original prompt: Question: When did they stop making the crown victoria? Answer:\n",
            "[QA(When did they stop making the crown victoria?) -> 1898] 1898<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did they stop making the crown victoria? Answer:\n",
            "[QA(When did they stop making the crown victoria?) -> In 2011.] 2011<|endoftext|>\n",
            "Original: Question: Who plays cuff in stuck in the middle? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays cuff in stuck in the middle? Answer:\n",
            "[QA(Who plays cuff in stuck in the middle?) -> Peter MacNicol] Peter MacNicol<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays cuff in stuck in the middle? Answer:\n",
            "[QA(Who plays cuff in stuck in the middle?) -> Ricardo Hurtado] Ricardo Hurtado<|endoftext|>\n",
            "Original: Question: Where did the last name turner originate from? Answer:\n",
            "\n",
            "Original prompt: Question: Where did the last name turner originate from? Answer:\n",
            "[QA(Where did the last name turner originate from?) -> The last name Turner originated from England.] England<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did the last name turner originate from? Answer:\n",
            "[QA(Where did the last name turner originate from?) -> The last name Turner originated from England.] England<|endoftext|>\n",
            "Original: Question: Where did the church of latter day saints originated? Answer:\n",
            "\n",
            "Original prompt: Question: Where did the church of latter day saints originated? Answer:\n",
            "[QA(Where did the church of latter day saints originated?) -> The Church of Latter-day Saints was founded in 1830.] Nauvoo, Illinois<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did the church of latter day saints originated? Answer:\n",
            "[QA(Where did the church of latter day saints originated?) -> The Church of Latter Day Saints originated in Fayette, New York, USA.] Fayette, New York, USA<|endoftext|>\n",
            "Original: Question: Who plays the dog catcher in lady and the tramp 2? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays the dog catcher in lady and the tramp 2? Answer:\n",
            "[QA(Who plays the dog catcher in lady and the tramp 2?) -> David McCallum] David McCallum<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays the dog catcher in lady and the tramp 2? Answer:\n",
            "[QA(Who plays the dog catcher in lady and the tramp 2?) -> Jeff Bennett] Jeff Bennett<|endoftext|>\n",
            "Original: Question: What is the population in sutherland springs texas? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: What is the population in sutherland springs texas? Answer:\n",
            "[Calculator(14,000)]=14,000 thus answer is 14,000 (people).<|endoftext|>\n",
            "Computed answer was: 14000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the population in sutherland springs texas? Answer:\n",
            "[Calculator(14,000)]=14000.0 thus answer is 14,000 (people).<|endoftext|>\n",
            "Original: Question: When did league of nations become united nations? Answer:\n",
            "\n",
            "Original prompt: Question: When did league of nations become united nations? Answer:\n",
            "[QA(When did league of nations become united nations?) -> 1945] 1945<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did league of nations become united nations? Answer:\n",
            "[QA(When did league of nations become united nations?) -> The League of Nations was dissolved on April 20, 1946 and replaced by the United Nations in October 1945.] October 24, 1945<|endoftext|>\n",
            "Original: Question: When does rachel find out mike didn't go to harvard? Answer:\n",
            "\n",
            "Original prompt: Question: When does rachel find out mike didn't go to harvard? Answer:\n",
            "[QA(When does rachel find out mike didn't go to harvard?) -> In the episode \"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does rachel find out mike didn't go to harvard? Answer:\n",
            "[QA(When does rachel find out mike didn't go to harvard?) -> In Season 2, Episode 16 titled \"War\".] Season 2, Episode 16<|endoftext|>\n",
            "Original: Question: The vertical groove in the upper lip is the? Answer:\n",
            "\n",
            "Original prompt: Question: The vertical groove in the upper lip is the? Answer:\n",
            "[QA(The vertical groove in the upper lip is the?) -> Vermillion border] Vermillion border<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The vertical groove in the upper lip is the? Answer:\n",
            "[QA(The vertical groove in the upper lip is the?) -> Philtrum] Philtrum<|endoftext|>\n",
            "Original: Question: When did slender man the movie come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did slender man the movie come out? Answer:\n",
            "[QA(When did slender man the movie come out?) -> October 16, 1999] October 16, 1999<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did slender man the movie come out? Answer:\n",
            "[QA(When did slender man the movie come out?) -> August 10, 2018] August 10, 2018<|endoftext|>\n",
            "Original: Question: Who did houston play in the world series? Answer:\n",
            "\n",
            "Original prompt: Question: Who did houston play in the world series? Answer:\n",
            "[QA(Who did houston play in the world series?) -> The Houston Astros] the Houston Astros<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who did houston play in the world series? Answer:\n",
            "[QA(Who did houston play in the world series?) -> Houston Astros played against the Washington Nationals in the 2019 World Series and against the Los Angeles Dodgers in the 2017 World Series.] Washington Nationals, Los Angeles Dodgers<|endoftext|>\n",
            "Original: Question: Who plays the voice of mittens in bolt? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays the voice of mittens in bolt? Answer:\n",
            "[QA(Who plays the voice of mittens in bolt?) -> Tom Hanks] Tom Hanks<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays the voice of mittens in bolt? Answer:\n",
            "[QA(Who plays the voice of mittens in bolt?) -> Susie Essman] Susie Essman<|endoftext|>\n",
            "Original: Question: How to identify amino acid sequence of a protein? Answer:\n",
            "\n",
            "Original prompt: Question: How to identify amino acid sequence of a protein? Answer:\n",
            "[QA(How to identify amino acid sequence of a protein?) -> The amino acid sequence of a protein can be identified by comparing it to the amino acid sequence of known proteins.] the amino acid sequence of a protein can be identified by comparing it to the amino acid sequence of known proteins.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How to identify amino acid sequence of a protein? Answer:\n",
            "[QA(How to identify amino acid sequence of a protein?) -> By using techniques such as Edman degradation or Mass spectrometry.] the amino acid sequence of a protein<|endoftext|>\n",
            "Original: Question: Who made up the periodic table of elements? Answer:\n",
            "\n",
            "Original prompt: Question: Who made up the periodic table of elements? Answer:\n",
            "[QA(Who made up the periodic table of elements?) -> The periodic table of elements was made up by Dmitri Mendeleev.] Dmitri Mendeleev<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who made up the periodic table of elements? Answer:\n",
            "[QA(Who made up the periodic table of elements?) -> Dmitri Mendeleev] Dmitri Mendeleev<|endoftext|>\n",
            "Original: Question: Who sent the first english settlers to jamestown? Answer:\n",
            "\n",
            "Original prompt: Question: Who sent the first english settlers to jamestown? Answer:\n",
            "[QA(Who sent the first english settlers to jamestown?) -> The Virginia Company of London.] Sir Walter Raleigh<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sent the first english settlers to jamestown? Answer:\n",
            "[QA(Who sent the first english settlers to jamestown?) -> The Virginia Company of London.] the Virginia Company of London<|endoftext|>\n",
            "Original: Question: Who is the chief minister of rajasthan 2017? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the chief minister of rajasthan 2017? Answer:\n",
            "[QA(Who is the chief minister of rajasthan 2017?) -> Ashok Gehlot] Ashok Gehlot<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the chief minister of rajasthan 2017? Answer:\n",
            "[QA(Who is the chief minister of rajasthan 2017?) -> Vasundhara Raje] Vasundhara Raje<|endoftext|>\n",
            "Original: Question: Who sings how can this happen to me? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings how can this happen to me? Answer:\n",
            "[QA(Who sings how can this happen to me?) -> How can this happen to me?] How can this happen to me?<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings how can this happen to me? Answer:\n",
            "[QA(Who sings how can this happen to me?) -> Simple Plan] Simple Plan<|endoftext|>\n",
            "Original: Question: Who is the girl in the bon jovi it's my life video? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the girl in the bon jovi it's my life video? Answer:\n",
            "[QA(Who is the girl in the bon jovi it's my life video?) -> LeAnn Rimes] LeAnn Rimes<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the girl in the bon jovi it's my life video? Answer:\n",
            "[QA(Who is the girl in the bon jovi it's my life video?) -> Shania Twain] Shania Twain<|endoftext|>\n",
            "Original: Question: When must a suspect be read their miranda rights? Answer:\n",
            "\n",
            "Original prompt: Question: When must a suspect be read their miranda rights? Answer:\n",
            "[QA(When must a suspect be read their miranda rights?) -> A suspect must be read their Miranda rights when they are taken into custody.] immediately<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When must a suspect be read their miranda rights? Answer:\n",
            "[QA(When must a suspect be read their miranda rights?) -> When they are in police custody and being interrogated.] the day of the arrest or the day after the arrest<|endoftext|>\n",
            "Original: Question: Who has played big brother the most times? Answer:\n",
            "\n",
            "Original prompt: Question: Who has played big brother the most times? Answer:\n",
            "[QA(Who has played big brother the most times?) -> Tom Bergeron] Tom Bergeron<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has played big brother the most times? Answer:\n",
            "[QA(Who has played big brother the most times?) -> Mike \"Boogie\" Malin] Mike \"Boogie\" Malin<|endoftext|>\n",
            "Original: Question: Who wrote i'll put a spell on you? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote i'll put a spell on you? Answer:\n",
            "[QA(Who wrote i'll put a spell on you?) -> Toni Braxton] Toni Braxton<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote i'll put a spell on you? Answer:\n",
            "[QA(Who wrote i'll put a spell on you?) -> Screamin' Jay Hawkins] Screamin' Jay Hawkins<|endoftext|>\n",
            "Original: Question: When does the movie my little pony come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does the movie my little pony come out? Answer:\n",
            "[QA(When does the movie my little pony come out?) -> The movie \"My Little Pony: Equestria Girls\" was released on June 2, 2017.] June 2, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does the movie my little pony come out? Answer:\n",
            "[QA(When does the movie my little pony come out?) -> The movie \"My Little Pony\" was released on October 6, 2017.] October 6, 2017<|endoftext|>\n",
            "Original: Question: Who narrates the new beauty and the beast? Answer:\n",
            "\n",
            "Original prompt: Question: Who narrates the new beauty and the beast? Answer:\n",
            "[QA(Who narrates the new beauty and the beast?) -> Gaston] Gaston<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who narrates the new beauty and the beast? Answer:\n",
            "[QA(Who narrates the new beauty and the beast?) -> The new Beauty and the Beast (2017) is narrated by Hattie Morahan.] Hattie Morahan<|endoftext|>\n",
            "Original: Question: Who owned nevada before it became a state? Answer:\n",
            "\n",
            "Original prompt: Question: Who owned nevada before it became a state? Answer:\n",
            "[QA(Who owned nevada before it became a state?) -> Mexico] Mexico<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who owned nevada before it became a state? Answer:\n",
            "[QA(Who owned nevada before it became a state?) -> Mexico] Mexico<|endoftext|>\n",
            "Original: Question: What was the name of the first rover to land on mars? Answer:\n",
            "\n",
            "Original prompt: Question: What was the name of the first rover to land on mars? Answer:\n",
            "[QA(What was the name of the first rover to land on mars?) -> Viking 1] Viking 1<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the name of the first rover to land on mars? Answer:\n",
            "[QA(What was the name of the first rover to land on mars?) -> Sojourner] Sojourner is the name of the first rover to land on mars.<|endoftext|>\n",
            "Original: Question: What happened to the chicago world's fair buildings? Answer:\n",
            "\n",
            "Original prompt: Question: What happened to the chicago world's fair buildings? Answer:\n",
            "[QA(What happened to the chicago world's fair buildings?) -> The Chicago World's Fair buildings were demolished in the 1970s.] the Chicago World's Fair buildings were demolished in the 1970s.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What happened to the chicago world's fair buildings? Answer:\n",
            "[QA(What happened to the chicago world's fair buildings?) -> Most of the Chicago World's Fair buildings were temporary and were dismantled after the Fair. Only two, the Palace of Fine Arts and the World's Congress Auxiliary Building, remain today.] the Palace of Fine Arts and the World's Congress Auxiliary Building<|endoftext|>\n",
            "Original: Question: Who has got the most followers in instagram? Answer:\n",
            "\n",
            "Original prompt: Question: Who has got the most followers in instagram? Answer:\n",
            "[QA(Who has got the most followers in instagram?) -> As of November 2018, the most followers on Instagram are 1.7 billion.] 1.7 billion<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has got the most followers in instagram? Answer:\n",
            "[QA(Who has got the most followers in instagram?) -> As of late 2021, the most followed individual on Instagram is Cristiano Ronaldo.] Cristiano Ronaldo<|endoftext|>\n",
            "Original: Question: Top 10 movies to make the most money? Answer:\n",
            "\n",
            "Original prompt: Question: Top 10 movies to make the most money? Answer:\n",
            "[QA(Top 10 movies to make the most money?) -> The Lord of the Rings: The Return of the King, The Hobbit: An Unexpected Journey, The Hobbit: The Desolation of Smaug, The Hobbit: The Battle of the Five Armies, The Hunger Games: Catching Fire, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3, The Hunger Games: Mockingjay Part 1, The Hunger Games: Mockingjay Part 2, The Hunger Games: Mockingjay Part 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Top 10 movies to make the most money? Answer:\n",
            "[QA(Top 10 movies to make the most money?) -> 1. \"Avengers: Endgame\"\n",
            "2. \"Avatar\"\n",
            "3. \"Titanic\"\n",
            "4. \"Star Wars: The Force Awakens\"\n",
            "5. \"Avengers: Infinity War\"\n",
            "6. \"The Lion King\" (2019)\n",
            "7. \"The Avengers\" (2012)\n",
            "8. \"Furious 7\"\n",
            "9. \"Avengers: Age of Ultron\"\n",
            "10. \"Black Panther\"]<|endoftext|>\n",
            "Original: Question: Where does the adventures of huckleberry finn start? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the adventures of huckleberry finn start? Answer:\n",
            "[QA(Where does the adventures of huckleberry finn start?) -> The Adventures of Huckleberry Finn starts in 1853.] 1853<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the adventures of huckleberry finn start? Answer:\n",
            "[QA(Where does the adventures of huckleberry finn start?) -> The Adventures of Huckleberry Finn starts in St. Petersburg, Missouri.] St. Petersburg, Missouri<|endoftext|>\n",
            "Original: Question: Where does the avon river start in christchurch? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the avon river start in christchurch? Answer:\n",
            "[QA(Where does the avon river start in christchurch?) -> The Avon River starts in Christchurch, New Zealand.] the Avon River<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the avon river start in christchurch? Answer:\n",
            "[QA(Where does the avon river start in christchurch?) -> Avon River in Christchurch starts in the suburb of Avonhead.] Avonhead<|endoftext|>\n",
            "Original: Question: When is this season of this is us over? Answer:\n",
            "\n",
            "Original prompt: Question: When is this season of this is us over? Answer:\n",
            "[QA(When is this season of this is us over?) -> The first season of this is us is over on October 2, 2017.] October 2, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is this season of this is us over? Answer:\n",
            "[QA(When is this season of this is us over?) -> The specific ending date for each season may vary.] December 17, 2018<|endoftext|>\n",
            "Original: Question: What are the three greek orders of columns? Answer:\n",
            "\n",
            "Original prompt: Question: What are the three greek orders of columns? Answer:\n",
            "[QA(What are the three greek orders of columns?) -> The three greek orders of columns are the Cavalry, the Artillery, and the Infantry.] Cavalry, Artillery, Infantry<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What are the three greek orders of columns? Answer:\n",
            "[QA(What are the three greek orders of columns?) -> Doric, Ionic, Corinthian] Doric, Ionic, Corinthian<|endoftext|>\n",
            "Original: Question: I have a dream speech is what kind of writing? Answer:\n",
            "\n",
            "Original prompt: Question: I have a dream speech is what kind of writing? Answer:\n",
            "[QA(I have a dream speech is what kind of writing?) -> A<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: I have a dream speech is what kind of writing? Answer:\n",
            "[QA(I have a dream speech is what kind of writing?) -> Public Speech/Rhetorical Oratory] Rhetorical Oratory<|endoftext|>\n",
            "Original: Question: What does the color of guyana flag mean? Answer:\n",
            "\n",
            "Original prompt: Question: What does the color of guyana flag mean? Answer:\n",
            "[QA(What does the color of guyana flag mean?) -> The color of the Guyana flag is red, white, and blue.] red, white, and blue<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What does the color of guyana flag mean? Answer:\n",
            "[QA(What does the color of guyana flag mean?) -> The green represents agriculture and forests, white symbolizes rivers and water, the golden arrowhead indicates Guyana's mineral wealth, the black stripe stands for endurance, and the red represents zeal and dynamic nature of the nation-building.] Guyana<|endoftext|>\n",
            "Original: Question: When was ed sheeran's first album released? Answer:\n",
            "\n",
            "Original prompt: Question: When was ed sheeran's first album released? Answer:\n",
            "[QA(When was ed sheeran's first album released?) -> Ed sheeran's first album was released in 2009.] 2009<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was ed sheeran's first album released? Answer:\n",
            "[QA(When was ed sheeran's first album released?) -> September 9, 2011] September 9, 2011<|endoftext|>\n",
            "Original: Question: Where did lorelai gilmore go to high school? Answer:\n",
            "\n",
            "Original prompt: Question: Where did lorelai gilmore go to high school? Answer:\n",
            "[QA(Where did lorelai gilmore go to high school?) -> \"Lorelai Gilmore\" went to high school in \"Gilmore Girls: A Year in the Life.\"] \"Gilmore Girls: A Year in the Life\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did lorelai gilmore go to high school? Answer:\n",
            "[QA(Where did lorelai gilmore go to high school?) -> Lorelai Gilmore did not attend high school.] New York, New York<|endoftext|>\n",
            "Original: Question: Which city is known as pearl city in india? Answer:\n",
            "\n",
            "Original prompt: Question: Which city is known as pearl city in india? Answer:\n",
            "[QA(Which city is known as pearl city in india?) -> Mumbai] Mumbai<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which city is known as pearl city in india? Answer:\n",
            "[QA(Which city is known as pearl city in india?) -> Hyderabad] Hyderabad<|endoftext|>\n",
            "Original: Question: When was the last time there was a total eclipse in the united states? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last time there was a total eclipse in the united states? Answer:\n",
            "[QA(When was the last time there was a total eclipse in the united states?) -> August 21, 2017] August 21, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last time there was a total eclipse in the united states? Answer:\n",
            "[QA(When was the last time there was a total eclipse in the united states?) -> August 21, 2017] August 21, 2017<|endoftext|>\n",
            "Original: Question: A composer famous for his fugues especially the collection the well-tempered clavier? Answer:\n",
            "\n",
            "Original prompt: Question: A composer famous for his fugues especially the collection the well-tempered clavier? Answer:\n",
            "[QA(A composer famous for his fugues especially the collection the well-tempered clavier?) -> Johann Sebastian Bach] Johann Sebastian Bach<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: A composer famous for his fugues especially the collection the well-tempered clavier? Answer:\n",
            "[QA(A composer famous for his fugues especially the collection the well-tempered clavier?) -> Johann Sebastian Bach] Johann Sebastian Bach<|endoftext|>\n",
            "Original: Question: Who plays jt hellstrom on young and restless? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays jt hellstrom on young and restless? Answer:\n",
            "[QA(Who plays jt hellstrom on young and restless?) -> Peter Macon] Peter Macon<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays jt hellstrom on young and restless? Answer:\n",
            "[QA(Who plays jt hellstrom on young and restless?) -> Thad Luckinbill] Thad Luckinbill<|endoftext|>\n",
            "Original: Question: When did but im a cheerleader come out? Answer:\n",
            "\n",
            "Original prompt: Question: When did but im a cheerleader come out? Answer:\n",
            "[QA(When did but im a cheerleader come out?) -> September 21, 2017] September 21, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did but im a cheerleader come out? Answer:\n",
            "[QA(When did but im a cheerleader come out?) -> July 7, 2000] June 21, 2000<|endoftext|>\n",
            "Original: Question: When did earth's population reached 6 billion? Answer:\n",
            "\n",
            "Original prompt: Question: When did earth's population reached 6 billion? Answer:\n",
            "[QA(When did earth's population reach 6 billion?) -> July 14, 2017] July 14, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did earth's population reached 6 billion? Answer:\n",
            "[QA(When did earth's population reach 6 billion?) -> October 12, 1999] October 12, 1999<|endoftext|>\n",
            "Original: Question: What is the largest state in america by size? Answer:\n",
            "\n",
            "Original prompt: Question: What is the largest state in america by size? Answer:\n",
            "[QA(What is the largest state in america by size?) -> Alaska] Alaska<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the largest state in america by size? Answer:\n",
            "[QA(What is the largest state in america by size?) -> Alaska] the largest state in america by size is alaska<|endoftext|>\n",
            "Original: Question: Who is the girl that does the trivago advert? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the girl that does the trivago advert? Answer:\n",
            "[QA(Who is the girl that does the trivago advert?) -> In the ad, the girl is the daughter of the owner of trivago.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the girl that does the trivago advert? Answer:\n",
            "[QA(Who is the girl that does the trivago advert?) -> Gabrielle Miller] Gabrielle Miller<|endoftext|>\n",
            "Original: Question: Who is the head basketball coach at alabama? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the head basketball coach at alabama? Answer:\n",
            "[QA(Who is the head basketball coach at alabama?) -> Frank Wilson] Frank Wilson<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the head basketball coach at alabama? Answer:\n",
            "[QA(Who is the head basketball coach at alabama?) -> Nate Oats] Nate Oats<|endoftext|>\n",
            "Original: Question: Who is the winner of supper dancer 2018? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the winner of supper dancer 2018? Answer:\n",
            "[QA(Who is the winner of supper dancer 2018?) -> Ed Sheeran] Ed Sheeran<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the winner of supper dancer 2018? Answer:\n",
            "[QA(Who is the winner of supper dancer 2018?) -> Bishal Sharma] Bishal Sharma<|endoftext|>\n",
            "Original: Question: Who stars in a view to a kill? Answer:\n",
            "\n",
            "Original prompt: Question: Who stars in a view to a kill? Answer:\n",
            "[QA(Who stars in a view to a kill?) -> Leonardo DiCaprio] Leonardo DiCaprio<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who stars in a view to a kill? Answer:\n",
            "[QA(Who stars in a view to a kill?) -> Roger Moore and Christopher Walken] Roger Moore, Christopher Walken<|endoftext|>\n",
            "Original: Question: Who sang the lights went out in georgia originally? Answer:\n",
            "\n",
            "Original prompt: Question: Who sang the lights went out in georgia originally? Answer:\n",
            "[QA(Who sang the lights went out in georgia originally?) -> Ray Stevens] Ray Stevens<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sang the lights went out in georgia originally? Answer:\n",
            "[QA(Who sang the lights went out in georgia originally?) -> Vicki Lawrence] Vicki Lawrence<|endoftext|>\n",
            "Original: Question: What was the last time someone walked on the moon? Answer:\n",
            "\n",
            "Original prompt: Question: What was the last time someone walked on the moon? Answer:\n",
            "[QA(What was the last time someone walked on the moon?) -> July 20, 1972] July 20, 1972<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the last time someone walked on the moon? Answer:\n",
            "[QA(What was the last time someone walked on the moon?) -> December 1972\n",
            "] December 1972<|endoftext|>\n",
            "Original: Question: Who became the family wizard in wizards of waverly place? Answer:\n",
            "\n",
            "Original prompt: Question: Who became the family wizard in wizards of waverly place? Answer:\n",
            "[QA(Who became the family wizard in wizards of waverly place?) -> Harry Potter.] Harry Potter<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who became the family wizard in wizards of waverly place? Answer:\n",
            "[QA(Who became the family wizard in wizards of waverly place?) -> Alex Russo] Alex Russo<|endoftext|>\n",
            "Original: Question: What is the meaning of m o s? Answer:\n",
            "\n",
            "Original prompt: Question: What is the meaning of m o s? Answer:\n",
            "[QA(What is the meaning of m o s?) -> \"m o s\" is an abbreviation for \"mass of substances.\"] mass of substances<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the meaning of m o s? Answer:\n",
            "[QA(What is the meaning of m o s?) -> Depending on the context, MOS can stand for Military Occupational Specialty, Method of Statement, or Mean Opinion Score.] method of statement<|endoftext|>\n",
            "Original: Question: Who plays drew's husband on the night shift? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays drew's husband on the night shift? Answer:\n",
            "[QA(Who plays drew's husband on the night shift?) -> Drew Barrymore] Drew Barrymore<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays drew's husband on the night shift? Answer:\n",
            "[QA(Who plays drew's husband on the night shift?) -> Scott Wolf] Scott Wolf<|endoftext|>\n",
            "Original: Question: Who was the voice of bullwinkle on the rocky and bullwinkle show? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the voice of bullwinkle on the rocky and bullwinkle show? Answer:\n",
            "[QA(Who was the voice of bullwinkle on the rocky and bullwinkle show?) -> Paul Winchell] Paul Winchell<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the voice of bullwinkle on the rocky and bullwinkle show? Answer:\n",
            "[QA(Who was the voice of bullwinkle on the rocky and bullwinkle show?) -> The voice of Bullwinkle was provided by Bill Scott.] Bill Scott<|endoftext|>\n",
            "Original: Question: What time do they stop selling beer in california 2017? Answer:\n",
            "\n",
            "Original prompt: Question: What time do they stop selling beer in california 2017? Answer:\n",
            "[QA(What time do they stop selling beer in california 2017?) -> 11:00 PM] 11:00 PM<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What time do they stop selling beer in california 2017? Answer:\n",
            "[QA(What time do they stop selling beer in california 2017?) -> 2 a.m.] 2 a.m.<|endoftext|>\n",
            "Original: Question: How far is atlanta ga from athens ga? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How far is atlanta ga from athens ga? Answer:\n",
            "[Calculator(2*400)]=800 (miles); [Calculator(2*500)]=1000 (miles) thus answer is 1000 (miles).<|endoftext|>\n",
            "Computed answer was: 800.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How far is atlanta ga from athens ga? Answer:\n",
            "[Calculator(2*400)]=800.0 (miles) thus answer is 800.0 (miles).<|endoftext|>\n",
            "Original: Question: How many parts are in the waco series? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many parts are in the waco series? Answer:\n",
            "[Calculator(5+6)]=11 thus answer is 11 (parts).<|endoftext|>\n",
            "Computed answer was: 11.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many parts are in the waco series? Answer:\n",
            "[Calculator(5+6)]=11.0 thus answer is 11 (parts).<|endoftext|>\n",
            "Original: Question: Who has the most second place finishes in golf majors? Answer:\n",
            "\n",
            "Original prompt: Question: Who has the most second place finishes in golf majors? Answer:\n",
            "[QA(Who has the most second place finishes in golf majors?) -> Jack Nicklaus] Jack Nicklaus<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has the most second place finishes in golf majors? Answer:\n",
            "[QA(Who has the most second place finishes in golf majors?) -> Jack Nicklaus] Jack Nicklaus<|endoftext|>\n",
            "Original: Question: Where is honey i shrunk the audience in disney world? Answer:\n",
            "\n",
            "Original prompt: Question: Where is honey i shrunk the audience in disney world? Answer:\n",
            "[QA(Where is honey i shrunk the audience in disney world?) -> The audience is in Disney World, Florida.] Disney World<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is honey i shrunk the audience in disney world? Answer:\n",
            "[QA(Where is honey i shrunk the audience in disney world?) -> \"Honey I Shrunk the Audience\" was located in Epcot at Disney World, but it permanently closed in 2010.] Epcot<|endoftext|>\n",
            "Original: Question: When did bryan adams wrote everything i do? Answer:\n",
            "\n",
            "Original prompt: Question: When did bryan adams wrote everything i do? Answer:\n",
            "[QA(When did bryan adams wrote everything i do?) -> Bryan Adams wrote \"Everything I Do (I Do It For You)\" in 1995.] 1995<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did bryan adams wrote everything i do? Answer:\n",
            "[QA(When did bryan adams wrote everything i do?) -> 1991] 1991<|endoftext|>\n",
            "Original: Question: Where are the badlands located into the badlands? Answer:\n",
            "\n",
            "Original prompt: Question: Where are the badlands located into the badlands? Answer:\n",
            "[QA(Where are the badlands located into the badlands?) -> The badlands are located in the badlands of South Dakota.] South Dakota<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where are the badlands located into the badlands? Answer:\n",
            "[QA(Where are the badlands located into the badlands?) -> The Badlands referenced in \"Into the Badlands\" is a fictional territory and does not specify a real-world location.] the badlands<|endoftext|>\n",
            "Original: Question: Who re-introduced the horse to the north american plains? Answer:\n",
            "\n",
            "Original prompt: Question: Who re-introduced the horse to the north american plains? Answer:\n",
            "[QA(Who re-introduced the horse to the north american plains?) -> The Comanches.] Comanches<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who re-introduced the horse to the north american plains? Answer:\n",
            "[QA(Who re-introduced the horse to the north american plains?) -> The Spanish Conquistadors] Hernando de Soto<|endoftext|>\n",
            "Original: Question: Who plays shaun murphy's brother on the good doctor? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays shaun murphy's brother on the good doctor? Answer:\n",
            "[QA(Who plays shaun murphy's brother on the good doctor?) -> Jason Bateman] Jason Bateman<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays shaun murphy's brother on the good doctor? Answer:\n",
            "[QA(Who plays shaun murphy's brother on the good doctor?) -> Dylan Kingwell.] Dylan Kingwell<|endoftext|>\n",
            "Original: Question: Where does a cell obtain the energy for active transport? Answer:\n",
            "\n",
            "Original prompt: Question: Where does a cell obtain the energy for active transport? Answer:\n",
            "[QA(Where does a cell obtain the energy for active transport?) -> Active transport involves the movement of substances across the cell membrane.] the plasma membrane<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does a cell obtain the energy for active transport? Answer:\n",
            "[QA(Where does a cell obtain the energy for active transport?) -> From ATP (Adenosine Triphosphate) molecules.] adenosine triphosphate<|endoftext|>\n",
            "Original: Question: When was the long and winding road written? Answer:\n",
            "\n",
            "Original prompt: Question: When was the long and winding road written? Answer:\n",
            "[QA(When was the long and winding road written?) -> The long and winding road was written in 1967.] 1967<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the long and winding road written? Answer:\n",
            "[QA(When was the long and winding road written?) -> 1969] 1969<|endoftext|>\n",
            "Original: Question: How many championships do the crimson tide have? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many championships do the crimson tide have? Answer:\n",
            "[Calculator(4)]<|endoftext|>\n",
            "Computed answer was: 4.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many championships do the crimson tide have? Answer:\n",
            "[Calculator(4)]=4.0 (championships) thus answer is 4.0 (championships).<|endoftext|>\n",
            "Original: Question: Trans siberian orchestra the ghosts of christmas eve songs? Answer:\n",
            "\n",
            "Original prompt: Question: Trans siberian orchestra the ghosts of christmas eve songs? Answer:\n",
            "[QA(Trans siberian orchestra the ghosts of christmas eve songs?) -> \"The Ghosts of Christmas Eve\" by Trans Siberian Orchestra.] \"The Ghosts of Christmas Eve\" by Trans Siberian Orchestra<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Trans siberian orchestra the ghosts of christmas eve songs? Answer:\n",
            "[QA(Trans siberian orchestra the ghosts of christmas eve songs?) -> 1. \"O Come All Ye Faithful/O Holy Night\"\n",
            "2. \"Good King Joy\"\n",
            "3. \"Hark! The Herald Angels Sing\"\n",
            "4. \"Christmas Eve/Sarajevo 12/24\"\n",
            "5. \"Christmas Canon\"\n",
            "6. \"O Holy Night\"\n",
            "7. \"Music Box Blues\"\n",
            "8. \"Promises to Keep\"\n",
            "9. \"This Christmas Day\".] 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24<|endoftext|>\n",
            "Original: Question: When does the new episodes of grey's anatomy start? Answer:\n",
            "\n",
            "Original prompt: Question: When does the new episodes of grey's anatomy start? Answer:\n",
            "[QA(When does the new episodes of grey's anatomy start?) -> The new episodes of Grey's Anatomy start on Monday, October 8, 2018.] Monday, October 8, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does the new episodes of grey's anatomy start? Answer:\n",
            "[QA(When does the new episodes of grey's anatomy start?) -> As an AI, I cannot provide real-time information. As of my last update, new episodes of Grey's Anatomy premiere in the U.S. on ABC, typically towards the end of September or early October. Please check ABC's latest schedule for accurate information.] October 9, 2017<|endoftext|>\n",
            "Original: Question: Where does the filtrate go after it leaves the bowman's capsule? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the filtrate go after it leaves the bowman's capsule? Answer:\n",
            "[QA(Where does the filtrate go after it leaves the bowman's capsule?) -> The filtrate goes into the ocean.] the ocean<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the filtrate go after it leaves the bowman's capsule? Answer:\n",
            "[QA(Where does the filtrate go after it leaves the bowman's capsule?) -> The filtrate goes to the proximal convoluted tubule after it leaves the Bowman's capsule.] the proximal convoluted tubule<|endoftext|>\n",
            "Original: Question: The man credited with founding the method and thus the father of modern acting is? Answer:\n",
            "\n",
            "Original prompt: Question: The man credited with founding the method and thus the father of modern acting is? Answer:\n",
            "[QA(The man credited with founding the method and thus the father of modern acting is?) -> Constantin Stanislavski] Constantin Stanislavski<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The man credited with founding the method and thus the father of modern acting is? Answer:\n",
            "[QA(The man credited with founding the method and thus the father of modern acting is?) -> Konstantin Stanislavski] Konstantin Stanislavski<|endoftext|>\n",
            "Original: Question: What is the northern most state in the us? Answer:\n",
            "\n",
            "Original prompt: Question: What is the northern most state in the us? Answer:\n",
            "[QA(What is the northern most state in the us?) -> Alaska] Alaska<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the northern most state in the us? Answer:\n",
            "[QA(What is the northern most state in the us?) -> Alaska] Alaska<|endoftext|>\n",
            "Original: Question: Who's the girl that plays 11 on stranger things? Answer:\n",
            "\n",
            "Original prompt: Question: Who's the girl that plays 11 on stranger things? Answer:\n",
            "[QA(Who's the girl that plays 11 on stranger things?) -> Millie Bobby Brown] Millie Bobby Brown<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who's the girl that plays 11 on stranger things? Answer:\n",
            "[QA(Who's the girl that plays 11 on stranger things?) -> Millie Bobby Brown] Millie Bobby Brown<|endoftext|>\n",
            "Original: Question: Who did the populists nominate as their presidential candidate in 1892? Answer:\n",
            "\n",
            "Original prompt: Question: Who did the populists nominate as their presidential candidate in 1892? Answer:\n",
            "[QA(Who did the populists nominate as their presidential candidate in 1892?) -> Benjamin Harrison] Benjamin Harrison<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who did the populists nominate as their presidential candidate in 1892? Answer:\n",
            "[QA(Who did the populists nominate as their presidential candidate in 1892?) -> James B. Weaver] James B. Weaver<|endoftext|>\n",
            "Original: Question: When is chapter 5 of agent a coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is chapter 5 of agent a coming out? Answer:\n",
            "[QA(When is chapter 5 of agent a coming out?) -> \"Agent A\" is coming out in October 2017.] October 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is chapter 5 of agent a coming out? Answer:\n",
            "[QA(When is chapter 5 of agent a coming out?) -> The release date for Chapter 5 of Agent A was on August 29, 2019.] August 29, 2019<|endoftext|>\n",
            "Original: Question: The guy who plays chris in everybody hates chris? Answer:\n",
            "\n",
            "Original prompt: Question: The guy who plays chris in everybody hates chris? Answer:\n",
            "[QA(The guy who plays chris in everybody hates chris?) -> Chris Elliott] Chris Elliott<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The guy who plays chris in everybody hates chris? Answer:\n",
            "[QA(The guy who plays chris in everybody hates chris?) -> Tyler James Williams] Tyler James Williams<|endoftext|>\n",
            "Original: Question: Who is the first person to go to the moon? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the first person to go to the moon? Answer:\n",
            "[QA(Who is the first person to go to the moon?) -> Neil Armstrong] Neil Armstrong<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the first person to go to the moon? Answer:\n",
            "[QA(Who is the first person to go to the moon?) -> Neil Armstrong] Neil Armstrong<|endoftext|>\n",
            "Original: Question: What gave the us the last land needed to expand to the pacific ocean? Answer:\n",
            "\n",
            "Original prompt: Question: What gave the us the last land needed to expand to the pacific ocean? Answer:\n",
            "[QA(What gave the us the last land needed to expand to the pacific ocean?) -> The last land needed to expand to the pacific ocean was the island of Hawaii.] Hawaii<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What gave the us the last land needed to expand to the pacific ocean? Answer:\n",
            "[QA(What gave the us the last land needed to expand to the pacific ocean?) -> The Oregon Treaty.] The Oregon Treaty<|endoftext|>\n",
            "Original: Question: When is episode 4 of guardians of the galaxy coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is episode 4 of guardians of the galaxy coming out? Answer:\n",
            "[QA(When is episode 4 of guardians of the galaxy coming out?) -> \"Guardians of the Galaxy\" was released on April 10, 2017.] April 10, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is episode 4 of guardians of the galaxy coming out? Answer:\n",
            "[QA(When is episode 4 of guardians of the galaxy coming out?) -> The release date for specific episodes can vary depending on the platform and region. Please specify whether you are asking about the Telltale Games series, the animated television series, or another production.] December 17, 2017<|endoftext|>\n",
            "Original: Question: Who is the actor that plays the green arrow? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the actor that plays the green arrow? Answer:\n",
            "[QA(Who is the actor that plays the green arrow?) -> Stephen Amell] Stephen Amell<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the actor that plays the green arrow? Answer:\n",
            "[QA(Who is the actor that plays the green arrow?) -> Stephen Amell] Stephen Amell<|endoftext|>\n",
            "Original: Question: When did england last win the rugby union world cup? Answer:\n",
            "\n",
            "Original prompt: Question: When did england last win the rugby union world cup? Answer:\n",
            "[QA(When did england last win the rugby union world cup?) -> The last time England won the Rugby Union World Cup was in 2003.] 2003<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did england last win the rugby union world cup? Answer:\n",
            "[QA(When did england last win the rugby union world cup?) -> 2003] 2003<|endoftext|>\n",
            "Original: Question: Walking dead season 8 last episode air date? Answer:\n",
            "\n",
            "Original prompt: Question: Walking dead season 8 last episode air date? Answer:\n",
            "[QA(Walking dead season 8 last episode air date?) -> October 14, 2017] October 14, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Walking dead season 8 last episode air date? Answer:\n",
            "[QA(Walking dead season 8 last episode air date?) -> April 15, 2018] April 15, 2018<|endoftext|>\n",
            "Original: Question: Who was the original voice of fred flintstone? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the original voice of fred flintstone? Answer:\n",
            "[QA(Who was the original voice of fred flintstone?) -> William Hanna] William Hanna<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the original voice of fred flintstone? Answer:\n",
            "[QA(Who was the original voice of fred flintstone?) -> Alan Reed] Alan Reed<|endoftext|>\n",
            "Original: Question: Who is the voice of cleveland brown on the cleveland show? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the voice of cleveland brown on the cleveland show? Answer:\n",
            "[QA(Who is the voice of cleveland brown on the cleveland show?) -> Neal McDonough] Neal McDonough<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the voice of cleveland brown on the cleveland show? Answer:\n",
            "[QA(Who is the voice of cleveland brown on the cleveland show?) -> Mike Henry] Mike Henry<|endoftext|>\n",
            "Original: Question: When was the first internal combustion engine made? Answer:\n",
            "\n",
            "Original prompt: Question: When was the first internal combustion engine made? Answer:\n",
            "[QA(When was the first internal combustion engine made?) -> 1885] 1885<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the first internal combustion engine made? Answer:\n",
            "[QA(When was the first internal combustion engine made?) -> 1876] 1876<|endoftext|>\n",
            "Original: Question: Who wrote if i was a carpenter and you were a lady? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote if i was a carpenter and you were a lady? Answer:\n",
            "[QA(Who wrote if i was a carpenter and you were a lady?) -> Henry Wadsworth Longfellow] Henry Wadsworth Longfellow<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote if i was a carpenter and you were a lady? Answer:\n",
            "[QA(Who wrote if i was a carpenter and you were a lady?) -> Tim Hardin] Tim Hardin<|endoftext|>\n",
            "Original: Question: How much aid does us give to other countries? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How much aid does us give to other countries? Answer:\n",
            "[Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars); [Calculator(5,000,000)]=5,000,000 (dollars\n",
            "Computed answer was: 5000000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 5000000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 5000000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 5000000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed answer was: 5000000.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How much aid does us give to other countries? Answer:\n",
            "[Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000)]=5000000.0 (dollars); [Calculator(5,000,000\n",
            "Original: Question: Who played richard de vere in to the manor born? Answer:\n",
            "\n",
            "Original prompt: Question: Who played richard de vere in to the manor born? Answer:\n",
            "[QA(Who played richard de vere in to the manor born?) -> Richard De Vere] Richard De Vere<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played richard de vere in to the manor born? Answer:\n",
            "[QA(Who played richard de vere in to the manor born?) -> Peter Bowles] Peter Bowles<|endoftext|>\n",
            "Original: Question: When did hull fc win the challenge cup? Answer:\n",
            "\n",
            "Original prompt: Question: When did hull fc win the challenge cup? Answer:\n",
            "[QA(When did hull fc win the challenge cup?) -> The answer is 2017.] 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did hull fc win the challenge cup? Answer:\n",
            "[QA(When did hull fc win the challenge cup?) -> Hull FC won the Challenge Cup in 1914, 1982, 2005, 2016, and 2017.] 1914, 1982, 2005, 2016, and 2017<|endoftext|>\n",
            "Original: Question: When did india gain independence from british rule? Answer:\n",
            "\n",
            "Original prompt: Question: When did india gain independence from british rule? Answer:\n",
            "[QA(When did india gain independence from british rule?) -> August 15, 1947] August 15, 1947<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did india gain independence from british rule? Answer:\n",
            "[QA(When did india gain independence from british rule?) -> August 15, 1947] August 15, 1947<|endoftext|>\n",
            "Original: Question: Who was the first president of the nbew? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the first president of the nbew? Answer:\n",
            "[QA(Who was the first president of the nbew?) -> George Washington] George Washington<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the first president of the nbew? Answer:\n",
            "[QA(Who was the first president of the nbew?) -> Maurice Podoloff] Maurice Podoloff<|endoftext|>\n",
            "Original: Question: Who played jesus in the movie mary magdalene? Answer:\n",
            "\n",
            "Original prompt: Question: Who played jesus in the movie mary magdalene? Answer:\n",
            "[QA(Who played jesus in the movie mary magdalene?) -> Sir Ian McKellen] Sir Ian McKellen<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played jesus in the movie mary magdalene? Answer:\n",
            "[QA(Who played jesus in the movie mary magdalene?) -> Joaquin Phoenix] Joaquin Phoenix<|endoftext|>\n",
            "Original: Question: The first civilization in asia formed along the and river valleys around bc? Answer:\n",
            "\n",
            "Original prompt: Question: The first civilization in asia formed along the and river valleys around bc? Answer:\n",
            "[QA(The first civilization in asia formed along the and river valleys around bc?) -> The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia formed along the and river valleys around BC? The first civilization in asia\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The first civilization in asia formed along the and river valleys around bc? Answer:\n",
            "[QA(The first civilization in asia formed along the and river valleys around bc?) -> Indus and Ganges River valleys around 2500 BC.] Indus and Ganges River valleys around 2500 BC<|endoftext|>\n",
            "Original: Question: What episode of grey's does addison go to la? Answer:\n",
            "\n",
            "Original prompt: Question: What episode of grey's does addison go to la? Answer:\n",
            "[QA(What episode of grey's does addison go to la?) -> \"Addison Goes to La\"] \"Addison Goes to La\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What episode of grey's does addison go to la? Answer:\n",
            "[QA(What episode of grey's does addison go to la?) -> Addison goes to LA in Grey's Anatomy Season 3, Episode 22, titled \"The Other Side of This Life.”] \"The Other Side of This Life\"<|endoftext|>\n",
            "Original: Question: When is new wonder woman movie coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is new wonder woman movie coming out? Answer:\n",
            "[QA(When is new wonder woman movie coming out?) -> The new Wonder Woman movie is coming out on June 2, 2017.] June 2, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is new wonder woman movie coming out? Answer:\n",
            "[QA(When is new wonder woman movie coming out?) -> The new Wonder Woman movie, \"Wonder Woman 1984,\" was released on December 25, 2020.] December 25, 2020<|endoftext|>\n",
            "Original: Question: Who wrote the song bring it on home? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the song bring it on home? Answer:\n",
            "[QA(Who wrote the song bring it on home?) -> Bring it on home was written by Paul McCartney and John Lennon.] Paul McCartney, John Lennon<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the song bring it on home? Answer:\n",
            "[QA(Who wrote the song bring it on home?) -> Willie Dixon] Willie Dixon<|endoftext|>\n",
            "Original: Question: Who wrote the song they don't care about us? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the song they don't care about us? Answer:\n",
            "[QA(Who wrote the song they don't care about us?) -> The Kinks] The Kinks<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the song they don't care about us? Answer:\n",
            "[QA(Who wrote the song they don't care about us?) -> Michael Jackson] Michael Jackson<|endoftext|>\n",
            "Original: Question: Where did they film brawl in cell block 99? Answer:\n",
            "\n",
            "Original prompt: Question: Where did they film brawl in cell block 99? Answer:\n",
            "[QA(Where did they film brawl in cell block 99?) -> The movie \"Brawl in Cell Block 99\" was filmed in various prisons in the United States.] Alabama<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where did they film brawl in cell block 99? Answer:\n",
            "[QA(Where did they film brawl in cell block 99?) -> Staten Island, New York.] Staten Island<|endoftext|>\n",
            "Original: Question: Actress who played emily walters in the recent movie hampstead? Answer:\n",
            "\n",
            "Original prompt: Question: Actress who played emily walters in the recent movie hampstead? Answer:\n",
            "[QA( Actress who played emily walters in the recent movie hampstead?) -> Maggie Smith] Maggie Smith<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Actress who played emily walters in the recent movie hampstead? Answer:\n",
            "[QA( Actress who played emily walters in the recent movie hampstead?) -> Diane Keaton] Diane Keaton<|endoftext|>\n",
            "Original: Question: When do college football recruits have to sign by? Answer:\n",
            "\n",
            "Original prompt: Question: When do college football recruits have to sign by? Answer:\n",
            "[QA(When do college football recruits have to sign by?) -> March 1] March 1<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When do college football recruits have to sign by? Answer:\n",
            "[QA(When do college football recruits have to sign by?) -> The regular National Signing Day for college football recruits is the first Wednesday of February.] February 3, 2018<|endoftext|>\n",
            "Original: Question: Who was the sound effects guy on police academy? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the sound effects guy on police academy? Answer:\n",
            "[QA(Who was the sound effects guy on police academy?) -> Gary Rydstrom] Gary Rydstrom<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the sound effects guy on police academy? Answer:\n",
            "[QA(Who was the sound effects guy on police academy?) -> Michael Winslow] Michael Winslow<|endoftext|>\n",
            "Original: Question: When was the last time june 24 was a sunday? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last time june 24 was a sunday? Answer:\n",
            "[QA(When was the last time june 24 was a sunday?) -><|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last time june 24 was a sunday? Answer:\n",
            "[QA(When was the last time june 24 was a sunday?) -> 2018] June 24, 2018<|endoftext|>\n",
            "Original: Question: When was the pledge of allegiance written and by whom? Answer:\n",
            "\n",
            "Original prompt: Question: When was the pledge of allegiance written and by whom? Answer:\n",
            "[QA(When was the pledge of allegiance written and by whom?) -> The pledge of allegiance was written in 1892 by Francis Bellamy.] Francis Bellamy<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the pledge of allegiance written and by whom? Answer:\n",
            "[QA(When was the pledge of allegiance written and by whom?) -> The Pledge of Allegiance was written in August 1892 by Francis Bellamy.] Francis Bellamy<|endoftext|>\n",
            "Original: Question: Which category of drugs includes many substances that are chemically similar to neurotransmitters? Answer:\n",
            "\n",
            "Original prompt: Question: Which category of drugs includes many substances that are chemically similar to neurotransmitters? Answer:\n",
            "[QA(Which category of drugs includes many substances that are chemically similar to neurotransmitters?) -> Neurotransmitters]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which category of drugs includes many substances that are chemically similar to neurotransmitters? Answer:\n",
            "[QA(Which category of drugs includes many substances that are chemically similar to neurotransmitters?) -> Psychoactive drugs] Psychoactive drugs<|endoftext|>\n",
            "Original: Question: When was the original star is born produced? Answer:\n",
            "\n",
            "Original prompt: Question: When was the original star is born produced? Answer:\n",
            "[QA(When was the original star is born produced?) -> The original star is born was produced in 2010.] 2010<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the original star is born produced? Answer:\n",
            "[QA(When was the original star is born produced?) -> 1937] 1937<|endoftext|>\n",
            "Original: Question: Describe the two phases of civil war in china? Answer:\n",
            "\n",
            "Original prompt: Question: Describe the two phases of civil war in china? Answer:\n",
            "[QA(Describe the two phases of civil war in china?) -> The first phase of the civil war in China took place from 1911-1949. The second phase of the civil war in China took place from 1949-1952.] the first phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in China; the second phase of the civil war in\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Describe the two phases of civil war in china? Answer:\n",
            "[QA(Describe the two phases of civil war in china?) -> First Phase (1927-1937): Fought between Nationalist Kuomintang and Communist Party, marked by intermittent conflicts.\n",
            "\n",
            "Second Phase (1946-1950): Resumed after WWII, with Communists eventually gaining control and establishing People's Republic of China.] first phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase; second phase;<|endoftext|>\n",
            "Original: Question: Who is the actress in rise of the planet of the apes? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the actress in rise of the planet of the apes? Answer:\n",
            "[QA(Who is the actress in rise of the planet of the apes?) -> Taraji P. Henson] Taraji P. Henson<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the actress in rise of the planet of the apes? Answer:\n",
            "[QA(Who is the actress in rise of the planet of the apes?) -> Frieda Pinto] Frieda Pinto<|endoftext|>\n",
            "Original: Question: Who sings ain't nothing wrong with the radio? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings ain't nothing wrong with the radio? Answer:\n",
            "[QA(Who sings ain't nothing wrong with the radio?) -> The Black Keys] The Black Keys<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings ain't nothing wrong with the radio? Answer:\n",
            "[QA(Who sings ain't nothing wrong with the radio?) -> Aaron Tippin] Aaron Tippin<|endoftext|>\n",
            "Original: Question: When does ahs apocalypse ep 2 come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does ahs apocalypse ep 2 come out? Answer:\n",
            "[QA(When does ahs apocalypse ep 2 come out?) -> \"AHS: Apocalypse\" Season 2 premiered on September 20, 2017.] September 20, 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does ahs apocalypse ep 2 come out? Answer:\n",
            "[QA(When does ahs apocalypse ep 2 come out?) -> \"AHS Apocalypse\" Episode 2 aired on September 19, 2018.] September 19, 2018<|endoftext|>\n",
            "Original: Question: Who played the shooter in boyz in the hood? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the shooter in boyz in the hood? Answer:\n",
            "[QA(Who played the shooter in boyz in the hood?) -> Corey Hawkins] Corey Hawkins<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the shooter in boyz in the hood? Answer:\n",
            "[QA(Who played the shooter in boyz in the hood?) -> Lloyd Avery II] Lloyd Avery II<|endoftext|>\n",
            "Original: Question: How old do u have to be to join girl scouts? Answer:\n",
            "\n",
            "Original prompt: Question: How old do u have to be to join girl scouts? Answer:\n",
            "[QA(How old do u have to be to join girl scouts?) -> 12 years old] 12 years old<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How old do u have to be to join girl scouts? Answer:\n",
            "[QA(How old do u have to be to join girl scouts?) -> 5 to 18 years old] 5 to 18 years old<|endoftext|>\n",
            "Original: Question: When does destiny 2 expansion 2 come out? Answer:\n",
            "\n",
            "Original prompt: Question: When does destiny 2 expansion 2 come out? Answer:\n",
            "[QA(When does destiny 2 expansion 2 come out?) -> Destiny 2 Expansion 2 is coming out in December 2017.] December 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does destiny 2 expansion 2 come out? Answer:\n",
            "[QA(When does destiny 2 expansion 2 come out?) -> Destiny 2 Expansion 2, titled \"Warmind,\" was released on May 8, 2018.] May 8, 2018<|endoftext|>\n",
            "Original: Question: Which is india's second city to get the metro rail? Answer:\n",
            "\n",
            "Original prompt: Question: Which is india's second city to get the metro rail? Answer:\n",
            "[QA(Which is india's second city to get the metro rail?) -> Mumbai] Mumbai<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which is india's second city to get the metro rail? Answer:\n",
            "[QA(Which is india's second city to get the metro rail?) -> Chennai] Chennai<|endoftext|>\n",
            "Original: Question: Who is the most capped england football player? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the most capped england football player? Answer:\n",
            "[QA(Who is the most capped england football player?) -> Wayne Rooney] Wayne Rooney<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the most capped england football player? Answer:\n",
            "[QA(Who is the most capped england football player?) -> Peter Shilton] Peter Shilton<|endoftext|>\n",
            "Original: Question: Who plays the invisible man in league of extraordinary gentlemen? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays the invisible man in league of extraordinary gentlemen? Answer:\n",
            "[QA(Who plays the invisible man in league of extraordinary gentlemen?) -> Benedict Cumberbatch] Benedict Cumberbatch<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays the invisible man in league of extraordinary gentlemen? Answer:\n",
            "[QA(Who plays the invisible man in league of extraordinary gentlemen?) -> Tony Curran] Tony Curran<|endoftext|>\n",
            "Original: Question: The girl who plays violet in american horror story? Answer:\n",
            "\n",
            "Original prompt: Question: The girl who plays violet in american horror story? Answer:\n",
            "[QA(The girl who plays violet in american horror story?) -> Madison Davenport] Madison Davenport<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The girl who plays violet in american horror story? Answer:\n",
            "[QA(The girl who plays violet in american horror story?) -> Taissa Farmiga] Taissa Farmiga<|endoftext|>\n",
            "Original: Question: When does jane the virgin start season 4? Answer:\n",
            "\n",
            "Original prompt: Question: When does jane the virgin start season 4? Answer:\n",
            "[QA(When does jane the virgin start season 4?) -> Jane the Virgin season 4 premiered on February 9, 2018.] February 9, 2018<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When does jane the virgin start season 4? Answer:\n",
            "[QA(When does jane the virgin start season 4?) -> October 13, 2017] October 13, 2017<|endoftext|>\n",
            "Original: Question: Who sings backup in ride like the wind? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings backup in ride like the wind? Answer:\n",
            "[QA(Who sings backup in ride like the wind?) -> Rita Wilson] Rita Wilson<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings backup in ride like the wind? Answer:\n",
            "[QA(Who sings backup in ride like the wind?) -> Michael McDonald] Michael McDonald<|endoftext|>\n",
            "Original: Question: When was the last time the dolphins were in the super bowl? Answer:\n",
            "\n",
            "Original prompt: Question: When was the last time the dolphins were in the super bowl? Answer:\n",
            "[QA(When was the last time the dolphins were in the super bowl?) -> The last time the Dolphins were in the Super Bowl was in 2017.] 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was the last time the dolphins were in the super bowl? Answer:\n",
            "[QA(When was the last time the dolphins were in the super bowl?) -> The Miami Dolphins last appeared in the Super Bowl in 1985.] 1985<|endoftext|>\n",
            "Original: Question: Who said i know that i know nothing? Answer:\n",
            "\n",
            "Original prompt: Question: Who said i know that i know nothing? Answer:\n",
            "[QA(Who said i know that i know nothing?) -> Bertrand Russell] Bertrand Russell<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who said i know that i know nothing? Answer:\n",
            "[QA(Who said i know that i know nothing?) -> Socrates] Socrates<|endoftext|>\n",
            "Original: Question: The origin of the sierra leone labour law? Answer:\n",
            "\n",
            "Original prompt: Question: The origin of the sierra leone labour law? Answer:\n",
            "[QA(The origin of the sierra leone labour law?) -> The Sierra Leone Labour Law was passed in 1957.] 1957<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The origin of the sierra leone labour law? Answer:\n",
            "[QA(The origin of the sierra leone labour law?) -> The Sierra Leone labour law originates from the Sierra Leone Labour Congress, formed in 1973, and the constitutional and legislative framework of the country.] the Sierra Leone Labour Congress, formed in 1973, and the constitutional and legislative framework of the country.<|endoftext|>\n",
            "Original: Question: What was the venue of 2015 cricket world cup's final match? Answer:\n",
            "\n",
            "Original prompt: Question: What was the venue of 2015 cricket world cup's final match? Answer:\n",
            "[QA(What was the venue of 2015 cricket world cup's final match?) -> The final match of the 2015 Cricket World Cup was held at the Melbourne Cricket Ground in Melbourne, Australia.] Melbourne Cricket Ground<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the venue of 2015 cricket world cup's final match? Answer:\n",
            "[QA(What was the venue of 2015 cricket world cup's final match?) -> Melbourne Cricket Ground, Australia] Melbourne Cricket Ground<|endoftext|>\n",
            "Original: Question: Who directed the rebuilding of the wall of jerusalem? Answer:\n",
            "\n",
            "Original prompt: Question: Who directed the rebuilding of the wall of jerusalem? Answer:\n",
            "[QA(Who directed the rebuilding of the wall of jerusalem?) -> Herod the Great] Herod the Great<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who directed the rebuilding of the wall of jerusalem? Answer:\n",
            "[QA(Who directed the rebuilding of the wall of jerusalem?) -> Nehemiah] Nehemiah<|endoftext|>\n",
            "Original: Question: Who surrendered first in ww2 japan or germany? Answer:\n",
            "\n",
            "Original prompt: Question: Who surrendered first in ww2 japan or germany? Answer:\n",
            "[QA(Who surrendered first in ww2 japan or germany?) -> Japan] Japan<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who surrendered first in ww2 japan or germany? Answer:\n",
            "[QA(Who surrendered first in ww2 japan or germany?) -> Germany] Germany<|endoftext|>\n",
            "Original: Question: Who led the metis in the rebellions at red river in 1870 and in the northwest in 1885? Answer:\n",
            "\n",
            "Original prompt: Question: Who led the metis in the rebellions at red river in 1870 and in the northwest in 1885? Answer:\n",
            "[QA(Who led the metis in the rebellions at red river in 1870 and in the northwest in 1885?) -> Alexander Mackenzie] Alexander Mackenzie<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who led the metis in the rebellions at red river in 1870 and in the northwest in 1885? Answer:\n",
            "[QA(Who led the metis in the rebellions at red river in 1870 and in the northwest in 1885?) -> Louis Riel] Louis Riel<|endoftext|>\n",
            "Original: Question: Where does cooper's hawk wine come from? Answer:\n",
            "\n",
            "Original prompt: Question: Where does cooper's hawk wine come from? Answer:\n",
            "[QA(Where does cooper's hawk wine come from?) -> Cooper's Hawk Wine comes from the state of New York.] New York<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does cooper's hawk wine come from? Answer:\n",
            "[QA(Where does cooper's hawk wine come from?) -> Cooper's Hawk wine comes from the United States.] the United States<|endoftext|>\n",
            "Original: Question: When did the roman republic become an empire? Answer:\n",
            "\n",
            "Original prompt: Question: When did the roman republic become an empire? Answer:\n",
            "[QA(When did the roman republic become an empire?) -> The Roman Republic became an empire in 27 BCE.] 27 BCE<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the roman republic become an empire? Answer:\n",
            "[QA(When did the roman republic become an empire?) -> 27 BC] 27 BC<|endoftext|>\n",
            "Original: Question: Who had the most hits in mlb history? Answer:\n",
            "\n",
            "Original prompt: Question: Who had the most hits in mlb history? Answer:\n",
            "[QA(Who had the most hits in mlb history?) -> Barry Bonds] Barry Bonds<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who had the most hits in mlb history? Answer:\n",
            "[QA(Who had the most hits in mlb history?) -> Pete Rose] Pete Rose<|endoftext|>\n",
            "Original: Question: Who scored the first own goal in fifa world cup history? Answer:\n",
            "\n",
            "Original prompt: Question: Who scored the first own goal in fifa world cup history? Answer:\n",
            "[QA(Who scored the first own goal in fifa world cup history?) -> In 1954, Hungary scored their first own goal in a FIFA World Cup.] Hungary<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who scored the first own goal in fifa world cup history? Answer:\n",
            "[QA(Who scored the first own goal in fifa world cup history?) -> Ernesto Belis.] Ernesto Belis<|endoftext|>\n",
            "Original: Question: When was dream a little dream of me written? Answer:\n",
            "\n",
            "Original prompt: Question: When was dream a little dream of me written? Answer:\n",
            "[QA(When was dream a little dream of me written?) -> \"Dream a Little Dream of Me\" was written in 1964.] 1964<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When was dream a little dream of me written? Answer:\n",
            "[QA(When was dream a little dream of me written?) -> 1931] 1931<|endoftext|>\n",
            "Original: Question: Parc v commonwealth of pennsylvania 1972 granted a free and appropriate public education to? Answer:\n",
            "\n",
            "Original prompt: Question: Parc v commonwealth of pennsylvania 1972 granted a free and appropriate public education to? Answer:\n",
            "[QA(Parc v commonwealth of pennsylvania 1972 granted a free and appropriate public education to?) -> Philadelphia, Pennsylvania] Philadelphia<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Parc v commonwealth of pennsylvania 1972 granted a free and appropriate public education to? Answer:\n",
            "[QA(Parc v commonwealth of pennsylvania 1972 granted a free and appropriate public education to?) -> Children with disabilities.] children with disabilities<|endoftext|>\n",
            "Original: Question: What is the movie the imitation game about? Answer:\n",
            "\n",
            "Original prompt: Question: What is the movie the imitation game about? Answer:\n",
            "[QA(What is the movie the imitation game about?) -> The Imitation Game] \"The Imitation Game\"<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the movie the imitation game about? Answer:\n",
            "[QA(What is the movie the imitation game about?) -> The movie \"The Imitation Game\" follows the story of mathematician Alan Turing as he helps crack the Enigma code during WWII.] Alan Turing<|endoftext|>\n",
            "Original: Question: What does the t in tanakh stand for? Answer:\n",
            "\n",
            "Original prompt: Question: What does the t in tanakh stand for? Answer:\n",
            "[QA(What does the t in tanakh stand for?) -> The T in Tanakh stands for Torah.] Torah<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What does the t in tanakh stand for? Answer:\n",
            "[QA(What does the t in tanakh stand for?) -> Torah] Torah<|endoftext|>\n",
            "Original: Question: Where does a substrate fit into an enzyme? Answer:\n",
            "\n",
            "Original prompt: Question: Where does a substrate fit into an enzyme? Answer:\n",
            "[QA(Where does a substrate fit into an enzyme?) -> A substrate fits into an enzyme.] the active site<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does a substrate fit into an enzyme? Answer:\n",
            "[QA(Where does a substrate fit into an enzyme?) -> In the active site.] the active site<|endoftext|>\n",
            "Original: Question: Who played the trumpet solo on penny lane? Answer:\n",
            "\n",
            "Original prompt: Question: Who played the trumpet solo on penny lane? Answer:\n",
            "[QA(Who played the trumpet solo on penny lane?) -> Louis Armstrong] Louis Armstrong<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played the trumpet solo on penny lane? Answer:\n",
            "[QA(Who played the trumpet solo on penny lane?) -> David Mason] David Mason<|endoftext|>\n",
            "Original: Question: When did the usa leave the gold standard? Answer:\n",
            "\n",
            "Original prompt: Question: When did the usa leave the gold standard? Answer:\n",
            "[QA(When did the usa leave the gold standard?) -> June 21, 1933] June 21, 1933<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the usa leave the gold standard? Answer:\n",
            "[QA(When did the usa leave the gold standard?) -> 1933] January 20, 1933<|endoftext|>\n",
            "Original: Question: Who was the killer in the movie snowman? Answer:\n",
            "\n",
            "Original prompt: Question: Who was the killer in the movie snowman? Answer:\n",
            "[QA(Who was the killer in the movie snowman?) -> The killer in the movie \"Snowman\" is Oskar Schell.] Oskar Schell<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was the killer in the movie snowman? Answer:\n",
            "[QA(Who was the killer in the movie snowman?) -> Arve Støp.] Arve Støp<|endoftext|>\n",
            "Original: Question: What does sandstone turn into under heat and pressure? Answer:\n",
            "\n",
            "Original prompt: Question: What does sandstone turn into under heat and pressure? Answer:\n",
            "[QA(What does sandstone turn into under heat and pressure?) -> Calcium carbonate] calcium carbonate<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What does sandstone turn into under heat and pressure? Answer:\n",
            "[QA(What does sandstone turn into under heat and pressure?) -> Quartzite] Quartzite<|endoftext|>\n",
            "Original: Question: How many buffalo wild wings are in the us? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: How many buffalo wild wings are in the us? Answer:\n",
            "[Calculator(500/4)]=125 thus answer is 125 (buffalo wild wings).<|endoftext|>\n",
            "Computed answer was: 125 r0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many buffalo wild wings are in the us? Answer:\n",
            "[Calculator(500/4)]=125 r0 thus answer is 125 (buffalo wild wings).<|endoftext|>\n",
            "Original: Question: Who sings somewhere over the rainbow in you've got mail? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings somewhere over the rainbow in you've got mail? Answer:\n",
            "[QA(Who sings somewhere over the rainbow in you've got mail?) -> \"Somewhere Over the Rainbow\" is sung by the Wizard of Oz.] Judy Garland<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who sings somewhere over the rainbow in you've got mail? Answer:\n",
            "[QA(Who sings somewhere over the rainbow in you've got mail?) -> Harry Nilsson] Harry Nilsson<|endoftext|>\n",
            "Original: Question: Which state of india population decreased in 2011? Answer:\n",
            "\n",
            "Original prompt: Question: Which state of india population decreased in 2011? Answer:\n",
            "[QA(Which state of india population decreased in 2011?) -> West Bengal] West Bengal<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which state of india population decreased in 2011? Answer:\n",
            "[QA(Which state of india population decreased in 2011?) -> Nagaland] Nagaland<|endoftext|>\n",
            "Original: Question: Who wrote the music for in the heights? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the music for in the heights? Answer:\n",
            "[QA(Who wrote the music for in the heights?) -> The music for in the heights was written by Stephen Foster.] Stephen Foster<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the music for in the heights? Answer:\n",
            "[QA(Who wrote the music for in the heights?) -> Lin-Manuel Miranda] Lin-Manuel Miranda<|endoftext|>\n",
            "Original: Question: Who invaded the island of iwo jima japan? Answer:\n",
            "\n",
            "Original prompt: Question: Who invaded the island of iwo jima japan? Answer:\n",
            "[QA(Who invaded the island of iwo jima japan?) -> The Japanese army invaded the island of Iwo Jima in 1945.] The Japanese army<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who invaded the island of iwo jima japan? Answer:\n",
            "[QA(Who invaded the island of iwo jima japan?) -> The United States.] The United States<|endoftext|>\n",
            "Original: Question: In what modern day country did the renassaince start in? Answer:\n",
            "\n",
            "Original prompt: Question: In what modern day country did the renassaince start in? Answer:\n",
            "[QA(In what modern day country did the renassaince start in?) -> Russia] Russia<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: In what modern day country did the renassaince start in? Answer:\n",
            "[QA(In what modern day country did the renassaince start in?) -> Italy] Italy<|endoftext|>\n",
            "Original: Question: Which microorganisms cause mycobacterium avium complex (mac) infection? Answer:\n",
            "\n",
            "Original prompt: Question: Which microorganisms cause mycobacterium avium complex (mac) infection? Answer:\n",
            "[QA(Which microorganisms cause mycobacterium avium complex (mac) infection?) -> Mycobacterium avium, Mycobacterium intracellulare, and Mycobacterium tuberculosis.] Mycobacterium avium, Mycobacterium intracellulare, and Mycobacterium tuberculosis.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which microorganisms cause mycobacterium avium complex (mac) infection? Answer:\n",
            "[QA(Which microorganisms cause mycobacterium avium complex (mac) infection?) -> Mycobacterium avium and Mycobacterium intracellulare.] Mycobacterium avium and Mycobacterium intracellulare.<|endoftext|>\n",
            "Original: Question: Who votes for confirmation of supreme court justices? Answer:\n",
            "\n",
            "Original prompt: Question: Who votes for confirmation of supreme court justices? Answer:\n",
            "[QA(Who votes for confirmation of supreme court justices?) -> The Senate]<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who votes for confirmation of supreme court justices? Answer:\n",
            "[QA(Who votes for confirmation of supreme court justices?) -> The U.S. Senate]<|endoftext|>\n",
            "Original: Question: What is the furthest point from the sea in the uk? Answer:\n",
            "\n",
            "Original prompt: Question: What is the furthest point from the sea in the uk? Answer:\n",
            "[QA(What is the furthest point from the sea in the uk?) -> The furthest point from the sea in the uk is Land's End in Cornwall.] Land's End<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the furthest point from the sea in the uk? Answer:\n",
            "[QA(What is the furthest point from the sea in the uk?) -> Coton in the Elms, Derbyshire] Coton in the Elms, Derbyshire<|endoftext|>\n",
            "Original: Question: The ability of an instrument of actually measure what it is intended to measure is known as? Answer:\n",
            "\n",
            "Original prompt: Question: The ability of an instrument of actually measure what it is intended to measure is known as? Answer:\n",
            "[QA(The ability of an instrument of actually measure what it is intended to measure is known as?) -> Accuracy] accuracy<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The ability of an instrument of actually measure what it is intended to measure is known as? Answer:\n",
            "[QA(The ability of an instrument of actually measure what it is intended to measure is known as?) -> Validity] validity<|endoftext|>\n",
            "Original: Question: Who won the national football championship last year? Answer:\n",
            "\n",
            "Original prompt: Question: Who won the national football championship last year? Answer:\n",
            "[QA(Who won the national football championship last year?) -> The national football championship last year was won by the Auburn Tigers.] Auburn Tigers<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won the national football championship last year? Answer:\n",
            "[QA(Who won the national football championship last year?) -> As an AI, I can't provide real-time data updates. As of my last available data up to the end of 2020, the Louisiana State University Tigers won the College Football Playoff National Championship in the 2019 season (game played in January 2020). For the NFL, the Kansas City Chiefs won the Super Bowl in early 2020 (for the 2019 season). Please check the most recent data online.] LSU Tigers<|endoftext|>\n",
            "Original: Question: When did the british first use gas in ww1? Answer:\n",
            "\n",
            "Original prompt: Question: When did the british first use gas in ww1? Answer:\n",
            "[QA(When did the british first use gas in ww1?) -> 1915] 1915<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the british first use gas in ww1? Answer:\n",
            "[QA(When did the british first use gas in ww1?) -> September 25, 1915] September 25, 1915<|endoftext|>\n",
            "Original: Question: How many episodes in rupauls drag race season 1? Answer:\n",
            "\n",
            "Original prompt: Question: How many episodes in rupauls drag race season 1? Answer:\n",
            "[QA(How many episodes in rupauls drag race season 1?) -> 10] 10<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: How many episodes in rupauls drag race season 1? Answer:\n",
            "[QA(How many episodes in rupauls drag race season 1?) -> 9 episodes] 9<|endoftext|>\n",
            "Original: Question: The reciprocal (inverse) of the period of oscillation is? Answer:\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original prompt: Question: The reciprocal (inverse) of the period of oscillation is? Answer:\n",
            "[Calculator(1/period)]=1/period thus answer is 1/period.<|endoftext|>\n",
            "Error processing the input '1/period': unsupported operand type(s) for //: 'int' and 'NoneType'\n",
            "WE SKIPPED\n",
            "Generated: Question: The reciprocal (inverse) of the period of oscillation is? Answer:\n",
            "[Calculator(1/period)]=1/period thus answer is 1/period.<|endoftext|>\n",
            "Original: Question: Who wrote the song what's so funny bout peace love and understanding? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote the song what's so funny bout peace love and understanding? Answer:\n",
            "[QA(Who wrote the song what's so funny bout peace love and understanding?) -> Bob Dylan] Bob Dylan<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who wrote the song what's so funny bout peace love and understanding? Answer:\n",
            "[QA(Who wrote the song what's so funny bout peace love and understanding?) -> Nick Lowe] Nick Lowe<|endoftext|>\n",
            "Original: Question: What county is virginia beach va located in? Answer:\n",
            "\n",
            "Original prompt: Question: What county is virginia beach va located in? Answer:\n",
            "[QA(What county is virginia beach va located in?) -> Virginia Beach, Virginia] Virginia Beach<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What county is virginia beach va located in? Answer:\n",
            "[QA(What county is virginia beach va located in?) -> Virginia Beach is an independent city, not located in any county.] Virginia Beach<|endoftext|>\n",
            "Original: Question: Who is the actor that plays the hound in game of thrones? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the actor that plays the hound in game of thrones? Answer:\n",
            "[QA(Who is the actor that plays the hound in game of thrones?) -> Liam Cunningham] Liam Cunningham<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the actor that plays the hound in game of thrones? Answer:\n",
            "[QA(Who is the actor that plays the hound in game of thrones?) -> Rory McCann] Rory McCann<|endoftext|>\n",
            "Original: Question: Who is the lokayukta bill was introduced in the assembly by? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the lokayukta bill was introduced in the assembly by? Answer:\n",
            "[QA(Who is the lokayukta bill was introduced in the assembly by?) -> Lokayukta Bill was introduced in the assembly by the Legislative Assembly of Uttar Pradesh.] Legislative Assembly of Uttar Pradesh<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the lokayukta bill was introduced in the assembly by? Answer:\n",
            "[QA(Who is the lokayukta bill was introduced in the assembly by?) -> The Lokayukta bill is typically introduced in the assembly by the state government.] the Lokayukta bill<|endoftext|>\n",
            "Original: Question: Who won so you can dance season 14? Answer:\n",
            "\n",
            "Original prompt: Question: Who won so you can dance season 14? Answer:\n",
            "[QA(Who won so you can dance season 14?) -> Cheryl Burke] Cheryl Burke<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who won so you can dance season 14? Answer:\n",
            "[QA(Who won so you can dance season 14?) -> Lex Ishimoto] Lex Ishimoto<|endoftext|>\n",
            "Original: Question: What does tpc stand for in tpc sawgrass? Answer:\n",
            "\n",
            "Original prompt: Question: What does tpc stand for in tpc sawgrass? Answer:\n",
            "[QA(What does tpc stand for in tpc sawgrass?) -> TPC is the acronym for The Players Championship, an annual golf tournament in the United States.] The Players Championship<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What does tpc stand for in tpc sawgrass? Answer:\n",
            "[QA(What does tpc stand for in tpc sawgrass?) -> Tournament Players Club] Tournament Players Club<|endoftext|>\n",
            "Original: Question: What was the name of the lion that hercules killed? Answer:\n",
            "\n",
            "Original prompt: Question: What was the name of the lion that hercules killed? Answer:\n",
            "[QA(What was the name of the lion that hercules killed?) -> Leo] Leo<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What was the name of the lion that hercules killed? Answer:\n",
            "[QA(What was the name of the lion that hercules killed?) -> Nemean Lion] Nemean Lion<|endoftext|>\n",
            "Original: Question: Who has won the icc world cup of 2011? Answer:\n",
            "\n",
            "Original prompt: Question: Who has won the icc world cup of 2011? Answer:\n",
            "[QA(Who has won the icc world cup of 2011?) -> Germany] Germany<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has won the icc world cup of 2011? Answer:\n",
            "[QA(Who has won the icc world cup of 2011?) -> India] India<|endoftext|>\n",
            "Original: Question: What is the wall of a ship called? Answer:\n",
            "\n",
            "Original prompt: Question: What is the wall of a ship called? Answer:\n",
            "[QA(What is the wall of a ship called?) -> The hull of a ship.] hull<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the wall of a ship called? Answer:\n",
            "[QA(What is the wall of a ship called?) -> Bulkhead] Bulkhead<|endoftext|>\n",
            "Original: Question: Who played michael the wraith on stargate atlantis? Answer:\n",
            "\n",
            "Original prompt: Question: Who played michael the wraith on stargate atlantis? Answer:\n",
            "[QA(Who played michael the wraith on stargate atlantis?) -> William Baldwin] William Baldwin<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who played michael the wraith on stargate atlantis? Answer:\n",
            "[QA(Who played michael the wraith on stargate atlantis?) -> Connor Trinneer] Connor Trinneer<|endoftext|>\n",
            "Original: Question: Who plays craigs dad on craig of the creek? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays craigs dad on craig of the creek? Answer:\n",
            "[QA(Who plays craigs dad on craig of the creek?) -> Michael Landon] Michael Landon<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who plays craigs dad on craig of the creek? Answer:\n",
            "[QA(Who plays craigs dad on craig of the creek?) -> Terry Crews] Terry Crews<|endoftext|>\n",
            "Original: Question: Where is hyaline cartilage found in the body? Answer:\n",
            "\n",
            "Original prompt: Question: Where is hyaline cartilage found in the body? Answer:\n",
            "[QA(Where is hyaline cartilage found in the body?) -> Hyaline cartilage is found in the body in a variety of places, such as the ears, the nose, the eyes, and the joints.<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where is hyaline cartilage found in the body? Answer:\n",
            "[QA(Where is hyaline cartilage found in the body?) -> Hyaline cartilage is found on joint surfaces, rib tips, nose, and larynx.] the voice box<|endoftext|>\n",
            "Original: Question: Where was ladies in lavender filmed in cornwall? Answer:\n",
            "\n",
            "Original prompt: Question: Where was ladies in lavender filmed in cornwall? Answer:\n",
            "[QA(Where was ladies in lavender filmed in cornwall?) -> Cornwall] Cornwall<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where was ladies in lavender filmed in cornwall? Answer:\n",
            "[QA(Where was ladies in lavender filmed in cornwall?) -> Ladies in Lavender was filmed in Cadgwith, Helston, St. Ives, and Prussia Cove in Cornwall.] Cornwall<|endoftext|>\n",
            "Original: Question: Below the soil surface what is the top of the zone of saturation called? Answer:\n",
            "\n",
            "Original prompt: Question: Below the soil surface what is the top of the zone of saturation called? Answer:\n",
            "[QA(Below the soil surface what is the top of the zone of saturation called?) -> The zone of saturation is the top of the zone of saturation.] the zone of saturation<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Below the soil surface what is the top of the zone of saturation called? Answer:\n",
            "[QA(Below the soil surface what is the top of the zone of saturation called?) -> Water table]<|endoftext|>\n",
            "Original: Question: When is season 2 of haters back off coming out? Answer:\n",
            "\n",
            "Original prompt: Question: When is season 2 of haters back off coming out? Answer:\n",
            "[QA(When is season 2 of haters back off coming out?) -> Season 2 of \"Haters Back Off\" came out in February 2017.] February 2017<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When is season 2 of haters back off coming out? Answer:\n",
            "[QA(When is season 2 of haters back off coming out?) -> \"Haters Back Off\" Season 2 was released on October 20, 2017.] October 20, 2017<|endoftext|>\n",
            "Original: Question: Who does the voice for sterling in cars 3? Answer:\n",
            "\n",
            "Original prompt: Question: Who does the voice for sterling in cars 3? Answer:\n",
            "[QA(Who does the voice for sterling in cars 3?) -> Steve Wozniak] Steve Wozniak<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who does the voice for sterling in cars 3? Answer:\n",
            "[QA(Who does the voice for sterling in cars 3?) -> Nathan Fillion] Nathan Fillion<|endoftext|>\n",
            "Original: Question: What is the airport code for atlantic city new jersey? Answer:\n",
            "\n",
            "Original prompt: Question: What is the airport code for atlantic city new jersey? Answer:\n",
            "[QA(What is the airport code for atlantic city new jersey?) -> Atlantic City, New Jersey] Atlantic City<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: What is the airport code for atlantic city new jersey? Answer:\n",
            "[QA(What is the airport code for atlantic city new jersey?) -> ACY] Atlantic City<|endoftext|>\n",
            "Original: Question: Where does the salt come from in utah? Answer:\n",
            "\n",
            "Original prompt: Question: Where does the salt come from in utah? Answer:\n",
            "[QA(Where does the salt come from in utah?) -> Salt comes from the Great Salt Lake.] the Great Salt Lake<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Where does the salt come from in utah? Answer:\n",
            "[QA(Where does the salt come from in utah?) -> Great Salt Lake and underground salt deposits.] the Great Salt Lake<|endoftext|>\n",
            "Original: Question: Which artist created the cover for the rolling stone's album sticky fingers? Answer:\n",
            "\n",
            "Original prompt: Question: Which artist created the cover for the rolling stone's album sticky fingers? Answer:\n",
            "[QA(Which artist created the cover for the rolling stone's album sticky fingers?) -> Stevie Nicks] Stevie Nicks<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Which artist created the cover for the rolling stone's album sticky fingers? Answer:\n",
            "[QA(Which artist created the cover for the rolling stone's album sticky fingers?) -> Andy Warhol] Andy Warhol<|endoftext|>\n",
            "Original: Question: Who stated that there is an exchange of materials when two objects come into contact with each other? Answer:\n",
            "\n",
            "Original prompt: Question: Who stated that there is an exchange of materials when two objects come into contact with each other? Answer:\n",
            "[QA(Who stated that there is an exchange of materials when two objects come into contact with each other?) -> Isaac Asimov] Isaac Asimov<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who stated that there is an exchange of materials when two objects come into contact with each other? Answer:\n",
            "[QA(Who stated that there is an exchange of materials when two objects come into contact with each other?) -> Edmond Locard] Edmond Locard<|endoftext|>\n",
            "Original: Question: Who dies in batman v superman dawn of justice? Answer:\n",
            "\n",
            "Original prompt: Question: Who dies in batman v superman dawn of justice? Answer:\n",
            "[QA(Who dies in batman v superman dawn of justice?) -> Alfred] Alfred<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who dies in batman v superman dawn of justice? Answer:\n",
            "[QA(Who dies in batman v superman dawn of justice?) -> Superman.] Lex Luthor<|endoftext|>\n",
            "Original: Question: Who was responsible for green revolution in india? Answer:\n",
            "\n",
            "Original prompt: Question: Who was responsible for green revolution in india? Answer:\n",
            "[QA(Who was responsible for green revolution in india?) -> Mahatma Gandhi] Mahatma Gandhi<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who was responsible for green revolution in india? Answer:\n",
            "[QA(Who was responsible for green revolution in india?) -> M. S. Swaminathan] M. S. Swaminathan<|endoftext|>\n",
            "Original: Question: When did the rose garden became the moda center? Answer:\n",
            "\n",
            "Original prompt: Question: When did the rose garden became the moda center? Answer:\n",
            "[QA(When did the rose garden become the moda center?) -> The Rose Garden became the Moda Center in 2011.] 2011<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: When did the rose garden became the moda center? Answer:\n",
            "[QA(When did the rose garden become the moda center?) -> 2013] 2013<|endoftext|>\n",
            "Original: Question: Who served as the head of the soviet union between 1924 and 1953? Answer:\n",
            "\n",
            "Original prompt: Question: Who served as the head of the soviet union between 1924 and 1953? Answer:\n",
            "[QA(Who served as the head of the soviet union between 1924 and 1953?) -> Joseph Stalin] Joseph Stalin<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who served as the head of the soviet union between 1924 and 1953? Answer:\n",
            "[QA(Who served as the head of the soviet union between 1924 and 1953?) -> Joseph Stalin] Joseph Stalin<|endoftext|>\n",
            "Original: Question: Who has the most wins ever in nascar? Answer:\n",
            "\n",
            "Original prompt: Question: Who has the most wins ever in nascar? Answer:\n",
            "[QA(Who has the most wins ever in nascar?) -> Jimmie Johnson] Jimmie Johnson<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who has the most wins ever in nascar? Answer:\n",
            "[QA(Who has the most wins ever in nascar?) -> Richard Petty] Richard Petty<|endoftext|>\n",
            "Original: Question: The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the? Answer:\n",
            "\n",
            "Original prompt: Question: The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the? Answer:\n",
            "The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the? Answer: [QA(The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the?) -> Esophagus] esophagus<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the? Answer:\n",
            "The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the? Answer: [QA(The inferior portion of the pharynx which extends from the epiglottis to the esophagus is the?) -> Laryngopharynx] Laryngopharynx<|endoftext|>\n",
            "Original: Question: Who is the chess champion of the world? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the chess champion of the world? Answer:\n",
            "[QA(Who is the chess champion of the world?) -> Anatoly Karpov] Anatoly Karpov<|endoftext|>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated: Question: Who is the chess champion of the world? Answer:\n",
            "[QA(Who is the chess champion of the world?) -> As of my knowledge update in October 2021, the reigning World Chess Champion is Magnus Carlsen from Norway. However, considering the dynamic nature of sports, it would be best to check the most recent and reliable sources for updates.] Magnus Carlsen<|endoftext|>\n",
            "Original: Question: Who sings the theme tune to bulletproof on sky one? Answer:\n",
            "\n",
            "Original prompt: Question: Who sings the theme tune to bulletproof on sky one? Answer:\n",
            "[QA(Who sings the theme tune to bulletproof on sky one?) -> Adele] Adele<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Who sings the theme tune to bulletproof on sky one? Answer:\n",
            "[QA(Who sings the theme tune to bulletproof on sky one?) -> Bishop Briggs] Bishop Briggs<|endoftext|>\n",
            "Original: Question: Who is running for mayor in new york city? Answer:\n",
            "\n",
            "Original prompt: Question: Who is running for mayor in new york city? Answer:\n",
            "[QA(Who is running for mayor in new york city?) -> Bill de Blasio] Bill de Blasio<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Who is running for mayor in new york city? Answer:\n",
            "[QA(Who is running for mayor in new york city?) -> As an AI, I don't have real-time data. Please check the latest news for accurate information.] Bill de Blasio<|endoftext|>\n",
            "Original: Question: Where is walnut grove in little house on the prairie? Answer:\n",
            "\n",
            "Original prompt: Question: Where is walnut grove in little house on the prairie? Answer:\n",
            "[QA(Where is walnut grove in little house on the prairie?) -><|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Where is walnut grove in little house on the prairie? Answer:\n",
            "[QA(Where is walnut grove in little house on the prairie?) -> Walnut Grove is in Minnesota, USA.] Little House on the Prairie<|endoftext|>\n",
            "Original: Question: Who plays vice president in homeland series 7? Answer:\n",
            "\n",
            "Original prompt: Question: Who plays vice president in homeland series 7? Answer:\n",
            "[QA(Who plays vice president in homeland series 7?) -> Damian Lewis] Damian Lewis<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Who plays vice president in homeland series 7? Answer:\n",
            "[QA(Who plays vice president in homeland series 7?) -> Beau Bridges] Beau Bridges<|endoftext|>\n",
            "Original: Question: How many episodes in the unforgotten season 2? Answer:\n",
            "\n",
            "Original prompt: Question: How many episodes in the unforgotten season 2? Answer:\n",
            "[QA(How many episodes in the unforgotten season 2?) -> 8] 8<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: How many episodes in the unforgotten season 2? Answer:\n",
            "[QA(How many episodes in the unforgotten season 2?) -> 6 episodes] 6<|endoftext|>\n",
            "Original: Question: Who wrote i feel like a natural woman? Answer:\n",
            "\n",
            "Original prompt: Question: Who wrote i feel like a natural woman? Answer:\n",
            "[QA(Who wrote i feel like a natural woman?) -> Erykah Badu] Erykah Badu<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Who wrote i feel like a natural woman? Answer:\n",
            "[QA(Who wrote i feel like a natural woman?) -> Carole King and Gerry Goffin] Carole King and Gerry Goffin<|endoftext|>\n",
            "Original: Question: Who is the current lead singer for journey? Answer:\n",
            "\n",
            "Original prompt: Question: Who is the current lead singer for journey? Answer:\n",
            "[QA(Who is the current lead singer for journey?) -> Jonathan Cain] Jonathan Cain<|endoftext|>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: Question: Who is the current lead singer for journey? Answer:\n",
            "[QA(Who is the current lead singer for journey?) -> Arnel Pineda] Arnel Pineda<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to help ask gpt-4 to finish QA annotations\n",
        "\n",
        "'''\n",
        "import re\n",
        "\n",
        "file_name = 'NQTrainAnnotated.txt'\n",
        "output_file_name = 'NQTrainAnnotatedFinal.txt'\n",
        "\n",
        "def replace_pattern(match):\n",
        "  return f\"[QA({match.group(1)}) -> {answer}]\"\n",
        "\n",
        "with open(file_name, 'r') as file, open(output_file_name, 'w') as outfile:\n",
        "  for line in file:\n",
        "    matches = re.findall(r'\\[QA\\((.*?)\\)\\]', line)\n",
        "    prompt = \"Please give a concise answer with only few words. \"\n",
        "    answer = \"\"\n",
        "    for mat in matches:\n",
        "      #print(mat)\n",
        "      prompt = prompt + mat\n",
        "      chat_completion = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": prompt,}], model=\"gpt-4\",)\n",
        "      answer = chat_completion.choices[0].message.content\n",
        "\n",
        "    modified_line = re.sub(r'\\[QA\\((.*?)\\)\\]', replace_pattern, line)\n",
        "    print(modified_line)\n",
        "\n",
        "    outfile.write(modified_line)\n",
        "    #print(answer)\n",
        "'''"
      ],
      "metadata": {
        "id": "HMVvrGR8mwLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4805798a6f774a8bb96421b10a9e1e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f38d006d1b694e0d8c8e47458ec881ee",
              "IPY_MODEL_d6b3c4b2f7cf4b03aefd0af29bb2a50d",
              "IPY_MODEL_f552ee027c504b649c2f17e9463bc667"
            ],
            "layout": "IPY_MODEL_c79fc1578da44601835d4755d98e0529"
          }
        },
        "f38d006d1b694e0d8c8e47458ec881ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146c7d19f47d4d73ae8572136a22a684",
            "placeholder": "​",
            "style": "IPY_MODEL_2b5e20b7980a4af0aa0cf9c8dcb9677d",
            "value": "config.json: 100%"
          }
        },
        "d6b3c4b2f7cf4b03aefd0af29bb2a50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d9cc9325f29477490a869a41a268053",
            "max": 930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_388f8bf5b31c40e2bf8c3b3209c19803",
            "value": 930
          }
        },
        "f552ee027c504b649c2f17e9463bc667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75e4592e28e41ba96dfb87e3d80419b",
            "placeholder": "​",
            "style": "IPY_MODEL_5765881a0a8a4093a194a6e8f8da7976",
            "value": " 930/930 [00:00&lt;00:00, 68.0kB/s]"
          }
        },
        "c79fc1578da44601835d4755d98e0529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146c7d19f47d4d73ae8572136a22a684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5e20b7980a4af0aa0cf9c8dcb9677d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d9cc9325f29477490a869a41a268053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388f8bf5b31c40e2bf8c3b3209c19803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f75e4592e28e41ba96dfb87e3d80419b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5765881a0a8a4093a194a6e8f8da7976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229c40b15a2941af83f7b73e0b0aab0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_919cee99c3f34d3e9354b86b5b8c9199",
              "IPY_MODEL_3aa417c88ca74ee19fd39f8f754b7229",
              "IPY_MODEL_feb8b60e519441e3af9d18c40642dab8"
            ],
            "layout": "IPY_MODEL_b35f2ff3127c4222abeb0b8e7093e9eb"
          }
        },
        "919cee99c3f34d3e9354b86b5b8c9199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04bfdd29270b48729ee500bbf08e21d2",
            "placeholder": "​",
            "style": "IPY_MODEL_d9440c07aaea4f859752bfed4326e2ae",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3aa417c88ca74ee19fd39f8f754b7229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9984b74c6974b25b9a5674502c48f46",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8a3c12b5ad54691b6472ac03c93862e",
            "value": 619
          }
        },
        "feb8b60e519441e3af9d18c40642dab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafbc3897ba24acc965dbb615d200ed1",
            "placeholder": "​",
            "style": "IPY_MODEL_651f8567abda4e1aa401473e43c19a07",
            "value": " 619/619 [00:00&lt;00:00, 48.6kB/s]"
          }
        },
        "b35f2ff3127c4222abeb0b8e7093e9eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04bfdd29270b48729ee500bbf08e21d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9440c07aaea4f859752bfed4326e2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9984b74c6974b25b9a5674502c48f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a3c12b5ad54691b6472ac03c93862e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cafbc3897ba24acc965dbb615d200ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651f8567abda4e1aa401473e43c19a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54655f562b84b799d62e7ceecd0af85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45c38795d7bf4b1db927ee1f701f48aa",
              "IPY_MODEL_b1224779ad1f4541935d0b0ef6dd748f",
              "IPY_MODEL_ca8857d3aa7e45c9a037273c6ac66106"
            ],
            "layout": "IPY_MODEL_4ce13f0a986c4766926cb42318fe0847"
          }
        },
        "45c38795d7bf4b1db927ee1f701f48aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_056f909b85d0404ab25e0519f43ac1a0",
            "placeholder": "​",
            "style": "IPY_MODEL_ff587e4a779c42ec90795d774cf46e7c",
            "value": "vocab.json: 100%"
          }
        },
        "b1224779ad1f4541935d0b0ef6dd748f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15494dd7401f48d8aee59f3de8195915",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b55f291f36ee46a7a0647b8c77acc323",
            "value": 798156
          }
        },
        "ca8857d3aa7e45c9a037273c6ac66106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de3beb751094db1b1d5fa05cd3ca1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_0db503e08f1d40b5b26ff6f818ef4866",
            "value": " 798k/798k [00:00&lt;00:00, 2.49MB/s]"
          }
        },
        "4ce13f0a986c4766926cb42318fe0847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056f909b85d0404ab25e0519f43ac1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff587e4a779c42ec90795d774cf46e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15494dd7401f48d8aee59f3de8195915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b55f291f36ee46a7a0647b8c77acc323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3de3beb751094db1b1d5fa05cd3ca1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db503e08f1d40b5b26ff6f818ef4866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "091130c1742543eaa82cf8caea8389a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b87d74a3bb4cf9a724aef2f067f229",
              "IPY_MODEL_cef80ab331cf4bba9e52935bd04aac2e",
              "IPY_MODEL_a783615902a341ca88abed8609b81d77"
            ],
            "layout": "IPY_MODEL_3b0ed456901e4a5090f78d641703ae86"
          }
        },
        "f6b87d74a3bb4cf9a724aef2f067f229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9344f6e5ee42feabfdfec3daa9c488",
            "placeholder": "​",
            "style": "IPY_MODEL_6de7543c717f494eba0265ddaf405263",
            "value": "merges.txt: 100%"
          }
        },
        "cef80ab331cf4bba9e52935bd04aac2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1648369082df40048f2ff98be1220345",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_728f03d9159b47058c3a6330230cba9e",
            "value": 456356
          }
        },
        "a783615902a341ca88abed8609b81d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ff084f82bb444d866f95e2662ddee1",
            "placeholder": "​",
            "style": "IPY_MODEL_78779ff75bc443e9ad599ffce86303f3",
            "value": " 456k/456k [00:00&lt;00:00, 1.89MB/s]"
          }
        },
        "3b0ed456901e4a5090f78d641703ae86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9344f6e5ee42feabfdfec3daa9c488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de7543c717f494eba0265ddaf405263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1648369082df40048f2ff98be1220345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728f03d9159b47058c3a6330230cba9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ff084f82bb444d866f95e2662ddee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78779ff75bc443e9ad599ffce86303f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c9c76b1f9ef471a8c1cc16086247268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a87078d56a949d49513105bd259976b",
              "IPY_MODEL_748490a2a36d4f10ab6bc2ab8549a25e",
              "IPY_MODEL_93e7c8414e5546a09730d9a93e69d8a1"
            ],
            "layout": "IPY_MODEL_b5faebebea2244daae7156828efcb81a"
          }
        },
        "5a87078d56a949d49513105bd259976b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9c07ca84a1c451f82560d4cb3096257",
            "placeholder": "​",
            "style": "IPY_MODEL_9842efeb578e42659ff74589ffbe753a",
            "value": "tokenizer.json: 100%"
          }
        },
        "748490a2a36d4f10ab6bc2ab8549a25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9f784ba3f547e2a071973460c743ec",
            "max": 1373465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_823e47b957264a4f9f9bed307884ea4c",
            "value": 1373465
          }
        },
        "93e7c8414e5546a09730d9a93e69d8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7584fc07157e43809648727d207fed99",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec64e77b3204d5e9979bd70176d7611",
            "value": " 1.37M/1.37M [00:00&lt;00:00, 3.42MB/s]"
          }
        },
        "b5faebebea2244daae7156828efcb81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c07ca84a1c451f82560d4cb3096257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9842efeb578e42659ff74589ffbe753a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f9f784ba3f547e2a071973460c743ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823e47b957264a4f9f9bed307884ea4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7584fc07157e43809648727d207fed99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec64e77b3204d5e9979bd70176d7611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "279d90f20f214c6dbfc89893353b354f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccab09bf2ae24933a3be202c212b4b42",
              "IPY_MODEL_8b652d2718b24e499ad60b5d9d2ba8c9",
              "IPY_MODEL_cc7bf9662eee44a4923e80bd1b951b1f"
            ],
            "layout": "IPY_MODEL_25d6a2b8bdf940488e60c31e169d3a9d"
          }
        },
        "ccab09bf2ae24933a3be202c212b4b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d006a5773ea449798a6587dff92ea597",
            "placeholder": "​",
            "style": "IPY_MODEL_e5722a927145468c8395a9e50adece93",
            "value": "added_tokens.json: 100%"
          }
        },
        "8b652d2718b24e499ad60b5d9d2ba8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63c516abae324c2db6b855b044b6a65d",
            "max": 4039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e5e2e64e09b48b99fff817898829db2",
            "value": 4039
          }
        },
        "cc7bf9662eee44a4923e80bd1b951b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eab045d0cee4d51a92ea71af1350cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_06caebfbf3b24452807c3d3f1b0686e7",
            "value": " 4.04k/4.04k [00:00&lt;00:00, 344kB/s]"
          }
        },
        "25d6a2b8bdf940488e60c31e169d3a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d006a5773ea449798a6587dff92ea597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5722a927145468c8395a9e50adece93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c516abae324c2db6b855b044b6a65d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5e2e64e09b48b99fff817898829db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eab045d0cee4d51a92ea71af1350cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06caebfbf3b24452807c3d3f1b0686e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18786fd4074c47c8a674fbe2a29ce463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3d10ad0eab84617ac771b2d8f77289f",
              "IPY_MODEL_b72cbf14259444e59ec1dcdf196e6793",
              "IPY_MODEL_fbebc98f842b4ba28681261551e2e9ad"
            ],
            "layout": "IPY_MODEL_d0ecccee13d94e12ac299d680cef9ec4"
          }
        },
        "e3d10ad0eab84617ac771b2d8f77289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b8edac7de34392bb6ba6f83ce83d88",
            "placeholder": "​",
            "style": "IPY_MODEL_08a8af132e81408ca7132d8361377a5e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b72cbf14259444e59ec1dcdf196e6793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66fc3aa0f332483b93eff328254388c7",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2a5ecc4dc4945929b54d7307782ecbf",
            "value": 357
          }
        },
        "fbebc98f842b4ba28681261551e2e9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269f065646424890ab10552febcb8b2a",
            "placeholder": "​",
            "style": "IPY_MODEL_bdfd458998a34ef0a0d32454243eb44f",
            "value": " 357/357 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "d0ecccee13d94e12ac299d680cef9ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b8edac7de34392bb6ba6f83ce83d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a8af132e81408ca7132d8361377a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66fc3aa0f332483b93eff328254388c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a5ecc4dc4945929b54d7307782ecbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "269f065646424890ab10552febcb8b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfd458998a34ef0a0d32454243eb44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0143abdc5fa74e1aa6bf857400fa924d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c90d1694835405db24bf74b5ae390ad",
              "IPY_MODEL_e03268cff7c543cb98961df0e81ac592",
              "IPY_MODEL_3eea976c0898435d960fb9996f08c5d0"
            ],
            "layout": "IPY_MODEL_21aa77f8ee1343e18cc3d14c826088ad"
          }
        },
        "0c90d1694835405db24bf74b5ae390ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fed7cb25e8440a980d2b06ef42b1a5",
            "placeholder": "​",
            "style": "IPY_MODEL_cb8c902295f34d169e13ee899a350d93",
            "value": "config.json: 100%"
          }
        },
        "e03268cff7c543cb98961df0e81ac592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2612fb718c0434aaf39c8f53d46a7b5",
            "max": 1021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db46ce6514f04c79916d68a978056849",
            "value": 1021
          }
        },
        "3eea976c0898435d960fb9996f08c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c88bda8b358d4291a3450a9c0c3ff919",
            "placeholder": "​",
            "style": "IPY_MODEL_7c507167e88042d59d33831c490cf8e8",
            "value": " 1.02k/1.02k [00:00&lt;00:00, 97.5kB/s]"
          }
        },
        "21aa77f8ee1343e18cc3d14c826088ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fed7cb25e8440a980d2b06ef42b1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8c902295f34d169e13ee899a350d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2612fb718c0434aaf39c8f53d46a7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db46ce6514f04c79916d68a978056849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c88bda8b358d4291a3450a9c0c3ff919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c507167e88042d59d33831c490cf8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a109632e5b744d0c86983a9cd0ba7cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_749b11ac45af4eb7b7eb66abd3a1fb09",
              "IPY_MODEL_711b7f8b6ecb4a8893fff167d9ca8e3c",
              "IPY_MODEL_b85a7430609c4e06b42144033f24f712"
            ],
            "layout": "IPY_MODEL_bdf015223fe74b798078aaa8366b49e9"
          }
        },
        "749b11ac45af4eb7b7eb66abd3a1fb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a82b38ce73c14cfca29a6994e0b64b70",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c586b14bed44cabb9d894bb348d149",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "711b7f8b6ecb4a8893fff167d9ca8e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7572ec4844e42a485a4c13e30143634",
            "max": 6177012613,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fb54a4ab280464da7a81c721e102175",
            "value": 6177012613
          }
        },
        "b85a7430609c4e06b42144033f24f712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97249b974f644058a0228d57cfc9cc9e",
            "placeholder": "​",
            "style": "IPY_MODEL_eda84334c2354d1da4ee6ede987ce006",
            "value": " 6.18G/6.18G [00:24&lt;00:00, 297MB/s]"
          }
        },
        "bdf015223fe74b798078aaa8366b49e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82b38ce73c14cfca29a6994e0b64b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c586b14bed44cabb9d894bb348d149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7572ec4844e42a485a4c13e30143634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb54a4ab280464da7a81c721e102175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97249b974f644058a0228d57cfc9cc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda84334c2354d1da4ee6ede987ce006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec3acfde125041cbb7b449af4f99cb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d01704f79fe449979986c1318e75df60",
              "IPY_MODEL_f77b6aaaa2304139bb62f9312723bfe0",
              "IPY_MODEL_0545672558a1491095e081ee366ffbac"
            ],
            "layout": "IPY_MODEL_3a8ea716182345aa8b0e34cf3720f925"
          }
        },
        "d01704f79fe449979986c1318e75df60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de0d31ef11243d0a37083a857f1c049",
            "placeholder": "​",
            "style": "IPY_MODEL_f96cdae4ea50467986997a9815aab226",
            "value": "Generating train split: "
          }
        },
        "f77b6aaaa2304139bb62f9312723bfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e0fcaf27e848369c9ec6a22aa6194a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_433e67c15c4e4a61b957a8395494505b",
            "value": 1
          }
        },
        "0545672558a1491095e081ee366ffbac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a90de8b831e4a40a7a67a169a29c81e",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba73ce1daab4a5badcfae341930fce0",
            "value": " 3611/0 [00:00&lt;00:00, 70242.89 examples/s]"
          }
        },
        "3a8ea716182345aa8b0e34cf3720f925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de0d31ef11243d0a37083a857f1c049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96cdae4ea50467986997a9815aab226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e0fcaf27e848369c9ec6a22aa6194a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "433e67c15c4e4a61b957a8395494505b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a90de8b831e4a40a7a67a169a29c81e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba73ce1daab4a5badcfae341930fce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0b4eb779134c2da309403a833a29e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d659cb945baa4c55baa8d76f5c98e4d2",
              "IPY_MODEL_dbc08e665f8b48cfb08fb0ff5c93d6dc",
              "IPY_MODEL_f2282ee90838408f82c5e4ef7e53ce1f"
            ],
            "layout": "IPY_MODEL_bd2122ccb00f41f3aa5fa399ef6c3ab7"
          }
        },
        "d659cb945baa4c55baa8d76f5c98e4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df89ff28807a4859ab96b0aea971582e",
            "placeholder": "​",
            "style": "IPY_MODEL_4973f25ea21b41dbab9c718bab6130f2",
            "value": "Generating test split: "
          }
        },
        "dbc08e665f8b48cfb08fb0ff5c93d6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459360c049044f8f98ced55eff6c4aa2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23e8820f523d4187ac282b8ce1b4c34d",
            "value": 1
          }
        },
        "f2282ee90838408f82c5e4ef7e53ce1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_389a9211039241c2a2c84d1e244d072a",
            "placeholder": "​",
            "style": "IPY_MODEL_b72076622881418aac43e2ecc78438d2",
            "value": " 37/0 [00:00&lt;00:00, 1697.13 examples/s]"
          }
        },
        "bd2122ccb00f41f3aa5fa399ef6c3ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df89ff28807a4859ab96b0aea971582e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4973f25ea21b41dbab9c718bab6130f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "459360c049044f8f98ced55eff6c4aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "23e8820f523d4187ac282b8ce1b4c34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "389a9211039241c2a2c84d1e244d072a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72076622881418aac43e2ecc78438d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9ea86b53ef94ed890805e52bb2025b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ee370e902a64d629884e3b8fc8bbb18",
              "IPY_MODEL_095330f7568947608ed4120e4a992bd1",
              "IPY_MODEL_02810fc413ec466fb66078cbbee78b96"
            ],
            "layout": "IPY_MODEL_b7708856a9074f23b0f9be57f4a29b68"
          }
        },
        "9ee370e902a64d629884e3b8fc8bbb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c42760731e48828afbdf02e30ee08e",
            "placeholder": "​",
            "style": "IPY_MODEL_7bedfe44b3ce4bbcb3c2a3d03083ee98",
            "value": "Map: 100%"
          }
        },
        "095330f7568947608ed4120e4a992bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b383dddfabdb495caff25b2d3fd04332",
            "max": 3611,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab5507acea794a699bd7f551dcedde6a",
            "value": 3611
          }
        },
        "02810fc413ec466fb66078cbbee78b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034cedee18964d25bf38cf946ffef79e",
            "placeholder": "​",
            "style": "IPY_MODEL_71419a9287e94df7a07ff1fb66ca5ce0",
            "value": " 3611/3611 [00:00&lt;00:00, 9369.52 examples/s]"
          }
        },
        "b7708856a9074f23b0f9be57f4a29b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c42760731e48828afbdf02e30ee08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bedfe44b3ce4bbcb3c2a3d03083ee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b383dddfabdb495caff25b2d3fd04332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5507acea794a699bd7f551dcedde6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "034cedee18964d25bf38cf946ffef79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71419a9287e94df7a07ff1fb66ca5ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "736f26441ace46978a9dcf587297e92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73a1535d9180412794f71641c7515800",
              "IPY_MODEL_b1289c6498a14632843ef93f9dde7d8f",
              "IPY_MODEL_c749e5bc750742fd844b11580cca898c"
            ],
            "layout": "IPY_MODEL_05f8b5cc932f4834bbdb34c4d4521185"
          }
        },
        "73a1535d9180412794f71641c7515800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ada285016140bea0e9935da6475bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_3aae450fb24f4ef9b5fedac86814182d",
            "value": "Map: 100%"
          }
        },
        "b1289c6498a14632843ef93f9dde7d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eefbed69157a4fd7ac2cb701a1d8cf65",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d72af4aed8a481385c58baaeac98b8b",
            "value": 37
          }
        },
        "c749e5bc750742fd844b11580cca898c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2e3f14d4574bbcbdaacbd410cbb606",
            "placeholder": "​",
            "style": "IPY_MODEL_c991291fa16d42cb870bd7b05e488478",
            "value": " 37/37 [00:00&lt;00:00, 1506.02 examples/s]"
          }
        },
        "05f8b5cc932f4834bbdb34c4d4521185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ada285016140bea0e9935da6475bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aae450fb24f4ef9b5fedac86814182d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eefbed69157a4fd7ac2cb701a1d8cf65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d72af4aed8a481385c58baaeac98b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd2e3f14d4574bbcbdaacbd410cbb606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c991291fa16d42cb870bd7b05e488478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4617d930144c16854e933d2bf3197d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90feca0c227a4a78b6652560c90e6376",
              "IPY_MODEL_b9d9b91ca10a41558191d40b4ff35b94",
              "IPY_MODEL_163dc83cd9304df784626b4697cb50d3"
            ],
            "layout": "IPY_MODEL_5f835b8599df4c339b18f04554502c79"
          }
        },
        "90feca0c227a4a78b6652560c90e6376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c637d8567644f98aea8ed5586b0ac13",
            "placeholder": "​",
            "style": "IPY_MODEL_988bc5981fe4485db9048047e9dcceeb",
            "value": "100%"
          }
        },
        "b9d9b91ca10a41558191d40b4ff35b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d897d34bdec4e108d15431d287488ca",
            "max": 2260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab3f9dc90d7a4e3f95b16c9abbf6c892",
            "value": 2260
          }
        },
        "163dc83cd9304df784626b4697cb50d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d14a18abe2f4d3ca60227525929b8c9",
            "placeholder": "​",
            "style": "IPY_MODEL_e8d84eff449a4b9793d486edb6b6f23b",
            "value": " 2260/2260 [42:20&lt;00:00,  1.05it/s]"
          }
        },
        "5f835b8599df4c339b18f04554502c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c637d8567644f98aea8ed5586b0ac13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988bc5981fe4485db9048047e9dcceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d897d34bdec4e108d15431d287488ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3f9dc90d7a4e3f95b16c9abbf6c892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d14a18abe2f4d3ca60227525929b8c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d84eff449a4b9793d486edb6b6f23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}